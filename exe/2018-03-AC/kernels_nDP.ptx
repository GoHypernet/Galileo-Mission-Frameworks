//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19805474
// Cuda compilation tools, release 7.5, V7.5.16
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	_Z15gpu_Hazard_ZUK0iiddd
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
;
.const .align 4 .u32 dc_unitsOption;
.const .align 8 .f64 dc_g;
.const .align 8 .f64 dc_nUnitsFactor;
.const .align 8 .f64 dc_wetDepthThreshold;
.const .align 8 .f64 dc_dryDepthThreshold;
.const .align 8 .f64 dc_nutM;
.const .align 8 .f64 dc_nutC;
.const .align 4 .u32 dc_nyPadded;
.const .align 4 .u32 dc_ny;
.const .align 4 .u32 dc_nx;
.const .align 8 .f64 dc_dy;
.const .align 8 .f64 dc_dx;
.const .align 4 .u32 dc_spatialOrder;
.const .align 8 .f64 dc_HTFormLoss;
.const .align 8 .f64 dc_HTViscMult;
.const .align 8 .f64 dc_rho;
.const .align 8 .f64 dc_shearStressH0;
.const .align 8 .f64 dc_shearStressH1;
.const .align 4 .u32 dc_turbulenceModel;
.const .align 8 .u64 dc_nanCounter;
.const .align 8 .u64 dc_a;
.const .align 8 .u64 dc_mat;
.const .align 8 .u64 dc_l;
.const .align 8 .u64 dc_Pk;
.const .align 8 .u64 dc_nut;
.const .align 8 .u64 dc_phi2;
.const .align 8 .u64 dc_phi4;
.const .align 8 .u64 dc_zc;
.const .align 8 .u64 dc_zu;
.const .align 8 .u64 dc_zv;
.const .align 8 .u64 dc_zh;
.const .align 8 .u64 dc_rf;
.const .align 8 .u64 dc_sa;
.const .align 8 .u64 dc_ir;
.const .align 8 .u64 dc_sx;
.const .align 8 .u64 dc_sc;
.const .align 8 .u64 dc_griddedSh;
.const .align 8 .u64 dc_tauU0;
.const .align 8 .u64 dc_tauV0;
.const .align 8 .u64 dc_tauU1;
.const .align 8 .u64 dc_tauV1;
.const .align 8 .u64 dc_hyetographIndexLayer;
.const .align 8 .u64 dc_hyetographWeightLayer;
.const .align 8 .u64 dc_mnu;
.const .align 8 .u64 dc_mnv;
.const .align 8 .u64 dc_areaFactor;
.const .align 8 .u64 dc_uFlowWidth;
.const .align 8 .u64 dc_vFlowWidth;
.const .align 8 .u64 dc_uFormLoss;
.const .align 8 .u64 dc_vFormLoss;
.const .align 8 .u64 dc_uniformShearStress;
.const .align 8 .u64 dc_boundaryLevelGraphTypes;
.const .align 8 .u64 dc_boundaryLevelGraphData;
.const .align 8 .u64 dc_materialTypes;
.const .align 8 .u64 dc_soilTypes;
.const .align 4 .u32 dc_switches;
.const .align 8 .u64 dc_varFC_m;
.const .align 8 .u64 dc_varFC_n;
.const .align 8 .u64 dc_varFC_type;
.const .align 8 .u64 dc_varFC_h;
.const .align 8 .u64 dc_varFC_ad;
.const .align 8 .u64 dc_varFC_fl;
.const .align 8 .u64 dc_varZ_m;
.const .align 8 .u64 dc_varZ_n;
.const .align 8 .u64 dc_varZ_type;
.const .align 8 .u64 dc_varZ_tv;
.const .align 8 .u64 dc_varZ_z;
.const .align 8 .u64 dc_varZ_t;
.const .align 8 .u64 dc_varZ_q;
.const .align 8 .u64 dc_fxHx;
.const .align 8 .u64 dc_fyHx;
.global .align 1 .b8 $str[87] = {40, 37, 105, 32, 37, 105, 41, 32, 116, 121, 112, 101, 32, 37, 105, 32, 87, 65, 82, 78, 73, 78, 71, 58, 32, 86, 97, 114, 105, 97, 98, 108, 101, 32, 90, 32, 109, 105, 115, 109, 97, 116, 99, 104, 32, 122, 67, 117, 114, 32, 61, 32, 37, 102, 32, 98, 117, 116, 32, 122, 49, 32, 61, 32, 37, 102, 44, 32, 102, 111, 114, 99, 105, 110, 103, 32, 122, 67, 117, 114, 32, 61, 32, 122, 49, 10, 0};

.visible .func  (.param .b64 func_retval0) _Z15gpu_Hazard_ZUK0iiddd(
	.param .b32 _Z15gpu_Hazard_ZUK0iiddd_param_0,
	.param .b32 _Z15gpu_Hazard_ZUK0iiddd_param_1,
	.param .b64 _Z15gpu_Hazard_ZUK0iiddd_param_2,
	.param .b64 _Z15gpu_Hazard_ZUK0iiddd_param_3,
	.param .b64 _Z15gpu_Hazard_ZUK0iiddd_param_4
)
{
	.reg .pred 	%p<26>;
	.reg .b32 	%r<3>;
	.reg .f64 	%fd<23>;


	ld.param.u32 	%r1, [_Z15gpu_Hazard_ZUK0iiddd_param_0];
	ld.param.u32 	%r2, [_Z15gpu_Hazard_ZUK0iiddd_param_1];
	ld.param.f64 	%fd21, [_Z15gpu_Hazard_ZUK0iiddd_param_2];
	ld.param.f64 	%fd10, [_Z15gpu_Hazard_ZUK0iiddd_param_3];
	ld.param.f64 	%fd11, [_Z15gpu_Hazard_ZUK0iiddd_param_4];
	mov.f64 	%fd22, 0d0000000000000000;
	setp.eq.s32	%p1, %r1, 1;
	@%p1 bra 	BB0_18;
	bra.uni 	BB0_1;

BB0_18:
	add.f64 	%fd20, %fd11, 0d3FF8000000000000;
	mul.f64 	%fd22, %fd20, %fd10;
	bra.uni 	BB0_19;

BB0_1:
	setp.ne.s32	%p2, %r1, 2;
	@%p2 bra 	BB0_19;

	setp.gt.s32	%p3, %r2, 2;
	@%p3 bra 	BB0_8;

	setp.eq.s32	%p6, %r2, 1;
	@%p6 bra 	BB0_14;
	bra.uni 	BB0_4;

BB0_14:
	setp.gt.f64	%p21, %fd10, 0d3FB999999999999A;
	setp.gt.f64	%p22, %fd11, 0d4000000000000000;
	and.pred  	%p23, %p21, %p22;
	mov.f64 	%fd21, 0d3FE0000000000000;
	@%p23 bra 	BB0_17;

	mov.f64 	%fd21, 0d0000000000000000;
	setp.le.f64	%p24, %fd10, 0d3FD0000000000000;
	@%p24 bra 	BB0_17;

	setp.gtu.f64	%p25, %fd10, 0d3FE8000000000000;
	selp.f64	%fd21, 0d3FE0000000000000, 0d0000000000000000, %p25;
	bra.uni 	BB0_17;

BB0_8:
	setp.eq.s32	%p4, %r2, 3;
	@%p4 bra 	BB0_12;
	bra.uni 	BB0_9;

BB0_12:
	setp.gt.f64	%p12, %fd10, 0d3FB999999999999A;
	setp.gt.f64	%p13, %fd11, 0d4000000000000000;
	and.pred  	%p14, %p12, %p13;
	mov.f64 	%fd21, 0d3FF0000000000000;
	@%p14 bra 	BB0_17;

	setp.gtu.f64	%p15, %fd10, 0d3FD0000000000000;
	selp.f64	%fd21, 0d3FF0000000000000, 0d0000000000000000, %p15;
	bra.uni 	BB0_17;

BB0_4:
	setp.eq.s32	%p7, %r2, 2;
	@%p7 bra 	BB0_5;
	bra.uni 	BB0_17;

BB0_5:
	setp.gt.f64	%p16, %fd10, 0d3FB999999999999A;
	setp.gt.f64	%p17, %fd11, 0d4000000000000000;
	and.pred  	%p18, %p16, %p17;
	mov.f64 	%fd21, 0d3FF0000000000000;
	@%p18 bra 	BB0_17;

	mov.f64 	%fd21, 0d0000000000000000;
	setp.le.f64	%p19, %fd10, 0d3FD0000000000000;
	@%p19 bra 	BB0_17;

	setp.gtu.f64	%p20, %fd10, 0d3FE8000000000000;
	selp.f64	%fd21, 0d3FF0000000000000, 0d3FE0000000000000, %p20;
	bra.uni 	BB0_17;

BB0_9:
	setp.ne.s32	%p5, %r2, 4;
	@%p5 bra 	BB0_17;

	setp.gt.f64	%p8, %fd10, 0d3FB999999999999A;
	setp.gt.f64	%p9, %fd11, 0d4000000000000000;
	and.pred  	%p10, %p8, %p9;
	mov.f64 	%fd21, 0d3FF0000000000000;
	@%p10 bra 	BB0_17;

	setp.gtu.f64	%p11, %fd10, 0d3FD0000000000000;
	selp.f64	%fd21, 0d3FF0000000000000, 0d3FE0000000000000, %p11;

BB0_17:
	add.f64 	%fd19, %fd11, 0d3FE0000000000000;
	fma.rn.f64 	%fd22, %fd19, %fd10, %fd21;

BB0_19:
	st.param.f64	[func_retval0+0], %fd22;
	ret;
}

	// .globl	_Z15gpu_Hazard_ZUK1d
.visible .func  (.param .b64 func_retval0) _Z15gpu_Hazard_ZUK1d(
	.param .b64 _Z15gpu_Hazard_ZUK1d_param_0
)
{
	.reg .pred 	%p<5>;
	.reg .f64 	%fd<8>;


	ld.param.f64 	%fd3, [_Z15gpu_Hazard_ZUK1d_param_0];
	mov.f64 	%fd7, 0d0000000000000000;
	setp.le.f64	%p1, %fd3, 0d0000000000000000;
	@%p1 bra 	BB1_4;

	mov.f64 	%fd7, 0d3FF0000000000000;
	setp.le.f64	%p2, %fd3, 0d3FE8000000000000;
	@%p2 bra 	BB1_4;

	mov.f64 	%fd7, 0d4000000000000000;
	setp.le.f64	%p3, %fd3, 0d3FF4000000000000;
	@%p3 bra 	BB1_4;

	setp.gtu.f64	%p4, %fd3, 0d4004000000000000;
	selp.f64	%fd7, 0d4010000000000000, 0d4008000000000000, %p4;

BB1_4:
	st.param.f64	[func_retval0+0], %fd7;
	ret;
}

	// .globl	_Z15gpu_Hazard_ZUK3d
.visible .func  (.param .b64 func_retval0) _Z15gpu_Hazard_ZUK3d(
	.param .b64 _Z15gpu_Hazard_ZUK3d_param_0
)
{
	.reg .pred 	%p<5>;
	.reg .f64 	%fd<8>;


	ld.param.f64 	%fd3, [_Z15gpu_Hazard_ZUK3d_param_0];
	mov.f64 	%fd7, 0d0000000000000000;
	setp.le.f64	%p1, %fd3, 0d0000000000000000;
	@%p1 bra 	BB2_4;

	mov.f64 	%fd7, 0d3FF0000000000000;
	setp.le.f64	%p2, %fd3, 0d3FE8000000000000;
	@%p2 bra 	BB2_4;

	mov.f64 	%fd7, 0d4000000000000000;
	setp.le.f64	%p3, %fd3, 0d3FF4000000000000;
	@%p3 bra 	BB2_4;

	setp.gtu.f64	%p4, %fd3, 0d4000000000000000;
	selp.f64	%fd7, 0d4010000000000000, 0d4008000000000000, %p4;

BB2_4:
	st.param.f64	[func_retval0+0], %fd7;
	ret;
}

	// .globl	_Z17gpu_calcFaceValueiddddd
.visible .func  (.param .b64 func_retval0) _Z17gpu_calcFaceValueiddddd(
	.param .b32 _Z17gpu_calcFaceValueiddddd_param_0,
	.param .b64 _Z17gpu_calcFaceValueiddddd_param_1,
	.param .b64 _Z17gpu_calcFaceValueiddddd_param_2,
	.param .b64 _Z17gpu_calcFaceValueiddddd_param_3,
	.param .b64 _Z17gpu_calcFaceValueiddddd_param_4,
	.param .b64 _Z17gpu_calcFaceValueiddddd_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<2>;
	.reg .f64 	%fd<44>;


	ld.param.u32 	%r1, [_Z17gpu_calcFaceValueiddddd_param_0];
	ld.param.f64 	%fd17, [_Z17gpu_calcFaceValueiddddd_param_1];
	ld.param.f64 	%fd18, [_Z17gpu_calcFaceValueiddddd_param_2];
	ld.param.f64 	%fd19, [_Z17gpu_calcFaceValueiddddd_param_3];
	ld.param.f64 	%fd20, [_Z17gpu_calcFaceValueiddddd_param_4];
	ld.param.f64 	%fd21, [_Z17gpu_calcFaceValueiddddd_param_5];
	setp.gt.f64	%p1, %fd21, 0d0000000000000000;
	@%p1 bra 	BB3_2;
	bra.uni 	BB3_1;

BB3_2:
	sub.f64 	%fd35, %fd18, %fd17;
	sub.f64 	%fd36, %fd19, %fd17;
	sub.f64 	%fd37, %fd19, %fd18;
	mov.f64 	%fd43, %fd18;
	bra.uni 	BB3_3;

BB3_1:
	sub.f64 	%fd35, %fd19, %fd20;
	sub.f64 	%fd36, %fd18, %fd20;
	sub.f64 	%fd37, %fd18, %fd19;
	mov.f64 	%fd43, %fd19;

BB3_3:
	mov.f64 	%fd38, %fd43;
	mov.f64 	%fd7, %fd38;
	mul.f64 	%fd22, %fd35, %fd37;
	setp.leu.f64	%p2, %fd22, 0d0000000000000000;
	mov.f64 	%fd41, %fd7;
	@%p2 bra 	BB3_10;

	setp.eq.s32	%p3, %r1, 2;
	@%p3 bra 	BB3_7;
	bra.uni 	BB3_5;

BB3_7:
	add.f64 	%fd27, %fd18, %fd19;
	mul.f64 	%fd42, %fd27, 0d3FE0000000000000;
	bra.uni 	BB3_8;

BB3_5:
	setp.ne.s32	%p4, %r1, 4;
	mov.f64 	%fd42, %fd7;
	@%p4 bra 	BB3_8;

	add.f64 	%fd23, %fd18, %fd19;
	mul.f64 	%fd24, %fd23, 0d4022000000000000;
	add.f64 	%fd25, %fd17, %fd20;
	sub.f64 	%fd26, %fd24, %fd25;
	mul.f64 	%fd42, %fd26, 0d3FB0000000000000;

BB3_8:
	mov.f64 	%fd13, %fd42;
	div.rn.f64 	%fd28, %fd35, %fd36;
	setp.lt.f64	%p5, %fd28, 0d3FE0000000000000;
	mov.f64 	%fd29, 0d3FF0000000000000;
	sub.f64 	%fd30, %fd29, %fd28;
	selp.f64	%fd31, %fd28, %fd30, %p5;
	mul.f64 	%fd14, %fd31, 0d4024000000000000;
	setp.geu.f64	%p6, %fd14, 0d3FF0000000000000;
	mov.f64 	%fd41, %fd13;
	@%p6 bra 	BB3_10;

	sub.f64 	%fd33, %fd29, %fd14;
	mul.f64 	%fd34, %fd7, %fd33;
	fma.rn.f64 	%fd41, %fd13, %fd14, %fd34;

BB3_10:
	st.param.f64	[func_retval0+0], %fd41;
	ret;
}

	// .globl	_Z10gpu_calcShjddjj
.visible .func  (.param .b64 func_retval0) _Z10gpu_calcShjddjj(
	.param .b32 _Z10gpu_calcShjddjj_param_0,
	.param .b64 _Z10gpu_calcShjddjj_param_1,
	.param .b64 _Z10gpu_calcShjddjj_param_2,
	.param .b32 _Z10gpu_calcShjddjj_param_3,
	.param .b32 _Z10gpu_calcShjddjj_param_4
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<11>;


	ld.param.u32 	%r1, [_Z10gpu_calcShjddjj_param_0];
	ld.param.f64 	%fd10, [_Z10gpu_calcShjddjj_param_1];
	ld.param.f64 	%fd6, [_Z10gpu_calcShjddjj_param_2];
	ld.param.u32 	%r2, [_Z10gpu_calcShjddjj_param_3];
	ld.param.u32 	%r3, [_Z10gpu_calcShjddjj_param_4];
	setp.eq.s32	%p1, %r1, 31;
	@%p1 bra 	BB4_7;
	bra.uni 	BB4_1;

BB4_7:
	or.b32  	%r4, %r3, %r2;
	setp.ne.s32	%p6, %r4, 0;
	selp.f64	%fd10, %fd10, 0d0000000000000000, %p6;
	bra.uni 	BB4_8;

BB4_1:
	setp.ne.s32	%p2, %r1, 34;
	@%p2 bra 	BB4_8;

	setp.eq.s32	%p3, %r2, 65535;
	@%p3 bra 	BB4_6;
	bra.uni 	BB4_3;

BB4_6:
	cvt.rn.f64.u32	%fd9, %r3;
	mul.f64 	%fd10, %fd9, %fd6;
	bra.uni 	BB4_8;

BB4_3:
	setp.ne.s32	%p4, %r2, 0;
	@%p4 bra 	BB4_8;

	setp.eq.s32	%p5, %r3, 0;
	mov.f64 	%fd10, 0d0000000000000000;
	@%p5 bra 	BB4_8;

	cvt.rn.f64.u32	%fd8, %r3;
	mul.f64 	%fd10, %fd8, %fd6;

BB4_8:
	st.param.f64	[func_retval0+0], %fd10;
	ret;
}

	// .globl	_Z17gpu_calcManningsNjjddd
.visible .func  (.param .b64 func_retval0) _Z17gpu_calcManningsNjjddd(
	.param .b32 _Z17gpu_calcManningsNjjddd_param_0,
	.param .b32 _Z17gpu_calcManningsNjjddd_param_1,
	.param .b64 _Z17gpu_calcManningsNjjddd_param_2,
	.param .b64 _Z17gpu_calcManningsNjjddd_param_3,
	.param .b64 _Z17gpu_calcManningsNjjddd_param_4
)
{
	.local .align 8 .b8 	__local_depot5[176];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<48>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<162>;
	.reg .b64 	%rd<38>;


	mov.u64 	%rd37, __local_depot5;
	cvta.local.u64 	%SP, %rd37;
	ld.param.u32 	%r15, [_Z17gpu_calcManningsNjjddd_param_1];
	ld.param.f64 	%fd55, [_Z17gpu_calcManningsNjjddd_param_2];
	ld.param.f64 	%fd56, [_Z17gpu_calcManningsNjjddd_param_3];
	ld.param.f64 	%fd57, [_Z17gpu_calcManningsNjjddd_param_4];
	add.u64 	%rd7, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd7;
	setp.eq.s32	%p2, %r15, 0;
	mov.f64 	%fd155, 0d0000000000000000;
	@%p2 bra 	BB5_54;

	ld.const.u64 	%rd8, [dc_materialTypes];
	cvta.to.global.u64 	%rd9, %rd8;
	add.s32 	%r17, %r15, -1;
	mul.wide.u32 	%rd10, %r17, 176;
	add.s64 	%rd2, %rd9, %rd10;
	mov.u32 	%r52, 0;

BB5_2:
	mul.wide.s32 	%rd11, %r52, 8;
	add.s64 	%rd12, %rd2, %rd11;
	ld.global.u64 	%rd13, [%rd12];
	add.s64 	%rd14, %rd1, %rd11;
	st.local.u64 	[%rd14], %rd13;
	add.s32 	%r52, %r52, 1;
	setp.lt.u32	%p3, %r52, 22;
	@%p3 bra 	BB5_2;

	ld.local.f64 	%fd1, [%rd1+16];
	setp.gt.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB5_29;
	bra.uni 	BB5_4;

BB5_29:
	mul.f64 	%fd67, %fd57, %fd57;
	fma.rn.f64 	%fd68, %fd56, %fd56, %fd67;
	sqrt.rn.f64 	%fd69, %fd68;
	setp.gt.f64	%p21, %fd69, 0d3EB0C6F7A0B5ED8D;
	selp.f64	%fd70, %fd69, 0d3EB0C6F7A0B5ED8D, %p21;
	ld.const.u32 	%r18, [dc_unitsOption];
	setp.eq.s32	%p22, %r18, 1;
	selp.f64	%fd71, 0d3EB3DD5DA733223F, 0d3E7D87247702C0D0, %p22;
	mul.f64 	%fd72, %fd70, %fd55;
	sqrt.rn.f64 	%fd73, %fd72;
	div.rn.f64 	%fd74, %fd71, %fd73;
	div.rn.f64 	%fd75, %fd1, 0d403E000000000000;
	add.f64 	%fd28, %fd75, %fd74;
	ld.local.f64 	%fd29, [%rd1+24];
	mov.f64 	%fd76, 0d3FC5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r19, %r3, 20, 11;
	add.s32 	%r20, %r19, -1012;
	mov.u64 	%rd34, 4595172819793696085;
	shl.b64 	%rd6, %rd34, %r20;
	setp.eq.s64	%p23, %rd6, -9223372036854775808;
	abs.f64 	%fd30, %fd55;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd30;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd145, [retval0+0];
	
	//{
	}// Callseq End 0
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd55;
	}
	setp.lt.s32	%p24, %r4, 0;
	and.pred  	%p1, %p24, %p23;
	@!%p1 bra 	BB5_31;
	bra.uni 	BB5_30;

BB5_30:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd145;
	}
	xor.b32  	%r22, %r21, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r23, %temp}, %fd145;
	}
	mov.b64 	%fd145, {%r23, %r22};

BB5_31:
	mov.f64 	%fd144, %fd145;
	setp.eq.f64	%p25, %fd55, 0d0000000000000000;
	@%p25 bra 	BB5_34;
	bra.uni 	BB5_32;

BB5_34:
	selp.b32	%r24, %r4, 0, %p23;
	or.b32  	%r25, %r24, 2146435072;
	setp.lt.s32	%p29, %r3, 0;
	selp.b32	%r26, %r25, %r24, %p29;
	mov.u32 	%r27, 0;
	mov.b64 	%fd144, {%r27, %r26};
	bra.uni 	BB5_35;

BB5_4:
	ld.local.f64 	%fd155, [%rd1+8];
	setp.geu.f64	%p5, %fd155, 0d0000000000000000;
	@%p5 bra 	BB5_54;

	ld.local.f64 	%fd137, [%rd1+48];
	setp.gt.f64	%p6, %fd137, %fd55;
	@%p6 bra 	BB5_28;
	bra.uni 	BB5_6;

BB5_28:
	ld.local.f64 	%fd155, [%rd1+112];
	bra.uni 	BB5_54;

BB5_32:
	setp.gt.s32	%p26, %r4, -1;
	@%p26 bra 	BB5_35;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p27, %fd78, 0d3FC5555555555555;
	selp.f64	%fd144, 0dFFF8000000000000, %fd144, %p27;

BB5_35:
	mov.f64 	%fd36, %fd144;
	add.f64 	%fd37, %fd55, 0d3FC5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd37;
	}
	and.b32  	%r29, %r28, 2146435072;
	setp.ne.s32	%p30, %r29, 2146435072;
	mov.f64 	%fd143, %fd36;
	@%p30 bra 	BB5_42;

	setp.gtu.f64	%p31, %fd30, 0d7FF0000000000000;
	mov.f64 	%fd143, %fd37;
	@%p31 bra 	BB5_42;

	abs.f64 	%fd38, %fd76;
	setp.gtu.f64	%p32, %fd38, 0d7FF0000000000000;
	mov.f64 	%fd142, %fd37;
	mov.f64 	%fd143, %fd142;
	@%p32 bra 	BB5_42;

	setp.eq.f64	%p33, %fd38, 0d7FF0000000000000;
	@%p33 bra 	BB5_41;
	bra.uni 	BB5_39;

BB5_41:
	setp.gt.f64	%p35, %fd30, 0d3FF0000000000000;
	selp.b32	%r36, 2146435072, 0, %p35;
	xor.b32  	%r37, %r36, 2146435072;
	setp.lt.s32	%p36, %r3, 0;
	selp.b32	%r38, %r37, %r36, %p36;
	setp.eq.f64	%p37, %fd55, 0dBFF0000000000000;
	selp.b32	%r39, 1072693248, %r38, %p37;
	mov.u32 	%r40, 0;
	mov.b64 	%fd143, {%r40, %r39};
	bra.uni 	BB5_42;

BB5_6:
	ld.local.f64 	%fd4, [%rd1+56];
	setp.gt.f64	%p7, %fd4, %fd55;
	mov.u64 	%rd36, 1;
	mov.u64 	%rd35, 0;
	mov.f64 	%fd138, %fd4;
	@%p7 bra 	BB5_27;

	setp.leu.f64	%p8, %fd137, 0d0000000000000000;
	mov.f64 	%fd161, %fd155;
	@%p8 bra 	BB5_9;

	ld.local.f64 	%fd161, [%rd1+112];

BB5_9:
	mov.f64 	%fd160, %fd161;
	ld.local.f64 	%fd7, [%rd1+64];
	setp.gt.f64	%p9, %fd7, %fd55;
	mov.u64 	%rd36, 2;
	mov.u64 	%rd35, 1;
	mov.f64 	%fd137, %fd4;
	mov.f64 	%fd138, %fd7;
	@%p9 bra 	BB5_27;

	setp.leu.f64	%p10, %fd4, 0d0000000000000000;
	@%p10 bra 	BB5_12;

	ld.local.f64 	%fd160, [%rd1+120];

BB5_12:
	mov.f64 	%fd159, %fd160;
	ld.local.f64 	%fd10, [%rd1+72];
	setp.gt.f64	%p11, %fd10, %fd55;
	mov.u64 	%rd36, 3;
	mov.u64 	%rd35, 2;
	mov.f64 	%fd137, %fd7;
	mov.f64 	%fd138, %fd10;
	@%p11 bra 	BB5_27;

	setp.leu.f64	%p12, %fd7, 0d0000000000000000;
	@%p12 bra 	BB5_15;

	ld.local.f64 	%fd159, [%rd1+128];

BB5_15:
	mov.f64 	%fd158, %fd159;
	ld.local.f64 	%fd13, [%rd1+80];
	setp.gt.f64	%p13, %fd13, %fd55;
	mov.u64 	%rd36, 4;
	mov.u64 	%rd35, 3;
	mov.f64 	%fd137, %fd10;
	mov.f64 	%fd138, %fd13;
	@%p13 bra 	BB5_27;

	setp.leu.f64	%p14, %fd10, 0d0000000000000000;
	@%p14 bra 	BB5_18;

	ld.local.f64 	%fd158, [%rd1+136];

BB5_18:
	mov.f64 	%fd157, %fd158;
	ld.local.f64 	%fd16, [%rd1+88];
	setp.gt.f64	%p15, %fd16, %fd55;
	mov.u64 	%rd36, 5;
	mov.u64 	%rd35, 4;
	mov.f64 	%fd137, %fd13;
	mov.f64 	%fd138, %fd16;
	@%p15 bra 	BB5_27;

	setp.leu.f64	%p16, %fd13, 0d0000000000000000;
	@%p16 bra 	BB5_21;

	ld.local.f64 	%fd157, [%rd1+144];

BB5_21:
	mov.f64 	%fd156, %fd157;
	ld.local.f64 	%fd19, [%rd1+96];
	setp.gt.f64	%p17, %fd19, %fd55;
	mov.u64 	%rd36, 6;
	mov.u64 	%rd35, 5;
	mov.f64 	%fd137, %fd16;
	mov.f64 	%fd138, %fd19;
	@%p17 bra 	BB5_27;

	setp.leu.f64	%p18, %fd16, 0d0000000000000000;
	@%p18 bra 	BB5_24;

	ld.local.f64 	%fd156, [%rd1+152];

BB5_24:
	mov.f64 	%fd155, %fd156;
	ld.local.f64 	%fd22, [%rd1+104];
	setp.gt.f64	%p19, %fd22, %fd55;
	mov.u64 	%rd36, 7;
	mov.u64 	%rd35, 6;
	mov.f64 	%fd137, %fd19;
	mov.f64 	%fd138, %fd22;
	@%p19 bra 	BB5_27;
	bra.uni 	BB5_25;

BB5_27:
	sub.f64 	%fd59, %fd138, %fd137;
	sub.f64 	%fd60, %fd55, %fd137;
	div.rn.f64 	%fd61, %fd60, %fd59;
	mov.f64 	%fd62, 0d3FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd61;
	shl.b64 	%rd29, %rd35, 3;
	add.s64 	%rd30, %rd1, 112;
	add.s64 	%rd31, %rd30, %rd29;
	ld.local.f64 	%fd64, [%rd31];
	shl.b64 	%rd32, %rd36, 3;
	add.s64 	%rd33, %rd30, %rd32;
	ld.local.f64 	%fd65, [%rd33];
	mul.f64 	%fd66, %fd61, %fd65;
	fma.rn.f64 	%fd155, %fd63, %fd64, %fd66;
	bra.uni 	BB5_54;

BB5_39:
	setp.neu.f64	%p34, %fd30, 0d7FF0000000000000;
	mov.f64 	%fd143, %fd36;
	@%p34 bra 	BB5_42;

	shr.s32 	%r30, %r3, 31;
	and.b32  	%r31, %r30, -2146435072;
	add.s32 	%r32, %r31, 2146435072;
	or.b32  	%r33, %r32, -2147483648;
	selp.b32	%r34, %r33, %r32, %p1;
	mov.u32 	%r35, 0;
	mov.b64 	%fd143, {%r35, %r34};

BB5_42:
	setp.eq.f64	%p38, %fd55, 0d3FF0000000000000;
	selp.f64	%fd80, 0d3FF0000000000000, %fd143, %p38;
	mul.f64 	%fd42, %fd29, %fd80;
	ld.const.f64 	%fd81, [dc_g];
	sqrt.rn.f64 	%fd43, %fd81;
	div.rn.f64 	%fd44, %fd55, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd44;
	}
	setp.gt.f64	%p39, %fd44, 0d0000000000000000;
	setp.lt.s32	%p40, %r53, 2146435072;
	and.pred  	%p41, %p39, %p40;
	@%p41 bra 	BB5_47;
	bra.uni 	BB5_43;

BB5_47:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r54, %temp}, %fd44;
	}
	mov.u32 	%r55, -1023;
	setp.gt.s32	%p45, %r53, 1048575;
	@%p45 bra 	BB5_49;

	mul.f64 	%fd84, %fd44, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd84;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r54, %temp}, %fd84;
	}
	mov.u32 	%r55, -1077;

BB5_49:
	shr.u32 	%r43, %r53, 20;
	add.s32 	%r56, %r55, %r43;
	and.b32  	%r44, %r53, -2146435073;
	or.b32  	%r45, %r44, 1072693248;
	mov.b64 	%fd146, {%r54, %r45};
	setp.lt.s32	%p46, %r45, 1073127583;
	@%p46 bra 	BB5_51;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd146;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd146;
	}
	add.s32 	%r48, %r47, -1048576;
	mov.b64 	%fd146, {%r46, %r48};
	add.s32 	%r56, %r56, 1;

BB5_51:
	add.f64 	%fd86, %fd146, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd85,%fd86;
	// inline asm
	neg.f64 	%fd87, %fd86;
	mov.f64 	%fd88, 0d3FF0000000000000;
	fma.rn.f64 	%fd89, %fd87, %fd85, %fd88;
	fma.rn.f64 	%fd90, %fd89, %fd89, %fd89;
	fma.rn.f64 	%fd91, %fd90, %fd85, %fd85;
	add.f64 	%fd92, %fd146, 0dBFF0000000000000;
	mul.f64 	%fd93, %fd92, %fd91;
	fma.rn.f64 	%fd94, %fd92, %fd91, %fd93;
	mul.f64 	%fd95, %fd94, %fd94;
	mov.f64 	%fd96, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd97, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd98, %fd97, %fd95, %fd96;
	mov.f64 	%fd99, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd100, %fd98, %fd95, %fd99;
	mov.f64 	%fd101, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd102, %fd100, %fd95, %fd101;
	mov.f64 	%fd103, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd104, %fd102, %fd95, %fd103;
	mov.f64 	%fd105, 0d3F624924923BE72D;
	fma.rn.f64 	%fd106, %fd104, %fd95, %fd105;
	mov.f64 	%fd107, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd108, %fd106, %fd95, %fd107;
	mov.f64 	%fd109, 0d3FB5555555555554;
	fma.rn.f64 	%fd110, %fd108, %fd95, %fd109;
	sub.f64 	%fd111, %fd92, %fd94;
	add.f64 	%fd112, %fd111, %fd111;
	neg.f64 	%fd113, %fd94;
	fma.rn.f64 	%fd114, %fd113, %fd92, %fd112;
	mul.f64 	%fd115, %fd91, %fd114;
	mul.f64 	%fd116, %fd95, %fd110;
	fma.rn.f64 	%fd117, %fd116, %fd94, %fd115;
	xor.b32  	%r49, %r56, -2147483648;
	mov.u32 	%r50, 1127219200;
	mov.b64 	%fd118, {%r49, %r50};
	mov.u32 	%r51, -2147483648;
	mov.b64 	%fd119, {%r51, %r50};
	sub.f64 	%fd120, %fd118, %fd119;
	mov.f64 	%fd121, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd122, %fd120, %fd121, %fd94;
	neg.f64 	%fd123, %fd120;
	fma.rn.f64 	%fd124, %fd123, %fd121, %fd122;
	sub.f64 	%fd125, %fd124, %fd94;
	sub.f64 	%fd126, %fd117, %fd125;
	mov.f64 	%fd127, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd128, %fd120, %fd127, %fd126;
	add.f64 	%fd147, %fd122, %fd128;
	bra.uni 	BB5_52;

BB5_43:
	abs.f64 	%fd82, %fd44;
	setp.gtu.f64	%p42, %fd82, 0d7FF0000000000000;
	@%p42 bra 	BB5_46;
	bra.uni 	BB5_44;

BB5_46:
	add.f64 	%fd147, %fd44, %fd44;
	bra.uni 	BB5_52;

BB5_44:
	setp.eq.f64	%p43, %fd44, 0d0000000000000000;
	mov.f64 	%fd147, 0dFFF0000000000000;
	@%p43 bra 	BB5_52;

	setp.eq.f64	%p44, %fd44, 0d7FF0000000000000;
	selp.f64	%fd147, %fd44, 0dFFF8000000000000, %p44;

BB5_52:
	add.f64 	%fd129, %fd147, 0dBFF0000000000000;
	mul.f64 	%fd130, %fd43, %fd129;
	div.rn.f64 	%fd52, %fd42, %fd130;
	ld.local.f64 	%fd53, [%rd1+8];
	setp.gt.f64	%p47, %fd52, %fd53;
	mov.f64 	%fd155, %fd52;
	@%p47 bra 	BB5_54;

	mov.f64 	%fd155, %fd53;

BB5_54:
	st.param.f64	[func_retval0+0], %fd155;
	ret;

BB5_25:
	setp.leu.f64	%p20, %fd19, 0d0000000000000000;
	@%p20 bra 	BB5_54;

	ld.local.f64 	%fd155, [%rd1+160];
	bra.uni 	BB5_54;
}

	// .globl	gpu_vectorCombine1Coeff
.visible .entry gpu_vectorCombine1Coeff(
	.param .u32 gpu_vectorCombine1Coeff_param_0,
	.param .u32 gpu_vectorCombine1Coeff_param_1,
	.param .f64 gpu_vectorCombine1Coeff_param_2,
	.param .u64 gpu_vectorCombine1Coeff_param_3,
	.param .u64 gpu_vectorCombine1Coeff_param_4,
	.param .u64 gpu_vectorCombine1Coeff_param_5
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<12>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r2, [gpu_vectorCombine1Coeff_param_1];
	ld.param.f64 	%fd1, [gpu_vectorCombine1Coeff_param_2];
	ld.param.u64 	%rd1, [gpu_vectorCombine1Coeff_param_3];
	ld.param.u64 	%rd2, [gpu_vectorCombine1Coeff_param_4];
	ld.param.u64 	%rd3, [gpu_vectorCombine1Coeff_param_5];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r6, %r4, %r3, %r5;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r10, %r7, %r8, %r9;
	ld.const.u32 	%r11, [dc_nyPadded];
	mad.lo.s32 	%r1, %r10, %r11, %r6;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB6_2;

	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f64 	%fd2, [%rd8];
	ld.global.f64 	%fd3, [%rd6];
	fma.rn.f64 	%fd4, %fd2, %fd1, %fd3;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd5;
	st.global.f64 	[%rd10], %fd4;

BB6_2:
	ret;
}

	// .globl	gpu_vectorCombine2Coeff
.visible .entry gpu_vectorCombine2Coeff(
	.param .u32 gpu_vectorCombine2Coeff_param_0,
	.param .u32 gpu_vectorCombine2Coeff_param_1,
	.param .f64 gpu_vectorCombine2Coeff_param_2,
	.param .f64 gpu_vectorCombine2Coeff_param_3,
	.param .u64 gpu_vectorCombine2Coeff_param_4,
	.param .u64 gpu_vectorCombine2Coeff_param_5,
	.param .u64 gpu_vectorCombine2Coeff_param_6
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<12>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r2, [gpu_vectorCombine2Coeff_param_1];
	ld.param.f64 	%fd1, [gpu_vectorCombine2Coeff_param_2];
	ld.param.f64 	%fd2, [gpu_vectorCombine2Coeff_param_3];
	ld.param.u64 	%rd1, [gpu_vectorCombine2Coeff_param_4];
	ld.param.u64 	%rd2, [gpu_vectorCombine2Coeff_param_5];
	ld.param.u64 	%rd3, [gpu_vectorCombine2Coeff_param_6];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r6, %r4, %r3, %r5;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r10, %r7, %r8, %r9;
	ld.const.u32 	%r11, [dc_nyPadded];
	mad.lo.s32 	%r1, %r10, %r11, %r6;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB7_2;

	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd3, [%rd6];
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f64 	%fd4, [%rd8];
	mul.f64 	%fd5, %fd4, %fd2;
	fma.rn.f64 	%fd6, %fd3, %fd1, %fd5;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd5;
	st.global.f64 	[%rd10], %fd6;

BB7_2:
	ret;
}

	// .globl	gpu_vectorCombine1Coeff3Fields
.visible .entry gpu_vectorCombine1Coeff3Fields(
	.param .u32 gpu_vectorCombine1Coeff3Fields_param_0,
	.param .u32 gpu_vectorCombine1Coeff3Fields_param_1,
	.param .f64 gpu_vectorCombine1Coeff3Fields_param_2,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_3,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_4,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_5,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_6,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_7,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_8,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_9,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_10,
	.param .u64 gpu_vectorCombine1Coeff3Fields_param_11
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<13>;
	.reg .f64 	%fd<11>;
	.reg .b64 	%rd<33>;


	ld.param.u32 	%r2, [gpu_vectorCombine1Coeff3Fields_param_1];
	ld.param.f64 	%fd1, [gpu_vectorCombine1Coeff3Fields_param_2];
	ld.param.u64 	%rd1, [gpu_vectorCombine1Coeff3Fields_param_3];
	ld.param.u64 	%rd2, [gpu_vectorCombine1Coeff3Fields_param_4];
	ld.param.u64 	%rd3, [gpu_vectorCombine1Coeff3Fields_param_5];
	ld.param.u64 	%rd4, [gpu_vectorCombine1Coeff3Fields_param_6];
	ld.param.u64 	%rd5, [gpu_vectorCombine1Coeff3Fields_param_7];
	ld.param.u64 	%rd6, [gpu_vectorCombine1Coeff3Fields_param_8];
	ld.param.u64 	%rd7, [gpu_vectorCombine1Coeff3Fields_param_9];
	ld.param.u64 	%rd8, [gpu_vectorCombine1Coeff3Fields_param_10];
	ld.param.u64 	%rd9, [gpu_vectorCombine1Coeff3Fields_param_11];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r10, %r7, %r8, %r9;
	ld.const.u32 	%r11, [dc_nyPadded];
	mad.lo.s32 	%r1, %r10, %r11, %r6;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB8_3;

	ld.const.u64 	%rd10, [dc_a];
	cvta.to.global.u64 	%rd11, %rd10;
	mul.wide.s32 	%rd12, %r1, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.u8 	%r12, [%rd13];
	setp.eq.s32	%p2, %r12, 255;
	@%p2 bra 	BB8_3;

	cvta.to.global.u64 	%rd14, %rd9;
	cvta.to.global.u64 	%rd15, %rd8;
	cvta.to.global.u64 	%rd16, %rd7;
	cvta.to.global.u64 	%rd17, %rd6;
	cvta.to.global.u64 	%rd18, %rd5;
	cvta.to.global.u64 	%rd19, %rd4;
	cvta.to.global.u64 	%rd20, %rd3;
	cvta.to.global.u64 	%rd21, %rd2;
	cvta.to.global.u64 	%rd22, %rd1;
	mul.wide.s32 	%rd23, %r1, 8;
	add.s64 	%rd24, %rd22, %rd23;
	add.s64 	%rd25, %rd21, %rd23;
	ld.global.f64 	%fd2, [%rd25];
	add.s64 	%rd26, %rd20, %rd23;
	ld.global.f64 	%fd3, [%rd26];
	add.s64 	%rd27, %rd18, %rd23;
	ld.global.f64 	%fd4, [%rd27];
	add.s64 	%rd28, %rd17, %rd23;
	ld.global.f64 	%fd5, [%rd28];
	add.s64 	%rd29, %rd19, %rd23;
	ld.global.f64 	%fd6, [%rd29];
	ld.global.f64 	%fd7, [%rd24];
	fma.rn.f64 	%fd8, %fd6, %fd1, %fd7;
	add.s64 	%rd30, %rd16, %rd23;
	st.global.f64 	[%rd30], %fd8;
	fma.rn.f64 	%fd9, %fd4, %fd1, %fd2;
	add.s64 	%rd31, %rd15, %rd23;
	st.global.f64 	[%rd31], %fd9;
	fma.rn.f64 	%fd10, %fd5, %fd1, %fd3;
	add.s64 	%rd32, %rd14, %rd23;
	st.global.f64 	[%rd32], %fd10;

BB8_3:
	ret;
}

	// .globl	gpu_vectorCombine2Coeff3Fields
.visible .entry gpu_vectorCombine2Coeff3Fields(
	.param .u32 gpu_vectorCombine2Coeff3Fields_param_0,
	.param .u32 gpu_vectorCombine2Coeff3Fields_param_1,
	.param .f64 gpu_vectorCombine2Coeff3Fields_param_2,
	.param .f64 gpu_vectorCombine2Coeff3Fields_param_3,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_4,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_5,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_6,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_7,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_8,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_9,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_10,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_11,
	.param .u64 gpu_vectorCombine2Coeff3Fields_param_12
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<13>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<33>;


	ld.param.u32 	%r2, [gpu_vectorCombine2Coeff3Fields_param_1];
	ld.param.f64 	%fd1, [gpu_vectorCombine2Coeff3Fields_param_2];
	ld.param.f64 	%fd2, [gpu_vectorCombine2Coeff3Fields_param_3];
	ld.param.u64 	%rd1, [gpu_vectorCombine2Coeff3Fields_param_4];
	ld.param.u64 	%rd2, [gpu_vectorCombine2Coeff3Fields_param_5];
	ld.param.u64 	%rd3, [gpu_vectorCombine2Coeff3Fields_param_6];
	ld.param.u64 	%rd4, [gpu_vectorCombine2Coeff3Fields_param_7];
	ld.param.u64 	%rd5, [gpu_vectorCombine2Coeff3Fields_param_8];
	ld.param.u64 	%rd6, [gpu_vectorCombine2Coeff3Fields_param_9];
	ld.param.u64 	%rd7, [gpu_vectorCombine2Coeff3Fields_param_10];
	ld.param.u64 	%rd8, [gpu_vectorCombine2Coeff3Fields_param_11];
	ld.param.u64 	%rd9, [gpu_vectorCombine2Coeff3Fields_param_12];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r10, %r7, %r8, %r9;
	ld.const.u32 	%r11, [dc_nyPadded];
	mad.lo.s32 	%r1, %r10, %r11, %r6;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB9_3;

	ld.const.u64 	%rd10, [dc_a];
	cvta.to.global.u64 	%rd11, %rd10;
	mul.wide.s32 	%rd12, %r1, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.u8 	%r12, [%rd13];
	setp.eq.s32	%p2, %r12, 255;
	@%p2 bra 	BB9_3;

	cvta.to.global.u64 	%rd14, %rd9;
	cvta.to.global.u64 	%rd15, %rd8;
	cvta.to.global.u64 	%rd16, %rd7;
	cvta.to.global.u64 	%rd17, %rd6;
	cvta.to.global.u64 	%rd18, %rd5;
	cvta.to.global.u64 	%rd19, %rd4;
	cvta.to.global.u64 	%rd20, %rd3;
	cvta.to.global.u64 	%rd21, %rd2;
	cvta.to.global.u64 	%rd22, %rd1;
	mul.wide.s32 	%rd23, %r1, 8;
	add.s64 	%rd24, %rd22, %rd23;
	add.s64 	%rd25, %rd21, %rd23;
	ld.global.f64 	%fd3, [%rd25];
	add.s64 	%rd26, %rd20, %rd23;
	ld.global.f64 	%fd4, [%rd26];
	add.s64 	%rd27, %rd18, %rd23;
	ld.global.f64 	%fd5, [%rd27];
	add.s64 	%rd28, %rd17, %rd23;
	ld.global.f64 	%fd6, [%rd28];
	ld.global.f64 	%fd7, [%rd24];
	add.s64 	%rd29, %rd19, %rd23;
	ld.global.f64 	%fd8, [%rd29];
	mul.f64 	%fd9, %fd8, %fd2;
	fma.rn.f64 	%fd10, %fd7, %fd1, %fd9;
	add.s64 	%rd30, %rd16, %rd23;
	st.global.f64 	[%rd30], %fd10;
	mul.f64 	%fd11, %fd5, %fd2;
	fma.rn.f64 	%fd12, %fd3, %fd1, %fd11;
	add.s64 	%rd31, %rd15, %rd23;
	st.global.f64 	[%rd31], %fd12;
	mul.f64 	%fd13, %fd6, %fd2;
	fma.rn.f64 	%fd14, %fd4, %fd1, %fd13;
	add.s64 	%rd32, %rd14, %rd23;
	st.global.f64 	[%rd32], %fd14;

BB9_3:
	ret;
}

	// .globl	gpu_calcResidualSoilCapacity
.visible .entry gpu_calcResidualSoilCapacity(
	.param .u32 gpu_calcResidualSoilCapacity_param_0,
	.param .u64 gpu_calcResidualSoilCapacity_param_1,
	.param .u64 gpu_calcResidualSoilCapacity_param_2
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd2, [gpu_calcResidualSoilCapacity_param_1];
	ld.param.u64 	%rd3, [gpu_calcResidualSoilCapacity_param_2];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r7, %r8, %r9;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r10, [dc_ny];
	add.s32 	%r11, %r10, -2;
	setp.lt.s32	%p2, %r1, %r11;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r12, [dc_nx];
	add.s32 	%r13, %r12, -2;
	setp.lt.s32	%p6, %r2, %r13;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB10_5;
	bra.uni 	BB10_1;

BB10_1:
	ld.const.u32 	%r14, [dc_nyPadded];
	mad.lo.s32 	%r3, %r14, %r2, %r1;
	ld.const.u64 	%rd4, [dc_a];
	cvta.to.global.u64 	%rd5, %rd4;
	mul.wide.s32 	%rd6, %r3, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u8 	%r15, [%rd7];
	setp.ne.s32	%p8, %r15, 0;
	@%p8 bra 	BB10_5;

	cvta.to.global.u64 	%rd8, %rd3;
	ld.const.u64 	%rd9, [dc_sc];
	cvta.to.global.u64 	%rd10, %rd9;
	mul.wide.s32 	%rd11, %r3, 8;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.f64 	%fd1, [%rd12];
	setp.lt.f64	%p9, %fd1, 0d40F869F000000000;
	add.s64 	%rd1, %rd8, %rd11;
	@%p9 bra 	BB10_4;
	bra.uni 	BB10_3;

BB10_4:
	cvta.to.global.u64 	%rd14, %rd2;
	add.s64 	%rd16, %rd14, %rd11;
	ld.global.f64 	%fd2, [%rd16];
	sub.f64 	%fd3, %fd1, %fd2;
	st.global.f64 	[%rd1], %fd3;
	bra.uni 	BB10_5;

BB10_3:
	mov.u64 	%rd13, 4681608292164698112;
	st.global.u64 	[%rd1], %rd13;

BB10_5:
	ret;
}

	// .globl	gpu_extractEvaluationGroupData
.visible .entry gpu_extractEvaluationGroupData(
	.param .u32 gpu_extractEvaluationGroupData_param_0,
	.param .u32 gpu_extractEvaluationGroupData_param_1,
	.param .u32 gpu_extractEvaluationGroupData_param_2,
	.param .u64 gpu_extractEvaluationGroupData_param_3,
	.param .u64 gpu_extractEvaluationGroupData_param_4,
	.param .u64 gpu_extractEvaluationGroupData_param_5,
	.param .u64 gpu_extractEvaluationGroupData_param_6,
	.param .u64 gpu_extractEvaluationGroupData_param_7,
	.param .u64 gpu_extractEvaluationGroupData_param_8,
	.param .u64 gpu_extractEvaluationGroupData_param_9
)
{
	.reg .pred 	%p<53>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<109>;
	.reg .b64 	%rd<71>;


	ld.param.u32 	%r15, [gpu_extractEvaluationGroupData_param_2];
	ld.param.u64 	%rd8, [gpu_extractEvaluationGroupData_param_3];
	ld.param.u64 	%rd9, [gpu_extractEvaluationGroupData_param_4];
	ld.param.u64 	%rd10, [gpu_extractEvaluationGroupData_param_5];
	ld.param.u64 	%rd12, [gpu_extractEvaluationGroupData_param_7];
	ld.param.u64 	%rd13, [gpu_extractEvaluationGroupData_param_8];
	ld.param.u64 	%rd14, [gpu_extractEvaluationGroupData_param_9];
	mov.u32 	%r16, %ntid.y;
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %tid.y;
	mad.lo.s32 	%r43, %r16, %r17, %r18;
	setp.ge.s32	%p3, %r43, %r15;
	@%p3 bra 	BB11_51;

	ld.const.u64 	%rd15, [dc_zc];
	cvta.to.global.u64 	%rd1, %rd15;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.const.u64 	%rd16, [dc_a];
	cvta.to.global.u64 	%rd2, %rd16;
	ld.const.u64 	%rd3, [dc_phi2];
	ld.const.u64 	%rd4, [dc_phi4];
	cvta.to.global.u64 	%rd17, %rd8;
	cvta.to.global.u64 	%rd20, %rd9;
	cvta.to.global.u64 	%rd22, %rd14;
	cvta.to.global.u64 	%rd43, %rd12;
	cvta.to.global.u64 	%rd48, %rd13;
	cvta.to.global.u64 	%rd54, %rd10;
	bra.uni 	BB11_2;

BB11_7:
	setp.eq.s32	%p14, %r9, 255;
	mov.f64 	%fd105, 0d0000000000000000;
	@%p14 bra 	BB11_11;

	setp.gt.f64	%p15, %fd5, %fd1;
	selp.f64	%fd105, %fd9, 0d0000000000000000, %p15;

BB11_11:
	and.b32  	%r26, %r11, 255;
	setp.ne.s32	%p19, %r26, 255;
	setp.gt.f64	%p20, %fd6, %fd1;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	BB11_14;
	bra.uni 	BB11_12;

BB11_14:
	setp.ne.s32	%p24, %r12, 255;
	setp.gt.f64	%p25, %fd7, %fd1;
	and.pred  	%p26, %p25, %p24;
	@!%p26 bra 	BB11_16;
	bra.uni 	BB11_15;

BB11_15:
	add.f64 	%fd30, %fd106, %fd11;
	mul.f64 	%fd106, %fd30, 0d3FE0000000000000;
	bra.uni 	BB11_16;

BB11_12:
	setp.eq.s32	%p22, %r12, 255;
	mov.f64 	%fd106, 0d0000000000000000;
	@%p22 bra 	BB11_16;

	setp.gt.f64	%p23, %fd7, %fd1;
	selp.f64	%fd106, %fd11, 0d0000000000000000, %p23;

BB11_16:
	shl.b64 	%rd55, %rd5, 2;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.u32 	%r27, [%rd56];
	setp.gt.s32	%p27, %r27, 20;
	@%p27 bra 	BB11_26;

	setp.gt.s32	%p35, %r27, 3;
	@%p35 bra 	BB11_22;

	setp.eq.s32	%p39, %r27, 1;
	@%p39 bra 	BB11_48;

	setp.eq.s32	%p40, %r27, 2;
	@%p40 bra 	BB11_47;
	bra.uni 	BB11_20;

BB11_47:
	st.global.f64 	[%rd6], %fd4;
	bra.uni 	BB11_50;

BB11_26:
	setp.gt.s32	%p28, %r27, 31;
	@%p28 bra 	BB11_31;

	setp.eq.s32	%p32, %r27, 21;
	@%p32 bra 	BB11_38;

	setp.eq.s32	%p33, %r27, 22;
	@%p33 bra 	BB11_37;
	bra.uni 	BB11_29;

BB11_37:
	mul.f64 	%fd35, %fd106, %fd106;
	fma.rn.f64 	%fd36, %fd105, %fd105, %fd35;
	sqrt.rn.f64 	%fd37, %fd36;
	mul.f64 	%fd38, %fd4, %fd37;
	st.global.f64 	[%rd6], %fd38;
	bra.uni 	BB11_50;

BB11_22:
	setp.eq.s32	%p36, %r27, 4;
	@%p36 bra 	BB11_46;

	setp.eq.s32	%p37, %r27, 10;
	@%p37 bra 	BB11_45;
	bra.uni 	BB11_24;

BB11_45:
	add.f64 	%fd103, %fd3, %fd4;
	st.global.f64 	[%rd6], %fd103;
	bra.uni 	BB11_50;

BB11_31:
	setp.eq.s32	%p29, %r27, 32;
	@%p29 bra 	BB11_36;

	setp.eq.s32	%p30, %r27, 33;
	@%p30 bra 	BB11_35;
	bra.uni 	BB11_33;

BB11_35:
	cvta.to.global.u64 	%rd60, %rd4;
	mul.wide.s32 	%rd61, %r10, 8;
	add.s64 	%rd62, %rd60, %rd61;
	ld.global.f64 	%fd32, [%rd62];
	st.global.f64 	[%rd6], %fd32;
	bra.uni 	BB11_50;

BB11_48:
	st.global.f64 	[%rd6], %fd3;
	bra.uni 	BB11_50;

BB11_20:
	setp.eq.s32	%p41, %r27, 3;
	@%p41 bra 	BB11_21;
	bra.uni 	BB11_49;

BB11_21:
	st.global.f64 	[%rd6], %fd105;
	bra.uni 	BB11_50;

BB11_38:
	abs.f64 	%fd39, %fd105;
	setp.lt.f64	%p42, %fd39, 0d3EB0C6F7A0B5ED8D;
	@%p42 bra 	BB11_42;
	bra.uni 	BB11_39;

BB11_42:
	setp.gt.f64	%p47, %fd106, 0d3EB0C6F7A0B5ED8D;
	mov.f64 	%fd108, 0d4056800000000000;
	@%p47 bra 	BB11_44;

	setp.lt.f64	%p48, %fd106, 0dBEB0C6F7A0B5ED8D;
	selp.f64	%fd108, 0dC056800000000000, 0d0000000000000000, %p48;
	bra.uni 	BB11_44;

BB11_29:
	setp.eq.s32	%p34, %r27, 31;
	@%p34 bra 	BB11_30;
	bra.uni 	BB11_49;

BB11_30:
	cvta.to.global.u64 	%rd66, %rd3;
	mul.wide.s32 	%rd67, %r8, 8;
	add.s64 	%rd68, %rd66, %rd67;
	ld.global.f64 	%fd34, [%rd68];
	st.global.f64 	[%rd6], %fd34;
	bra.uni 	BB11_50;

BB11_46:
	st.global.f64 	[%rd6], %fd106;
	bra.uni 	BB11_50;

BB11_24:
	setp.eq.s32	%p38, %r27, 20;
	@%p38 bra 	BB11_25;
	bra.uni 	BB11_49;

BB11_25:
	mul.f64 	%fd100, %fd106, %fd106;
	fma.rn.f64 	%fd101, %fd105, %fd105, %fd100;
	sqrt.rn.f64 	%fd102, %fd101;
	st.global.f64 	[%rd6], %fd102;
	bra.uni 	BB11_50;

BB11_36:
	cvta.to.global.u64 	%rd63, %rd3;
	shl.b64 	%rd64, %rd7, 3;
	add.s64 	%rd65, %rd63, %rd64;
	ld.global.f64 	%fd33, [%rd65];
	st.global.f64 	[%rd6], %fd33;
	bra.uni 	BB11_50;

BB11_33:
	setp.ne.s32	%p31, %r27, 34;
	@%p31 bra 	BB11_49;

	cvta.to.global.u64 	%rd57, %rd4;
	shl.b64 	%rd58, %rd7, 3;
	add.s64 	%rd59, %rd57, %rd58;
	ld.global.f64 	%fd31, [%rd59];
	st.global.f64 	[%rd6], %fd31;
	bra.uni 	BB11_50;

BB11_49:
	mov.u64 	%rd69, 0;
	st.global.u64 	[%rd6], %rd69;
	bra.uni 	BB11_50;

BB11_39:
	div.rn.f64 	%fd18, %fd106, %fd105;
	abs.f64 	%fd19, %fd18;
	setp.leu.f64	%p43, %fd19, 0d3FF0000000000000;
	mov.f64 	%fd107, %fd19;
	@%p43 bra 	BB11_41;

	// inline asm
	rcp.approx.ftz.f64 %fd40,%fd19;
	// inline asm
	neg.f64 	%fd42, %fd19;
	mov.f64 	%fd43, 0d3FF0000000000000;
	fma.rn.f64 	%fd44, %fd42, %fd40, %fd43;
	fma.rn.f64 	%fd45, %fd44, %fd44, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd40, %fd40;
	setp.eq.f64	%p44, %fd19, 0d7FF0000000000000;
	selp.f64	%fd20, 0d0000000000000000, %fd46, %p44;
	mov.f64 	%fd107, %fd20;

BB11_41:
	mov.f64 	%fd21, %fd107;
	mul.f64 	%fd47, %fd21, %fd21;
	mov.f64 	%fd48, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd49, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd50, %fd49, %fd47, %fd48;
	mov.f64 	%fd51, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd52, %fd50, %fd47, %fd51;
	mov.f64 	%fd53, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd54, %fd52, %fd47, %fd53;
	mov.f64 	%fd55, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd56, %fd54, %fd47, %fd55;
	mov.f64 	%fd57, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd58, %fd56, %fd47, %fd57;
	mov.f64 	%fd59, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd60, %fd58, %fd47, %fd59;
	mov.f64 	%fd61, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd62, %fd60, %fd47, %fd61;
	mov.f64 	%fd63, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd64, %fd62, %fd47, %fd63;
	mov.f64 	%fd65, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd66, %fd64, %fd47, %fd65;
	mov.f64 	%fd67, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd68, %fd66, %fd47, %fd67;
	mov.f64 	%fd69, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd70, %fd68, %fd47, %fd69;
	mov.f64 	%fd71, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd72, %fd70, %fd47, %fd71;
	mov.f64 	%fd73, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd74, %fd72, %fd47, %fd73;
	mov.f64 	%fd75, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd76, %fd74, %fd47, %fd75;
	mov.f64 	%fd77, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd78, %fd76, %fd47, %fd77;
	mov.f64 	%fd79, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd80, %fd78, %fd47, %fd79;
	mov.f64 	%fd81, 0d3FC99999999840D2;
	fma.rn.f64 	%fd82, %fd80, %fd47, %fd81;
	mov.f64 	%fd83, 0dBFD555555555544C;
	fma.rn.f64 	%fd84, %fd82, %fd47, %fd83;
	mul.f64 	%fd85, %fd47, %fd84;
	fma.rn.f64 	%fd86, %fd85, %fd21, %fd21;
	mov.f64 	%fd87, 0d3FF921FB54442D18;
	sub.f64 	%fd88, %fd87, %fd86;
	setp.gt.f64	%p45, %fd19, 0d3FF0000000000000;
	selp.f64	%fd89, %fd88, %fd86, %p45;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd89;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd89;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd18;
	}
	and.b32  	%r31, %r30, -2147483648;
	or.b32  	%r32, %r29, %r31;
	mov.b64 	%fd90, {%r28, %r32};
	mul.f64 	%fd91, %fd90, 0d404CA5DC1A63C1F8;
	add.f64 	%fd92, %fd91, 0d4066800000000000;
	setp.lt.f64	%p46, %fd105, 0d0000000000000000;
	selp.f64	%fd108, %fd92, %fd91, %p46;

BB11_44:
	mov.f64 	%fd94, 0d4056800000000000;
	sub.f64 	%fd95, %fd94, %fd108;
	setp.lt.f64	%p49, %fd95, 0d0000000000000000;
	add.f64 	%fd96, %fd95, 0d4076800000000000;
	selp.f64	%fd97, %fd96, %fd95, %p49;
	setp.gt.f64	%p50, %fd97, 0d4076800000000000;
	add.f64 	%fd98, %fd97, 0dC076800000000000;
	selp.f64	%fd99, %fd98, %fd97, %p50;
	st.global.f64 	[%rd6], %fd99;
	bra.uni 	BB11_50;

BB11_2:
	ld.const.u32 	%r41, [dc_nx];
	add.s32 	%r40, %r41, -2;
	ld.const.u32 	%r39, [dc_ny];
	add.s32 	%r38, %r39, -2;
	ld.param.u32 	%r37, [gpu_extractEvaluationGroupData_param_1];
	cvt.s64.s32	%rd5, %r43;
	mul.wide.s32 	%rd18, %r43, 4;
	add.s64 	%rd19, %rd17, %rd18;
	add.s64 	%rd21, %rd20, %rd18;
	ld.global.u32 	%r21, [%rd21];
	sub.s32 	%r6, %r21, %r37;
	ld.global.u32 	%r7, [%rd19];
	setp.gt.s32	%p4, %r7, 1;
	setp.lt.s32	%p5, %r7, %r38;
	and.pred  	%p6, %p4, %p5;
	setp.gt.s32	%p7, %r6, 1;
	and.pred  	%p8, %p6, %p7;
	setp.lt.s32	%p9, %r6, %r40;
	and.pred  	%p10, %p8, %p9;
	mul.wide.s32 	%rd23, %r43, 8;
	add.s64 	%rd6, %rd22, %rd23;
	@%p10 bra 	BB11_4;
	bra.uni 	BB11_3;

BB11_4:
	ld.const.f64 	%fd104, [dc_dryDepthThreshold];
	ld.param.u64 	%rd70, [gpu_extractEvaluationGroupData_param_6];
	ld.const.u32 	%r42, [dc_nyPadded];
	mad.lo.s32 	%r22, %r42, %r6, %r7;
	cvt.s64.s32	%rd7, %r22;
	mul.wide.s32 	%rd25, %r22, 8;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.f64 	%fd3, [%rd26];
	cvta.to.global.u64 	%rd27, %rd70;
	add.s64 	%rd28, %rd27, %rd25;
	ld.global.f64 	%fd25, [%rd28];
	setp.gt.f64	%p12, %fd25, %fd1;
	selp.f64	%fd4, %fd25, %fd104, %p12;
	sub.s32 	%r8, %r22, %r42;
	mul.wide.u32 	%rd29, %r8, 4;
	add.s64 	%rd30, %rd2, %rd29;
	ld.global.u8 	%r23, [%rd30];
	add.s32 	%r24, %r42, %r22;
	mul.wide.u32 	%rd31, %r24, 4;
	add.s64 	%rd32, %rd2, %rd31;
	ld.global.u8 	%r9, [%rd32];
	add.s32 	%r10, %r22, -1;
	mul.wide.u32 	%rd33, %r10, 4;
	add.s64 	%rd34, %rd2, %rd33;
	ld.global.u32 	%r11, [%rd34];
	add.s32 	%r25, %r22, 1;
	mul.wide.u32 	%rd35, %r25, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.u8 	%r12, [%rd36];
	mul.wide.u32 	%rd37, %r24, 8;
	add.s64 	%rd38, %rd27, %rd37;
	ld.global.f64 	%fd5, [%rd38];
	mul.wide.u32 	%rd39, %r10, 8;
	add.s64 	%rd40, %rd27, %rd39;
	ld.global.f64 	%fd6, [%rd40];
	mul.wide.u32 	%rd41, %r25, 8;
	add.s64 	%rd42, %rd27, %rd41;
	ld.global.f64 	%fd7, [%rd42];
	mul.wide.u32 	%rd44, %r8, 8;
	add.s64 	%rd45, %rd43, %rd44;
	ld.global.f64 	%fd105, [%rd45];
	mul.wide.u32 	%rd46, %r22, 8;
	add.s64 	%rd47, %rd43, %rd46;
	ld.global.f64 	%fd9, [%rd47];
	add.s64 	%rd49, %rd48, %rd39;
	ld.global.f64 	%fd106, [%rd49];
	add.s64 	%rd50, %rd48, %rd46;
	ld.global.f64 	%fd11, [%rd50];
	setp.eq.s32	%p13, %r23, 255;
	mov.pred 	%p52, 0;
	@%p13 bra 	BB11_6;

	add.s64 	%rd53, %rd27, %rd44;
	ld.global.f64 	%fd26, [%rd53];
	setp.gt.f64	%p52, %fd26, %fd1;

BB11_6:
	@%p52 bra 	BB11_9;
	bra.uni 	BB11_7;

BB11_9:
	setp.ne.s32	%p16, %r9, 255;
	setp.gt.f64	%p17, %fd5, %fd1;
	and.pred  	%p18, %p17, %p16;
	@!%p18 bra 	BB11_11;
	bra.uni 	BB11_10;

BB11_10:
	add.f64 	%fd28, %fd105, %fd9;
	mul.f64 	%fd105, %fd28, 0d3FE0000000000000;
	bra.uni 	BB11_11;

BB11_3:
	mov.u64 	%rd24, 0;
	st.global.u64 	[%rd6], %rd24;

BB11_50:
	ld.param.u32 	%r36, [gpu_extractEvaluationGroupData_param_2];
	mov.u32 	%r35, %ntid.y;
	mov.u32 	%r33, %ntid.x;
	mad.lo.s32 	%r43, %r33, %r35, %r43;
	setp.lt.s32	%p51, %r43, %r36;
	@%p51 bra 	BB11_2;

BB11_51:
	ret;
}

	// .globl	gpu_extractpoData
.visible .entry gpu_extractpoData(
	.param .u32 gpu_extractpoData_param_0,
	.param .u32 gpu_extractpoData_param_1,
	.param .u32 gpu_extractpoData_param_2,
	.param .u32 gpu_extractpoData_param_3,
	.param .u64 gpu_extractpoData_param_4,
	.param .u64 gpu_extractpoData_param_5,
	.param .u64 gpu_extractpoData_param_6,
	.param .u64 gpu_extractpoData_param_7,
	.param .u64 gpu_extractpoData_param_8,
	.param .u64 gpu_extractpoData_param_9,
	.param .u64 gpu_extractpoData_param_10
)
{
	.reg .pred 	%p<51>;
	.reg .b32 	%r<46>;
	.reg .f64 	%fd<118>;
	.reg .b64 	%rd<77>;


	ld.param.u32 	%r14, [gpu_extractpoData_param_3];
	ld.param.u64 	%rd13, [gpu_extractpoData_param_4];
	ld.param.u64 	%rd14, [gpu_extractpoData_param_5];
	ld.param.u64 	%rd15, [gpu_extractpoData_param_6];
	ld.param.u64 	%rd16, [gpu_extractpoData_param_7];
	ld.param.u64 	%rd17, [gpu_extractpoData_param_8];
	ld.param.u64 	%rd18, [gpu_extractpoData_param_9];
	ld.param.u64 	%rd19, [gpu_extractpoData_param_10];
	mov.u32 	%r15, %tid.x;
	mov.u32 	%r16, %ntid.y;
	mov.u32 	%r17, %tid.y;
	mad.lo.s32 	%r45, %r16, %r15, %r17;
	setp.ge.s32	%p3, %r45, %r14;
	@%p3 bra 	BB12_45;

	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.const.u64 	%rd20, [dc_a];
	cvta.to.global.u64 	%rd1, %rd20;
	ld.const.u64 	%rd21, [dc_zc];
	cvta.to.global.u64 	%rd2, %rd21;
	ld.const.u64 	%rd22, [dc_phi2];
	cvta.to.global.u64 	%rd3, %rd22;
	ld.const.u64 	%rd23, [dc_phi4];
	cvta.to.global.u64 	%rd4, %rd23;
	ld.const.u64 	%rd24, [dc_rf];
	cvta.to.global.u64 	%rd5, %rd24;
	ld.const.u64 	%rd25, [dc_sa];
	cvta.to.global.u64 	%rd6, %rd25;
	ld.const.u32 	%r5, [dc_switches];
	ld.const.u64 	%rd26, [dc_sx];
	cvta.to.global.u64 	%rd7, %rd26;
	ld.const.u64 	%rd27, [dc_ir];
	cvta.to.global.u64 	%rd8, %rd27;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd31, %rd14;
	cvta.to.global.u64 	%rd33, %rd19;
	cvta.to.global.u64 	%rd36, %rd16;
	cvta.to.global.u64 	%rd54, %rd17;
	cvta.to.global.u64 	%rd58, %rd18;
	cvta.to.global.u64 	%rd61, %rd15;

BB12_2:
	ld.const.u32 	%r43, [dc_nx];
	add.s32 	%r42, %r43, -2;
	ld.const.u32 	%r41, [dc_ny];
	add.s32 	%r40, %r41, -2;
	ld.param.u32 	%r39, [gpu_extractpoData_param_2];
	cvt.s64.s32	%rd9, %r45;
	mul.wide.s32 	%rd29, %r45, 4;
	add.s64 	%rd30, %rd28, %rd29;
	add.s64 	%rd32, %rd31, %rd29;
	ld.global.u32 	%r20, [%rd32];
	sub.s32 	%r7, %r20, %r39;
	ld.global.u32 	%r8, [%rd30];
	setp.gt.s32	%p4, %r8, 1;
	setp.lt.s32	%p5, %r8, %r40;
	and.pred  	%p6, %p4, %p5;
	setp.gt.s32	%p7, %r7, 1;
	and.pred  	%p8, %p6, %p7;
	setp.lt.s32	%p9, %r7, %r42;
	and.pred  	%p10, %p8, %p9;
	mul.wide.s32 	%rd34, %r45, 8;
	add.s64 	%rd10, %rd33, %rd34;
	@%p10 bra 	BB12_4;
	bra.uni 	BB12_3;

BB12_4:
	ld.const.f64 	%fd108, [dc_dryDepthThreshold];
	ld.const.u32 	%r44, [dc_nyPadded];
	mad.lo.s32 	%r21, %r44, %r7, %r8;
	cvt.s64.s32	%rd11, %r21;
	mul.wide.s32 	%rd37, %r21, 8;
	add.s64 	%rd38, %rd36, %rd37;
	ld.global.f64 	%fd34, [%rd38];
	setp.gt.f64	%p12, %fd34, %fd1;
	selp.f64	%fd3, %fd34, %fd108, %p12;
	sub.s32 	%r22, %r21, %r44;
	mul.wide.u32 	%rd39, %r22, 4;
	add.s64 	%rd40, %rd1, %rd39;
	ld.global.u8 	%r23, [%rd40];
	add.s32 	%r24, %r44, %r21;
	mul.wide.u32 	%rd41, %r24, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.global.u8 	%r9, [%rd42];
	add.s32 	%r25, %r21, -1;
	mul.wide.u32 	%rd43, %r25, 4;
	add.s64 	%rd44, %rd1, %rd43;
	ld.global.u8 	%r10, [%rd44];
	add.s32 	%r26, %r21, 1;
	mul.wide.u32 	%rd45, %r26, 4;
	add.s64 	%rd46, %rd1, %rd45;
	ld.global.u8 	%r11, [%rd46];
	mul.wide.u32 	%rd47, %r22, 8;
	add.s64 	%rd12, %rd36, %rd47;
	mul.wide.u32 	%rd48, %r24, 8;
	add.s64 	%rd49, %rd36, %rd48;
	ld.global.f64 	%fd4, [%rd49];
	mul.wide.u32 	%rd50, %r25, 8;
	add.s64 	%rd51, %rd36, %rd50;
	ld.global.f64 	%fd5, [%rd51];
	mul.wide.u32 	%rd52, %r26, 8;
	add.s64 	%rd53, %rd36, %rd52;
	ld.global.f64 	%fd6, [%rd53];
	add.s64 	%rd55, %rd54, %rd47;
	ld.global.f64 	%fd117, [%rd55];
	mul.wide.u32 	%rd56, %r21, 8;
	add.s64 	%rd57, %rd54, %rd56;
	ld.global.f64 	%fd8, [%rd57];
	add.s64 	%rd59, %rd58, %rd50;
	ld.global.f64 	%fd115, [%rd59];
	add.s64 	%rd60, %rd58, %rd56;
	ld.global.f64 	%fd10, [%rd60];
	setp.eq.s32	%p13, %r23, 255;
	mov.pred 	%p50, 0;
	@%p13 bra 	BB12_6;

	ld.global.f64 	%fd35, [%rd12];
	setp.gt.f64	%p50, %fd35, %fd1;

BB12_6:
	@%p50 bra 	BB12_9;
	bra.uni 	BB12_7;

BB12_9:
	setp.ne.s32	%p16, %r9, 255;
	setp.gt.f64	%p17, %fd4, %fd1;
	and.pred  	%p18, %p17, %p16;
	@!%p18 bra 	BB12_11;
	bra.uni 	BB12_10;

BB12_10:
	add.f64 	%fd37, %fd117, %fd8;
	mul.f64 	%fd117, %fd37, 0d3FE0000000000000;
	bra.uni 	BB12_11;

BB12_3:
	mov.u64 	%rd35, 0;
	st.global.u64 	[%rd10], %rd35;
	bra.uni 	BB12_44;

BB12_7:
	setp.eq.s32	%p14, %r9, 255;
	mov.f64 	%fd117, 0d0000000000000000;
	@%p14 bra 	BB12_11;

	setp.gt.f64	%p15, %fd4, %fd1;
	selp.f64	%fd117, %fd8, 0d0000000000000000, %p15;

BB12_11:
	mov.f64 	%fd13, %fd117;
	setp.ne.s32	%p19, %r10, 255;
	setp.gt.f64	%p20, %fd5, %fd1;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	BB12_14;
	bra.uni 	BB12_12;

BB12_14:
	setp.ne.s32	%p24, %r11, 255;
	setp.gt.f64	%p25, %fd6, %fd1;
	and.pred  	%p26, %p25, %p24;
	@!%p26 bra 	BB12_16;
	bra.uni 	BB12_15;

BB12_15:
	add.f64 	%fd39, %fd115, %fd10;
	mul.f64 	%fd115, %fd39, 0d3FE0000000000000;
	bra.uni 	BB12_16;

BB12_12:
	setp.eq.s32	%p22, %r11, 255;
	mov.f64 	%fd115, 0d0000000000000000;
	@%p22 bra 	BB12_16;

	setp.gt.f64	%p23, %fd6, %fd1;
	selp.f64	%fd115, %fd10, 0d0000000000000000, %p23;

BB12_16:
	mov.f64 	%fd16, %fd115;
	shl.b64 	%rd62, %rd9, 2;
	add.s64 	%rd63, %rd61, %rd62;
	ld.global.u32 	%r27, [%rd63];
	setp.gt.s32	%p27, %r27, 24;
	@%p27 bra 	BB12_24;

	setp.gt.s32	%p33, %r27, 22;
	@%p33 bra 	BB12_21;

	setp.eq.s32	%p36, %r27, 10;
	@%p36 bra 	BB12_42;
	bra.uni 	BB12_19;

BB12_42:
	shl.b64 	%rd75, %rd11, 3;
	add.s64 	%rd76, %rd2, %rd75;
	ld.global.f64 	%fd106, [%rd76];
	add.f64 	%fd114, %fd3, %fd106;
	bra.uni 	BB12_43;

BB12_24:
	setp.gt.s32	%p28, %r27, 31;
	@%p28 bra 	BB12_28;

	setp.eq.s32	%p31, %r27, 25;
	@%p31 bra 	BB12_35;
	bra.uni 	BB12_26;

BB12_35:
	abs.f64 	%fd44, %fd13;
	setp.lt.f64	%p40, %fd44, 0d3EB0C6F7A0B5ED8D;
	@%p40 bra 	BB12_39;
	bra.uni 	BB12_36;

BB12_39:
	setp.gt.f64	%p45, %fd16, 0d3EB0C6F7A0B5ED8D;
	mov.f64 	%fd110, 0d4056800000000000;
	@%p45 bra 	BB12_41;

	setp.lt.f64	%p46, %fd16, 0dBEB0C6F7A0B5ED8D;
	selp.f64	%fd110, 0dC056800000000000, 0d0000000000000000, %p46;
	bra.uni 	BB12_41;

BB12_21:
	setp.eq.s32	%p34, %r27, 23;
	mov.f64 	%fd114, %fd13;
	@%p34 bra 	BB12_43;

	setp.eq.s32	%p35, %r27, 24;
	mov.f64 	%fd114, %fd16;
	@%p35 bra 	BB12_43;
	bra.uni 	BB12_23;

BB12_28:
	setp.eq.s32	%p29, %r27, 32;
	@%p29 bra 	BB12_34;
	bra.uni 	BB12_29;

BB12_34:
	shl.b64 	%rd71, %rd11, 3;
	add.s64 	%rd72, %rd4, %rd71;
	ld.global.f64 	%fd114, [%rd72];
	bra.uni 	BB12_43;

BB12_19:
	setp.eq.s32	%p37, %r27, 20;
	@%p37 bra 	BB12_20;
	bra.uni 	BB12_23;

BB12_20:
	mul.f64 	%fd104, %fd16, %fd16;
	fma.rn.f64 	%fd105, %fd13, %fd13, %fd104;
	sqrt.rn.f64 	%fd114, %fd105;
	bra.uni 	BB12_43;

BB12_26:
	setp.eq.s32	%p32, %r27, 31;
	@%p32 bra 	BB12_27;
	bra.uni 	BB12_23;

BB12_27:
	shl.b64 	%rd73, %rd11, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.f64 	%fd114, [%rd74];
	bra.uni 	BB12_43;

BB12_29:
	setp.ne.s32	%p30, %r27, 40;
	@%p30 bra 	BB12_23;

	and.b32  	%r28, %r5, 8;
	setp.eq.s32	%p38, %r28, 0;
	shl.b64 	%rd64, %rd11, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.f64 	%fd40, [%rd65];
	add.s64 	%rd66, %rd5, %rd64;
	ld.global.f64 	%fd41, [%rd66];
	add.f64 	%fd116, %fd41, %fd40;
	@%p38 bra 	BB12_32;

	add.s64 	%rd68, %rd8, %rd64;
	ld.global.f64 	%fd42, [%rd68];
	add.f64 	%fd116, %fd116, %fd42;

BB12_32:
	mov.f64 	%fd114, %fd116;
	and.b32  	%r29, %r5, 458752;
	setp.eq.s32	%p39, %r29, 0;
	@%p39 bra 	BB12_43;

	add.s64 	%rd70, %rd7, %rd64;
	ld.global.f64 	%fd43, [%rd70];
	add.f64 	%fd114, %fd114, %fd43;
	bra.uni 	BB12_43;

BB12_23:
	mov.f64 	%fd114, 0d0000000000000000;
	bra.uni 	BB12_43;

BB12_36:
	div.rn.f64 	%fd23, %fd16, %fd13;
	abs.f64 	%fd24, %fd23;
	setp.leu.f64	%p41, %fd24, 0d3FF0000000000000;
	mov.f64 	%fd109, %fd24;
	@%p41 bra 	BB12_38;

	// inline asm
	rcp.approx.ftz.f64 %fd45,%fd24;
	// inline asm
	neg.f64 	%fd47, %fd24;
	mov.f64 	%fd48, 0d3FF0000000000000;
	fma.rn.f64 	%fd49, %fd47, %fd45, %fd48;
	fma.rn.f64 	%fd50, %fd49, %fd49, %fd49;
	fma.rn.f64 	%fd51, %fd50, %fd45, %fd45;
	setp.eq.f64	%p42, %fd24, 0d7FF0000000000000;
	selp.f64	%fd25, 0d0000000000000000, %fd51, %p42;
	mov.f64 	%fd109, %fd25;

BB12_38:
	mov.f64 	%fd26, %fd109;
	mul.f64 	%fd52, %fd26, %fd26;
	mov.f64 	%fd53, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd54, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd55, %fd54, %fd52, %fd53;
	mov.f64 	%fd56, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd57, %fd55, %fd52, %fd56;
	mov.f64 	%fd58, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd59, %fd57, %fd52, %fd58;
	mov.f64 	%fd60, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd61, %fd59, %fd52, %fd60;
	mov.f64 	%fd62, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd63, %fd61, %fd52, %fd62;
	mov.f64 	%fd64, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd65, %fd63, %fd52, %fd64;
	mov.f64 	%fd66, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd67, %fd65, %fd52, %fd66;
	mov.f64 	%fd68, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd69, %fd67, %fd52, %fd68;
	mov.f64 	%fd70, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd71, %fd69, %fd52, %fd70;
	mov.f64 	%fd72, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd73, %fd71, %fd52, %fd72;
	mov.f64 	%fd74, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd75, %fd73, %fd52, %fd74;
	mov.f64 	%fd76, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd77, %fd75, %fd52, %fd76;
	mov.f64 	%fd78, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd79, %fd77, %fd52, %fd78;
	mov.f64 	%fd80, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd81, %fd79, %fd52, %fd80;
	mov.f64 	%fd82, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd83, %fd81, %fd52, %fd82;
	mov.f64 	%fd84, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd85, %fd83, %fd52, %fd84;
	mov.f64 	%fd86, 0d3FC99999999840D2;
	fma.rn.f64 	%fd87, %fd85, %fd52, %fd86;
	mov.f64 	%fd88, 0dBFD555555555544C;
	fma.rn.f64 	%fd89, %fd87, %fd52, %fd88;
	mul.f64 	%fd90, %fd52, %fd89;
	fma.rn.f64 	%fd91, %fd90, %fd26, %fd26;
	mov.f64 	%fd92, 0d3FF921FB54442D18;
	sub.f64 	%fd93, %fd92, %fd91;
	setp.gt.f64	%p43, %fd24, 0d3FF0000000000000;
	selp.f64	%fd94, %fd93, %fd91, %p43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd94;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd94;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd23;
	}
	and.b32  	%r33, %r32, -2147483648;
	or.b32  	%r34, %r31, %r33;
	mov.b64 	%fd95, {%r30, %r34};
	mul.f64 	%fd96, %fd95, 0d404CA5DC1A63C1F8;
	add.f64 	%fd97, %fd96, 0d4066800000000000;
	setp.lt.f64	%p44, %fd13, 0d0000000000000000;
	selp.f64	%fd110, %fd97, %fd96, %p44;

BB12_41:
	mov.f64 	%fd99, 0d4056800000000000;
	sub.f64 	%fd100, %fd99, %fd110;
	setp.lt.f64	%p47, %fd100, 0d0000000000000000;
	add.f64 	%fd101, %fd100, 0d4076800000000000;
	selp.f64	%fd102, %fd101, %fd100, %p47;
	setp.gt.f64	%p48, %fd102, 0d4076800000000000;
	add.f64 	%fd103, %fd102, 0dC076800000000000;
	selp.f64	%fd114, %fd103, %fd102, %p48;

BB12_43:
	st.global.f64 	[%rd10], %fd114;

BB12_44:
	ld.param.u32 	%r38, [gpu_extractpoData_param_3];
	mov.u32 	%r37, %ntid.y;
	mov.u32 	%r35, %ntid.x;
	mad.lo.s32 	%r45, %r35, %r37, %r45;
	setp.lt.s32	%p49, %r45, %r38;
	@%p49 bra 	BB12_2;

BB12_45:
	ret;
}

	// .globl	gpu_calcRF
.visible .entry gpu_calcRF(
	.param .u32 gpu_calcRF_param_0,
	.param .f64 gpu_calcRF_param_1,
	.param .u64 gpu_calcRF_param_2,
	.param .u64 gpu_calcRF_param_3,
	.param .u64 gpu_calcRF_param_4,
	.param .u64 gpu_calcRF_param_5
)
{
	.reg .pred 	%p<26>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<45>;
	.reg .f64 	%fd<76>;
	.reg .b64 	%rd<76>;


	ld.param.f64 	%fd26, [gpu_calcRF_param_1];
	ld.param.u64 	%rd9, [gpu_calcRF_param_2];
	ld.param.u64 	%rd10, [gpu_calcRF_param_3];
	ld.param.u64 	%rd11, [gpu_calcRF_param_4];
	ld.param.u64 	%rd12, [gpu_calcRF_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	mov.u32 	%r10, %ntid.y;
	mov.u32 	%r11, %ctaid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r2, %r10, %r11, %r12;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r13, [dc_ny];
	add.s32 	%r14, %r13, -2;
	setp.lt.s32	%p2, %r1, %r14;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r15, [dc_nx];
	add.s32 	%r16, %r15, -2;
	setp.lt.s32	%p6, %r2, %r16;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB13_30;
	bra.uni 	BB13_1;

BB13_1:
	ld.const.u32 	%r17, [dc_nyPadded];
	mad.lo.s32 	%r18, %r17, %r2, %r1;
	ld.const.u64 	%rd13, [dc_a];
	cvta.to.global.u64 	%rd14, %rd13;
	cvt.s64.s32	%rd1, %r18;
	mul.wide.s32 	%rd15, %r18, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.u8 	%r19, [%rd16];
	setp.ne.s32	%p8, %r19, 0;
	@%p8 bra 	BB13_30;

	ld.const.u32 	%r3, [dc_switches];
	and.b32  	%r20, %r3, 32;
	setp.eq.s32	%p9, %r20, 0;
	mov.f64 	%fd75, 0d0000000000000000;
	@%p9 bra 	BB13_4;

	ld.const.u64 	%rd17, [dc_griddedSh];
	cvta.to.global.u64 	%rd18, %rd17;
	shl.b64 	%rd19, %rd1, 3;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.f64 	%fd28, [%rd20];
	add.f64 	%fd75, %fd28, 0d0000000000000000;

BB13_4:
	mov.f64 	%fd2, %fd75;
	and.b32  	%r21, %r3, 128;
	setp.eq.s32	%p10, %r21, 0;
	@%p10 bra 	BB13_19;

	ld.const.u64 	%rd21, [dc_hyetographIndexLayer];
	cvta.to.global.u64 	%rd22, %rd21;
	shl.b64 	%rd23, %rd1, 3;
	add.s64 	%rd24, %rd22, %rd23;
	ld.global.u64 	%rd2, [%rd24];
	and.b32  	%r22, %r3, 256;
	setp.eq.s32	%p11, %r22, 0;
	mov.f64 	%fd56, 0d3FF0000000000000;
	mov.f64 	%fd55, %fd56;
	mov.f64 	%fd54, %fd56;
	mov.f64 	%fd53, %fd56;
	@%p11 bra 	BB13_7;

	ld.const.u64 	%rd25, [dc_hyetographWeightLayer];
	cvta.to.global.u64 	%rd26, %rd25;
	add.s64 	%rd28, %rd26, %rd23;
	ld.global.u64 	%rd29, [%rd28];
	cvt.u32.u64	%r23, %rd29;
	and.b32  	%r24, %r23, 65535;
	cvt.rn.f64.u32	%fd33, %r24;
	div.rn.f64 	%fd53, %fd33, 0d40C3880000000000;
	shr.u32 	%r25, %r23, 16;
	cvt.rn.f64.u32	%fd34, %r25;
	div.rn.f64 	%fd54, %fd34, 0d40C3880000000000;
	shr.u64 	%rd30, %rd29, 32;
	cvt.u32.u64	%r26, %rd30;
	and.b32  	%r27, %r26, 65535;
	cvt.rn.f64.u32	%fd35, %r27;
	div.rn.f64 	%fd55, %fd35, 0d40C3880000000000;
	shr.u64 	%rd31, %rd29, 48;
	cvt.u32.u64	%r28, %rd31;
	cvt.rn.f64.u32	%fd36, %r28;
	div.rn.f64 	%fd56, %fd36, 0d40C3880000000000;

BB13_7:
	cvt.u32.u64	%r29, %rd2;
	and.b32  	%r4, %r29, 65535;
	setp.eq.s32	%p12, %r4, 0;
	mov.f64 	%fd74, %fd2;
	@%p12 bra 	BB13_10;

	cvt.u64.u32	%rd3, %r4;
	cvta.to.global.u64 	%rd32, %rd9;
	mul.wide.u32 	%rd33, %r4, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.u32 	%r30, [%rd34];
	add.s32 	%r31, %r30, -11;
	setp.gt.u32	%p13, %r31, 1;
	mov.f64 	%fd58, %fd2;
	mov.f64 	%fd74, %fd58;
	@%p13 bra 	BB13_10;

	cvta.to.global.u64 	%rd35, %rd10;
	shl.b64 	%rd36, %rd3, 3;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.f64 	%fd37, [%rd37];
	fma.rn.f64 	%fd74, %fd53, %fd37, %fd2;

BB13_10:
	mov.f64 	%fd12, %fd74;
	shr.u32 	%r5, %r29, 16;
	setp.eq.s32	%p14, %r5, 0;
	mov.f64 	%fd73, %fd12;
	@%p14 bra 	BB13_13;

	cvt.u64.u32	%rd4, %r5;
	cvta.to.global.u64 	%rd38, %rd9;
	mul.wide.u32 	%rd39, %r5, 4;
	add.s64 	%rd40, %rd38, %rd39;
	ld.global.u32 	%r33, [%rd40];
	add.s32 	%r34, %r33, -11;
	setp.gt.u32	%p15, %r34, 1;
	mov.f64 	%fd61, %fd12;
	mov.f64 	%fd73, %fd61;
	@%p15 bra 	BB13_13;

	cvta.to.global.u64 	%rd41, %rd10;
	shl.b64 	%rd42, %rd4, 3;
	add.s64 	%rd43, %rd41, %rd42;
	ld.global.f64 	%fd38, [%rd43];
	fma.rn.f64 	%fd73, %fd54, %fd38, %fd12;

BB13_13:
	mov.f64 	%fd14, %fd73;
	shr.u64 	%rd44, %rd2, 32;
	cvt.u32.u64	%r35, %rd44;
	and.b32  	%r6, %r35, 65535;
	setp.eq.s32	%p16, %r6, 0;
	mov.f64 	%fd72, %fd14;
	@%p16 bra 	BB13_16;

	cvt.u64.u32	%rd5, %r6;
	cvta.to.global.u64 	%rd45, %rd9;
	mul.wide.u32 	%rd46, %r6, 4;
	add.s64 	%rd47, %rd45, %rd46;
	ld.global.u32 	%r36, [%rd47];
	add.s32 	%r37, %r36, -11;
	setp.gt.u32	%p17, %r37, 1;
	mov.f64 	%fd63, %fd14;
	mov.f64 	%fd72, %fd63;
	@%p17 bra 	BB13_16;

	cvta.to.global.u64 	%rd48, %rd10;
	shl.b64 	%rd49, %rd5, 3;
	add.s64 	%rd50, %rd48, %rd49;
	ld.global.f64 	%fd39, [%rd50];
	fma.rn.f64 	%fd72, %fd55, %fd39, %fd14;

BB13_16:
	mov.f64 	%fd16, %fd72;
	shr.u64 	%rd6, %rd2, 48;
	setp.eq.s64	%p18, %rd6, 0;
	mov.f64 	%fd71, %fd16;
	@%p18 bra 	BB13_21;

	cvta.to.global.u64 	%rd51, %rd9;
	shl.b64 	%rd52, %rd6, 2;
	add.s64 	%rd53, %rd51, %rd52;
	ld.global.u32 	%r38, [%rd53];
	add.s32 	%r39, %r38, -11;
	setp.gt.u32	%p19, %r39, 1;
	mov.f64 	%fd65, %fd16;
	mov.f64 	%fd71, %fd65;
	@%p19 bra 	BB13_21;

	cvta.to.global.u64 	%rd54, %rd10;
	shl.b64 	%rd55, %rd6, 3;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.f64 	%fd40, [%rd56];
	fma.rn.f64 	%fd71, %fd56, %fd40, %fd16;
	bra.uni 	BB13_21;

BB13_19:
	cvta.to.global.u64 	%rd57, %rd9;
	ldu.global.u32 	%r40, [%rd57+4];
	add.s32 	%r41, %r40, -11;
	setp.gt.u32	%p20, %r41, 1;
	mov.f64 	%fd71, %fd2;
	@%p20 bra 	BB13_21;

	cvta.to.global.u64 	%rd58, %rd10;
	ldu.global.f64 	%fd41, [%rd58+8];
	add.f64 	%fd71, %fd2, %fd41;

BB13_21:
	mov.f64 	%fd69, %fd71;
	and.b32  	%r42, %r3, 16;
	setp.eq.s32	%p21, %r42, 0;
	@%p21 bra 	BB13_29;

	setp.gt.f64	%p22, %fd69, 0d0000000000000000;
	cvta.to.global.u64 	%rd59, %rd12;
	shl.b64 	%rd60, %rd1, 3;
	add.s64 	%rd7, %rd59, %rd60;
	@%p22 bra 	BB13_24;
	bra.uni 	BB13_23;

BB13_24:
	ld.const.u64 	%rd62, [dc_mat];
	cvta.to.global.u64 	%rd63, %rd62;
	shl.b64 	%rd64, %rd1, 2;
	add.s64 	%rd65, %rd63, %rd64;
	ld.global.u8 	%r43, [%rd65+3];
	ld.const.u64 	%rd66, [dc_materialTypes];
	cvta.to.global.u64 	%rd67, %rd66;
	add.s32 	%r44, %r43, -1;
	mul.wide.u32 	%rd68, %r44, 176;
	add.s64 	%rd8, %rd67, %rd68;
	cvta.to.global.u64 	%rd69, %rd11;
	add.s64 	%rd71, %rd69, %rd60;
	ld.global.f64 	%fd42, [%rd71];
	ld.global.f64 	%fd43, [%rd8+32];
	sub.f64 	%fd44, %fd43, %fd42;
	cvt.rn.f32.f64	%f1, %fd44;
	mov.f32 	%f4, 0f00000000;
	setp.leu.f32	%p23, %f1, 0f00000000;
	mov.f32 	%f6, %f4;
	mov.f64 	%fd70, %fd69;
	@%p23 bra 	BB13_28;

	mul.f64 	%fd20, %fd69, %fd26;
	cvt.f64.f32	%fd21, %f1;
	setp.gt.f64	%p24, %fd20, %fd21;
	@%p24 bra 	BB13_27;
	bra.uni 	BB13_26;

BB13_27:
	div.rn.f64 	%fd46, %fd21, %fd26;
	sub.f64 	%fd70, %fd69, %fd46;
	mov.f32 	%f6, %f1;
	bra.uni 	BB13_28;

BB13_23:
	mov.u64 	%rd61, 0;
	st.global.u64 	[%rd7], %rd61;
	bra.uni 	BB13_29;

BB13_26:
	cvt.rn.f32.f64	%f6, %fd20;
	mov.f64 	%fd70, 0d0000000000000000;

BB13_28:
	ld.global.f64 	%fd47, [%rd8+40];
	sub.f64 	%fd48, %fd70, %fd47;
	setp.gt.f64	%p25, %fd70, %fd47;
	selp.f64	%fd69, %fd48, 0d0000000000000000, %p25;
	selp.f64	%fd49, %fd47, %fd70, %p25;
	cvt.f64.f32	%fd50, %f6;
	fma.rn.f64 	%fd51, %fd49, %fd26, %fd50;
	cvt.rn.f32.f64	%f5, %fd51;
	cvt.f64.f32	%fd52, %f5;
	st.global.f64 	[%rd7], %fd52;

BB13_29:
	ld.const.u64 	%rd72, [dc_rf];
	cvta.to.global.u64 	%rd73, %rd72;
	shl.b64 	%rd74, %rd1, 3;
	add.s64 	%rd75, %rd73, %rd74;
	st.global.f64 	[%rd75], %fd69;

BB13_30:
	ret;
}

	// .globl	gpu_calcSA
.visible .entry gpu_calcSA(
	.param .u32 gpu_calcSA_param_0,
	.param .u64 gpu_calcSA_param_1,
	.param .u64 gpu_calcSA_param_2,
	.param .u64 gpu_calcSA_param_3,
	.param .u64 gpu_calcSA_param_4
)
{
	.reg .pred 	%p<50>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<64>;
	.reg .f64 	%fd<84>;
	.reg .b64 	%rd<69>;


	ld.param.u64 	%rd7, [gpu_calcSA_param_1];
	ld.param.u64 	%rd8, [gpu_calcSA_param_2];
	ld.param.u64 	%rd9, [gpu_calcSA_param_3];
	ld.param.u64 	%rd10, [gpu_calcSA_param_4];
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r1, %r14, %r15, %r16;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r2, %r17, %r18, %r19;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r20, [dc_ny];
	add.s32 	%r21, %r20, -2;
	setp.lt.s32	%p2, %r1, %r21;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r22, [dc_nx];
	add.s32 	%r23, %r22, -2;
	setp.lt.s32	%p6, %r2, %r23;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB14_60;
	bra.uni 	BB14_1;

BB14_1:
	ld.const.u32 	%r24, [dc_nyPadded];
	mad.lo.s32 	%r25, %r24, %r2, %r1;
	ld.const.u64 	%rd11, [dc_a];
	cvta.to.global.u64 	%rd12, %rd11;
	cvt.s64.s32	%rd1, %r25;
	mul.wide.s32 	%rd13, %r25, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.u8 	%r26, [%rd14];
	setp.ne.s32	%p8, %r26, 0;
	@%p8 bra 	BB14_60;

	cvta.to.global.u64 	%rd15, %rd10;
	shl.b64 	%rd16, %rd1, 2;
	add.s64 	%rd17, %rd15, %rd16;
	ld.global.u32 	%r3, [%rd17];
	and.b32  	%r4, %r3, 65535;
	shr.u32 	%r5, %r3, 16;
	ld.const.u32 	%r6, [dc_switches];
	and.b32  	%r27, %r6, 128;
	setp.eq.s32	%p9, %r27, 0;
	@%p9 bra 	BB14_49;

	ld.const.u64 	%rd18, [dc_hyetographIndexLayer];
	cvta.to.global.u64 	%rd19, %rd18;
	shl.b64 	%rd20, %rd1, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u64 	%rd2, [%rd21];
	and.b32  	%r28, %r6, 256;
	setp.eq.s32	%p10, %r28, 0;
	mov.f64 	%fd77, 0d3FF0000000000000;
	mov.f64 	%fd76, %fd77;
	mov.f64 	%fd75, %fd77;
	mov.f64 	%fd74, %fd77;
	@%p10 bra 	BB14_5;

	ld.const.u64 	%rd22, [dc_hyetographWeightLayer];
	cvta.to.global.u64 	%rd23, %rd22;
	add.s64 	%rd25, %rd23, %rd20;
	ld.global.u64 	%rd26, [%rd25];
	cvt.u32.u64	%r29, %rd26;
	and.b32  	%r30, %r29, 65535;
	cvt.rn.f64.u32	%fd52, %r30;
	div.rn.f64 	%fd77, %fd52, 0d40C3880000000000;
	shr.u32 	%r31, %r29, 16;
	cvt.rn.f64.u32	%fd53, %r31;
	div.rn.f64 	%fd76, %fd53, 0d40C3880000000000;
	shr.u64 	%rd27, %rd26, 32;
	cvt.u32.u64	%r32, %rd27;
	and.b32  	%r33, %r32, 65535;
	cvt.rn.f64.u32	%fd54, %r33;
	div.rn.f64 	%fd75, %fd54, 0d40C3880000000000;
	shr.u64 	%rd28, %rd26, 48;
	cvt.u32.u64	%r34, %rd28;
	cvt.rn.f64.u32	%fd55, %r34;
	div.rn.f64 	%fd74, %fd55, 0d40C3880000000000;

BB14_5:
	cvt.u16.u64	%rs1, %rd2;
	setp.eq.s16	%p11, %rs1, 0;
	mov.f64 	%fd83, 0d0000000000000000;
	@%p11 bra 	BB14_16;

	cvt.u32.u64	%r35, %rd2;
	and.b32  	%r36, %r35, 65535;
	and.b64  	%rd3, %rd2, 65535;
	cvta.to.global.u64 	%rd29, %rd7;
	mul.wide.u32 	%rd30, %r36, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.u32 	%r7, [%rd31];
	setp.lt.u32	%p12, %r7, 21;
	@%p12 bra 	BB14_16;

	cvta.to.global.u64 	%rd32, %rd8;
	shl.b64 	%rd33, %rd3, 3;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.f64 	%fd78, [%rd34];
	cvta.to.global.u64 	%rd35, %rd9;
	add.s64 	%rd36, %rd35, %rd33;
	ld.global.f64 	%fd10, [%rd36];
	setp.eq.s32	%p13, %r7, 31;
	@%p13 bra 	BB14_14;
	bra.uni 	BB14_8;

BB14_14:
	or.b32  	%r42, %r5, %r4;
	setp.ne.s32	%p18, %r42, 0;
	selp.f64	%fd78, %fd78, 0d0000000000000000, %p18;
	bra.uni 	BB14_15;

BB14_49:
	cvta.to.global.u64 	%rd62, %rd7;
	ldu.global.u32 	%r13, [%rd62+4];
	mov.f64 	%fd83, 0d0000000000000000;
	setp.lt.u32	%p43, %r13, 21;
	@%p43 bra 	BB14_59;

	cvta.to.global.u64 	%rd63, %rd9;
	cvta.to.global.u64 	%rd64, %rd8;
	ldu.global.f64 	%fd82, [%rd64+8];
	ldu.global.f64 	%fd41, [%rd63+8];
	setp.eq.s32	%p44, %r13, 31;
	@%p44 bra 	BB14_57;
	bra.uni 	BB14_51;

BB14_57:
	or.b32  	%r63, %r5, %r4;
	setp.ne.s32	%p49, %r63, 0;
	selp.f64	%fd82, %fd82, 0d0000000000000000, %p49;
	bra.uni 	BB14_58;

BB14_8:
	setp.ne.s32	%p14, %r7, 34;
	@%p14 bra 	BB14_15;

	cvt.u16.u32	%rs2, %r3;
	setp.eq.s16	%p15, %rs2, -1;
	@%p15 bra 	BB14_13;
	bra.uni 	BB14_10;

BB14_13:
	cvt.rn.f64.u32	%fd60, %r5;
	mul.f64 	%fd78, %fd60, %fd10;
	bra.uni 	BB14_15;

BB14_51:
	setp.ne.s32	%p45, %r13, 34;
	@%p45 bra 	BB14_58;

	setp.eq.s32	%p46, %r4, 65535;
	@%p46 bra 	BB14_56;
	bra.uni 	BB14_53;

BB14_56:
	cvt.rn.f64.u32	%fd73, %r5;
	mul.f64 	%fd82, %fd73, %fd41;
	bra.uni 	BB14_58;

BB14_10:
	setp.ne.s16	%p16, %rs2, 0;
	@%p16 bra 	BB14_15;

	setp.eq.s32	%p17, %r5, 0;
	mov.f64 	%fd78, 0d0000000000000000;
	@%p17 bra 	BB14_15;

	cvt.rn.f64.u32	%fd59, %r5;
	mul.f64 	%fd78, %fd59, %fd10;

BB14_15:
	fma.rn.f64 	%fd83, %fd77, %fd78, 0d0000000000000000;

BB14_16:
	cvt.u32.u64	%r43, %rd2;
	shr.u32 	%r8, %r43, 16;
	setp.eq.s32	%p19, %r8, 0;
	@%p19 bra 	BB14_27;

	cvt.u64.u32	%rd4, %r8;
	cvta.to.global.u64 	%rd37, %rd7;
	mul.wide.u32 	%rd38, %r8, 4;
	add.s64 	%rd39, %rd37, %rd38;
	ld.global.u32 	%r9, [%rd39];
	setp.lt.u32	%p20, %r9, 21;
	@%p20 bra 	BB14_27;

	cvta.to.global.u64 	%rd40, %rd8;
	shl.b64 	%rd41, %rd4, 3;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.f64 	%fd79, [%rd42];
	cvta.to.global.u64 	%rd43, %rd9;
	add.s64 	%rd44, %rd43, %rd41;
	ld.global.f64 	%fd18, [%rd44];
	setp.eq.s32	%p21, %r9, 31;
	@%p21 bra 	BB14_25;
	bra.uni 	BB14_19;

BB14_25:
	or.b32  	%r49, %r5, %r4;
	setp.ne.s32	%p26, %r49, 0;
	selp.f64	%fd79, %fd79, 0d0000000000000000, %p26;
	bra.uni 	BB14_26;

BB14_19:
	setp.ne.s32	%p22, %r9, 34;
	@%p22 bra 	BB14_26;

	cvt.u16.u32	%rs4, %r3;
	setp.eq.s16	%p23, %rs4, -1;
	@%p23 bra 	BB14_24;
	bra.uni 	BB14_21;

BB14_24:
	cvt.rn.f64.u32	%fd63, %r5;
	mul.f64 	%fd79, %fd63, %fd18;
	bra.uni 	BB14_26;

BB14_21:
	setp.ne.s16	%p24, %rs4, 0;
	@%p24 bra 	BB14_26;

	setp.eq.s32	%p25, %r5, 0;
	mov.f64 	%fd79, 0d0000000000000000;
	@%p25 bra 	BB14_26;

	cvt.rn.f64.u32	%fd62, %r5;
	mul.f64 	%fd79, %fd62, %fd18;

BB14_26:
	fma.rn.f64 	%fd83, %fd76, %fd79, %fd83;

BB14_27:
	shr.u64 	%rd45, %rd2, 32;
	cvt.u32.u64	%r50, %rd45;
	and.b32  	%r10, %r50, 65535;
	setp.eq.s32	%p27, %r10, 0;
	@%p27 bra 	BB14_38;

	cvt.u64.u32	%rd5, %r10;
	cvta.to.global.u64 	%rd46, %rd7;
	mul.wide.u32 	%rd47, %r10, 4;
	add.s64 	%rd48, %rd46, %rd47;
	ld.global.u32 	%r11, [%rd48];
	setp.lt.u32	%p28, %r11, 21;
	@%p28 bra 	BB14_38;

	cvta.to.global.u64 	%rd49, %rd8;
	shl.b64 	%rd50, %rd5, 3;
	add.s64 	%rd51, %rd49, %rd50;
	ld.global.f64 	%fd80, [%rd51];
	cvta.to.global.u64 	%rd52, %rd9;
	add.s64 	%rd53, %rd52, %rd50;
	ld.global.f64 	%fd26, [%rd53];
	setp.eq.s32	%p29, %r11, 31;
	@%p29 bra 	BB14_36;
	bra.uni 	BB14_30;

BB14_36:
	or.b32  	%r56, %r5, %r4;
	setp.ne.s32	%p34, %r56, 0;
	selp.f64	%fd80, %fd80, 0d0000000000000000, %p34;
	bra.uni 	BB14_37;

BB14_30:
	setp.ne.s32	%p30, %r11, 34;
	@%p30 bra 	BB14_37;

	cvt.u16.u32	%rs6, %r3;
	setp.eq.s16	%p31, %rs6, -1;
	@%p31 bra 	BB14_35;
	bra.uni 	BB14_32;

BB14_35:
	cvt.rn.f64.u32	%fd66, %r5;
	mul.f64 	%fd80, %fd66, %fd26;
	bra.uni 	BB14_37;

BB14_32:
	setp.ne.s16	%p32, %rs6, 0;
	@%p32 bra 	BB14_37;

	setp.eq.s32	%p33, %r5, 0;
	mov.f64 	%fd80, 0d0000000000000000;
	@%p33 bra 	BB14_37;

	cvt.rn.f64.u32	%fd65, %r5;
	mul.f64 	%fd80, %fd65, %fd26;

BB14_37:
	fma.rn.f64 	%fd83, %fd75, %fd80, %fd83;

BB14_38:
	shr.u64 	%rd6, %rd2, 48;
	setp.eq.s64	%p35, %rd6, 0;
	@%p35 bra 	BB14_59;

	cvta.to.global.u64 	%rd54, %rd7;
	shl.b64 	%rd55, %rd6, 2;
	add.s64 	%rd56, %rd54, %rd55;
	ld.global.u32 	%r12, [%rd56];
	setp.lt.u32	%p36, %r12, 21;
	@%p36 bra 	BB14_59;

	cvta.to.global.u64 	%rd57, %rd8;
	shl.b64 	%rd58, %rd6, 3;
	add.s64 	%rd59, %rd57, %rd58;
	ld.global.f64 	%fd81, [%rd59];
	cvta.to.global.u64 	%rd60, %rd9;
	add.s64 	%rd61, %rd60, %rd58;
	ld.global.f64 	%fd34, [%rd61];
	setp.eq.s32	%p37, %r12, 31;
	@%p37 bra 	BB14_47;
	bra.uni 	BB14_41;

BB14_47:
	or.b32  	%r62, %r5, %r4;
	setp.ne.s32	%p42, %r62, 0;
	selp.f64	%fd81, %fd81, 0d0000000000000000, %p42;
	bra.uni 	BB14_48;

BB14_41:
	setp.ne.s32	%p38, %r12, 34;
	@%p38 bra 	BB14_48;

	cvt.u16.u32	%rs8, %r3;
	setp.eq.s16	%p39, %rs8, -1;
	@%p39 bra 	BB14_46;
	bra.uni 	BB14_43;

BB14_46:
	cvt.rn.f64.u32	%fd69, %r5;
	mul.f64 	%fd81, %fd69, %fd34;
	bra.uni 	BB14_48;

BB14_43:
	setp.ne.s16	%p40, %rs8, 0;
	@%p40 bra 	BB14_48;

	setp.eq.s32	%p41, %r5, 0;
	mov.f64 	%fd81, 0d0000000000000000;
	@%p41 bra 	BB14_48;

	cvt.rn.f64.u32	%fd68, %r5;
	mul.f64 	%fd81, %fd68, %fd34;

BB14_48:
	fma.rn.f64 	%fd83, %fd74, %fd81, %fd83;
	bra.uni 	BB14_59;

BB14_53:
	setp.ne.s32	%p47, %r4, 0;
	@%p47 bra 	BB14_58;

	setp.eq.s32	%p48, %r5, 0;
	mov.f64 	%fd82, 0d0000000000000000;
	@%p48 bra 	BB14_58;

	cvt.rn.f64.u32	%fd72, %r5;
	mul.f64 	%fd82, %fd72, %fd41;

BB14_58:
	add.f64 	%fd83, %fd82, 0d0000000000000000;

BB14_59:
	ld.const.u64 	%rd65, [dc_sa];
	cvta.to.global.u64 	%rd66, %rd65;
	shl.b64 	%rd67, %rd1, 3;
	add.s64 	%rd68, %rd66, %rd67;
	st.global.f64 	[%rd68], %fd83;

BB14_60:
	ret;
}

	// .globl	gpu_calcInfiltration
.visible .entry gpu_calcInfiltration(
	.param .u32 gpu_calcInfiltration_param_0,
	.param .f64 gpu_calcInfiltration_param_1,
	.param .f64 gpu_calcInfiltration_param_2,
	.param .u64 gpu_calcInfiltration_param_3,
	.param .u64 gpu_calcInfiltration_param_4,
	.param .u64 gpu_calcInfiltration_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<39>;
	.reg .f64 	%fd<97>;
	.reg .b64 	%rd<41>;


	ld.param.f64 	%fd30, [gpu_calcInfiltration_param_2];
	ld.param.u64 	%rd2, [gpu_calcInfiltration_param_3];
	ld.param.u64 	%rd3, [gpu_calcInfiltration_param_4];
	ld.param.u64 	%rd4, [gpu_calcInfiltration_param_5];
	mov.u32 	%r10, %ntid.x;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %tid.x;
	mad.lo.s32 	%r1, %r10, %r11, %r12;
	mov.u32 	%r13, %ntid.y;
	mov.u32 	%r14, %ctaid.y;
	mov.u32 	%r15, %tid.y;
	mad.lo.s32 	%r2, %r13, %r14, %r15;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r16, [dc_ny];
	add.s32 	%r17, %r16, -2;
	setp.lt.s32	%p2, %r1, %r17;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r18, [dc_nx];
	add.s32 	%r19, %r18, -2;
	setp.lt.s32	%p6, %r2, %r19;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB15_19;
	bra.uni 	BB15_1;

BB15_1:
	ld.const.u32 	%r20, [dc_nyPadded];
	mad.lo.s32 	%r21, %r20, %r2, %r1;
	ld.const.u64 	%rd5, [dc_a];
	cvta.to.global.u64 	%rd6, %rd5;
	cvt.s64.s32	%rd1, %r21;
	mul.wide.s32 	%rd7, %r21, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.u32 	%r3, [%rd8];
	and.b32  	%r22, %r3, 255;
	setp.ne.s32	%p8, %r22, 0;
	@%p8 bra 	BB15_19;

	cvta.to.global.u64 	%rd9, %rd2;
	shl.b64 	%rd10, %rd1, 3;
	add.s64 	%rd11, %rd9, %rd10;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.global.f64 	%fd2, [%rd11];
	setp.gt.f64	%p9, %fd2, %fd1;
	@%p9 bra 	BB15_4;
	bra.uni 	BB15_3;

BB15_4:
	cvta.to.global.u64 	%rd17, %rd4;
	cvta.to.global.u64 	%rd18, %rd3;
	add.s64 	%rd20, %rd18, %rd10;
	ld.global.f64 	%fd3, [%rd20];
	add.s64 	%rd21, %rd17, %rd10;
	ld.global.f64 	%fd4, [%rd21];
	ld.const.u64 	%rd22, [dc_sc];
	cvta.to.global.u64 	%rd23, %rd22;
	add.s64 	%rd24, %rd23, %rd10;
	ld.global.f64 	%fd5, [%rd24];
	ld.const.u64 	%rd25, [dc_mat];
	cvta.to.global.u64 	%rd26, %rd25;
	shl.b64 	%rd27, %rd1, 2;
	add.s64 	%rd28, %rd26, %rd27;
	ld.global.u32 	%r23, [%rd28];
	shr.u32 	%r4, %r23, 24;
	bfe.u32 	%r5, %r3, 16, 8;
	setp.eq.s32	%p10, %r4, 0;
	mov.f64 	%fd31, 0d0000000000000000;
	mov.f64 	%fd96, %fd31;
	@%p10 bra 	BB15_6;

	ld.const.u64 	%rd29, [dc_materialTypes];
	cvta.to.global.u64 	%rd30, %rd29;
	add.s32 	%r24, %r4, -1;
	mul.wide.u32 	%rd31, %r24, 176;
	add.s64 	%rd32, %rd30, %rd31;
	ld.global.f64 	%fd6, [%rd32];
	mov.f64 	%fd96, %fd6;

BB15_6:
	mov.f64 	%fd7, %fd96;
	setp.eq.f64	%p11, %fd7, 0d3FF0000000000000;
	setp.eq.s32	%p12, %r5, 0;
	or.pred  	%p13, %p12, %p11;
	mov.f64 	%fd95, %fd31;
	@%p13 bra 	BB15_18;

	ld.const.u64 	%rd33, [dc_soilTypes];
	cvta.to.global.u64 	%rd34, %rd33;
	add.s32 	%r26, %r5, -1;
	mul.wide.u32 	%rd35, %r26, 72;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.f64 	%fd12, [%rd36+40];
	ld.global.f64 	%fd18, [%rd36+32];
	ld.global.f64 	%fd17, [%rd36+24];
	ld.global.f64 	%fd16, [%rd36+16];
	ld.global.f64 	%fd8, [%rd36+8];
	ld.global.u32 	%r25, [%rd36];
	mov.f64 	%fd33, 0d0000000000000000;
	setp.eq.s32	%p14, %r25, 1;
	mov.f64 	%fd93, %fd16;
	@%p14 bra 	BB15_16;

	setp.eq.s32	%p15, %r25, 3;
	@%p15 bra 	BB15_15;
	bra.uni 	BB15_9;

BB15_15:
	setp.gt.f64	%p21, %fd3, %fd1;
	ld.const.f64 	%fd72, [dc_dryDepthThreshold];
	selp.f64	%fd73, %fd3, %fd72, %p21;
	div.rn.f64 	%fd74, %fd73, %fd18;
	setp.lt.f64	%p22, %fd2, %fd12;
	selp.f64	%fd75, %fd2, %fd12, %p22;
	add.f64 	%fd76, %fd17, %fd75;
	div.rn.f64 	%fd77, %fd76, %fd74;
	add.f64 	%fd78, %fd77, 0d3FF0000000000000;
	mul.f64 	%fd93, %fd16, %fd78;
	bra.uni 	BB15_16;

BB15_3:
	ld.const.u64 	%rd12, [dc_ir];
	cvta.to.global.u64 	%rd13, %rd12;
	add.s64 	%rd15, %rd13, %rd10;
	mov.u64 	%rd16, 0;
	st.global.u64 	[%rd15], %rd16;
	bra.uni 	BB15_19;

BB15_9:
	setp.ne.s32	%p16, %r25, 2;
	mov.f64 	%fd93, %fd33;
	@%p16 bra 	BB15_16;

	mul.f64 	%fd19, %fd4, %fd18;
	setp.geu.f64	%p17, %fd19, 0d404E000000000000;
	mov.f64 	%fd93, %fd17;
	@%p17 bra 	BB15_16;

	neg.f64 	%fd34, %fd19;
	mov.f64 	%fd35, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd36, %fd34, %fd35;
	mov.f64 	%fd37, 0d4338000000000000;
	add.rn.f64 	%fd38, %fd36, %fd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd38;
	}
	mov.f64 	%fd39, 0dC338000000000000;
	add.rn.f64 	%fd40, %fd38, %fd39;
	mov.f64 	%fd41, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd42, %fd40, %fd41, %fd34;
	mov.f64 	%fd43, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd44, %fd40, %fd43, %fd42;
	mov.f64 	%fd45, 0d3E928AF3FCA213EA;
	mov.f64 	%fd46, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd47, %fd46, %fd44, %fd45;
	mov.f64 	%fd48, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd49, %fd47, %fd44, %fd48;
	mov.f64 	%fd50, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd51, %fd49, %fd44, %fd50;
	mov.f64 	%fd52, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd53, %fd51, %fd44, %fd52;
	mov.f64 	%fd54, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd55, %fd53, %fd44, %fd54;
	mov.f64 	%fd56, 0d3F81111111122322;
	fma.rn.f64 	%fd57, %fd55, %fd44, %fd56;
	mov.f64 	%fd58, 0d3FA55555555502A1;
	fma.rn.f64 	%fd59, %fd57, %fd44, %fd58;
	mov.f64 	%fd60, 0d3FC5555555555511;
	fma.rn.f64 	%fd61, %fd59, %fd44, %fd60;
	mov.f64 	%fd62, 0d3FE000000000000B;
	fma.rn.f64 	%fd63, %fd61, %fd44, %fd62;
	mov.f64 	%fd64, 0d3FF0000000000000;
	fma.rn.f64 	%fd65, %fd63, %fd44, %fd64;
	fma.rn.f64 	%fd66, %fd65, %fd44, %fd64;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd66;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd66;
	}
	shl.b32 	%r27, %r7, 20;
	add.s32 	%r28, %r9, %r27;
	mov.b64 	%fd92, {%r8, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd34;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p18, %f1, 0f4086232B;
	@%p18 bra 	BB15_14;

	setp.gt.f64	%p19, %fd19, 0d8000000000000000;
	mov.f64 	%fd67, 0d7FF0000000000000;
	sub.f64 	%fd68, %fd67, %fd19;
	selp.f64	%fd92, 0d0000000000000000, %fd68, %p19;
	setp.geu.f32	%p20, %f1, 0f40874800;
	@%p20 bra 	BB15_14;

	shr.u32 	%r30, %r7, 31;
	add.s32 	%r31, %r7, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r9;
	mov.b64 	%fd69, {%r8, %r34};
	sub.s32 	%r35, %r7, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd70, {%r38, %r37};
	mul.f64 	%fd92, %fd69, %fd70;

BB15_14:
	sub.f64 	%fd71, %fd16, %fd17;
	fma.rn.f64 	%fd93, %fd71, %fd92, %fd17;

BB15_16:
	mov.f64 	%fd79, 0d3FF0000000000000;
	sub.f64 	%fd80, %fd79, %fd7;
	mul.f64 	%fd81, %fd80, %fd93;
	ld.const.u8 	%rs1, [dc_switches+2];
	and.b16  	%rs2, %rs1, 64;
	setp.eq.s16	%p23, %rs2, 0;
	mul.f64 	%fd82, %fd80, %fd8;
	selp.f64	%fd83, %fd8, %fd82, %p23;
	sub.f64 	%fd84, %fd83, %fd3;
	div.rn.f64 	%fd85, %fd84, %fd30;
	setp.gt.f64	%p24, %fd85, %fd81;
	selp.f64	%fd86, %fd85, %fd81, %p24;
	ld.const.f64 	%fd87, [dc_dryDepthThreshold];
	sub.f64 	%fd88, %fd2, %fd87;
	div.rn.f64 	%fd89, %fd88, %fd30;
	setp.lt.f64	%p25, %fd86, %fd89;
	selp.f64	%fd95, %fd86, %fd89, %p25;
	setp.geu.f64	%p26, %fd5, 0d40F869F000000000;
	@%p26 bra 	BB15_18;

	sub.f64 	%fd90, %fd5, %fd3;
	div.rn.f64 	%fd91, %fd90, %fd30;
	setp.lt.f64	%p27, %fd95, %fd91;
	selp.f64	%fd95, %fd95, %fd91, %p27;

BB15_18:
	ld.const.u64 	%rd37, [dc_ir];
	cvta.to.global.u64 	%rd38, %rd37;
	add.s64 	%rd40, %rd38, %rd10;
	st.global.f64 	[%rd40], %fd95;

BB15_19:
	ret;
}

	// .globl	gpu_extractSxDepths
.visible .entry gpu_extractSxDepths(
	.param .u32 gpu_extractSxDepths_param_0,
	.param .u32 gpu_extractSxDepths_param_1,
	.param .u32 gpu_extractSxDepths_param_2,
	.param .u64 gpu_extractSxDepths_param_3,
	.param .u64 gpu_extractSxDepths_param_4,
	.param .u64 gpu_extractSxDepths_param_5,
	.param .u64 gpu_extractSxDepths_param_6,
	.param .u64 gpu_extractSxDepths_param_7
)
{
	.reg .pred 	%p<19>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<10>;
	.reg .b64 	%rd<43>;


	ld.param.u32 	%r15, [gpu_extractSxDepths_param_1];
	ld.param.u32 	%r16, [gpu_extractSxDepths_param_2];
	ld.param.u64 	%rd6, [gpu_extractSxDepths_param_3];
	ld.param.u64 	%rd7, [gpu_extractSxDepths_param_4];
	ld.param.u64 	%rd8, [gpu_extractSxDepths_param_5];
	ld.param.u64 	%rd9, [gpu_extractSxDepths_param_6];
	ld.param.u64 	%rd10, [gpu_extractSxDepths_param_7];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %tid.y;
	mad.lo.s32 	%r28, %r1, %r17, %r18;
	setp.ge.s32	%p1, %r28, %r16;
	@%p1 bra 	BB16_9;

	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd7;
	ld.const.u32 	%r19, [dc_ny];
	add.s32 	%r3, %r19, -2;
	ld.const.u32 	%r20, [dc_nx];
	add.s32 	%r4, %r20, -2;
	ld.const.u32 	%r5, [dc_nyPadded];
	ld.const.u64 	%rd11, [dc_phi2];
	cvta.to.global.u64 	%rd3, %rd11;
	ld.const.u64 	%rd12, [dc_phi4];
	cvta.to.global.u64 	%rd4, %rd12;
	mov.u32 	%r21, %ntid.x;
	mul.lo.s32 	%r6, %r21, %r1;
	setp.eq.s64	%p2, %rd10, 0;
	@%p2 bra 	BB16_6;

BB16_2:
	mul.wide.s32 	%rd14, %r28, 4;
	add.s64 	%rd15, %rd2, %rd14;
	cvta.to.global.u64 	%rd16, %rd8;
	add.s64 	%rd17, %rd16, %rd14;
	ld.global.u32 	%r22, [%rd17];
	sub.s32 	%r8, %r22, %r15;
	ld.global.u32 	%r9, [%rd15];
	setp.gt.s32	%p3, %r9, 1;
	setp.lt.s32	%p4, %r9, %r3;
	and.pred  	%p5, %p3, %p4;
	setp.gt.s32	%p6, %r8, 1;
	and.pred  	%p7, %p5, %p6;
	setp.lt.s32	%p8, %r8, %r4;
	and.pred  	%p9, %p7, %p8;
	shl.b32 	%r23, %r28, 2;
	cvta.to.global.u64 	%rd18, %rd10;
	mul.wide.s32 	%rd19, %r23, 8;
	add.s64 	%rd5, %rd18, %rd19;
	@%p9 bra 	BB16_4;
	bra.uni 	BB16_3;

BB16_4:
	mad.lo.s32 	%r24, %r5, %r8, %r9;
	cvta.to.global.u64 	%rd24, %rd6;
	mul.wide.s32 	%rd25, %r24, 8;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.f64 	%fd3, [%rd26];
	mul.wide.s32 	%rd28, %r28, 8;
	add.s64 	%rd29, %rd1, %rd28;
	st.global.f64 	[%rd29], %fd3;
	sub.s32 	%r25, %r24, %r5;
	mul.wide.s32 	%rd30, %r25, 8;
	add.s64 	%rd31, %rd3, %rd30;
	ld.global.f64 	%fd4, [%rd31];
	st.global.f64 	[%rd5], %fd4;
	add.s64 	%rd32, %rd3, %rd25;
	ld.global.f64 	%fd5, [%rd32];
	st.global.f64 	[%rd5+8], %fd5;
	add.s64 	%rd33, %rd4, %rd25;
	ld.global.f64 	%fd6, [%rd33+-8];
	st.global.f64 	[%rd5+16], %fd6;
	ld.global.f64 	%fd7, [%rd33];
	st.global.f64 	[%rd5+24], %fd7;
	bra.uni 	BB16_5;

BB16_3:
	mul.wide.s32 	%rd21, %r28, 8;
	add.s64 	%rd22, %rd1, %rd21;
	mov.u64 	%rd23, 0;
	st.global.u64 	[%rd22], %rd23;
	st.global.u64 	[%rd5], %rd23;
	st.global.u64 	[%rd5+8], %rd23;
	st.global.u64 	[%rd5+16], %rd23;
	st.global.u64 	[%rd5+24], %rd23;

BB16_5:
	add.s32 	%r28, %r6, %r28;
	setp.lt.s32	%p10, %r28, %r16;
	@%p10 bra 	BB16_2;
	bra.uni 	BB16_9;

BB16_6:
	mul.wide.s32 	%rd34, %r28, 4;
	add.s64 	%rd35, %rd2, %rd34;
	cvta.to.global.u64 	%rd36, %rd8;
	add.s64 	%rd37, %rd36, %rd34;
	ld.global.u32 	%r26, [%rd37];
	sub.s32 	%r12, %r26, %r15;
	ld.global.u32 	%r13, [%rd35];
	setp.gt.s32	%p11, %r13, 1;
	setp.lt.s32	%p12, %r13, %r3;
	and.pred  	%p13, %p11, %p12;
	setp.gt.s32	%p14, %r12, 1;
	and.pred  	%p15, %p13, %p14;
	setp.lt.s32	%p16, %r12, %r4;
	and.pred  	%p17, %p15, %p16;
	mov.f64 	%fd9, 0d0000000000000000;
	@!%p17 bra 	BB16_8;
	bra.uni 	BB16_7;

BB16_7:
	mad.lo.s32 	%r27, %r5, %r12, %r13;
	cvta.to.global.u64 	%rd38, %rd6;
	mul.wide.s32 	%rd39, %r27, 8;
	add.s64 	%rd40, %rd38, %rd39;
	ld.global.f64 	%fd9, [%rd40];

BB16_8:
	mul.wide.s32 	%rd41, %r28, 8;
	add.s64 	%rd42, %rd1, %rd41;
	st.global.f64 	[%rd42], %fd9;
	add.s32 	%r28, %r6, %r28;
	setp.lt.s32	%p18, %r28, %r16;
	@%p18 bra 	BB16_6;

BB16_9:
	ret;
}

	// .globl	gpu_calcSxSources
.visible .entry gpu_calcSxSources(
	.param .u32 gpu_calcSxSources_param_0,
	.param .u32 gpu_calcSxSources_param_1,
	.param .u32 gpu_calcSxSources_param_2,
	.param .u64 gpu_calcSxSources_param_3,
	.param .u64 gpu_calcSxSources_param_4,
	.param .u64 gpu_calcSxSources_param_5,
	.param .u64 gpu_calcSxSources_param_6
)
{
	.reg .pred 	%p<23>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<35>;


	ld.param.u32 	%r15, [gpu_calcSxSources_param_1];
	ld.param.u32 	%r16, [gpu_calcSxSources_param_2];
	ld.param.u64 	%rd5, [gpu_calcSxSources_param_3];
	ld.param.u64 	%rd6, [gpu_calcSxSources_param_4];
	ld.param.u64 	%rd7, [gpu_calcSxSources_param_5];
	ld.param.u64 	%rd8, [gpu_calcSxSources_param_6];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %tid.y;
	mad.lo.s32 	%r28, %r1, %r17, %r18;
	setp.ge.s32	%p1, %r28, %r16;
	@%p1 bra 	BB17_11;

	ld.const.u32 	%r19, [dc_ny];
	add.s32 	%r3, %r19, -2;
	ld.const.u32 	%r20, [dc_nx];
	add.s32 	%r4, %r20, -2;
	ld.const.u32 	%r5, [dc_nyPadded];
	ld.const.u8 	%rs1, [dc_switches+1];
	shr.u16 	%rs2, %rs1, 2;
	and.b16  	%rs3, %rs2, 1;
	setp.eq.b16	%p2, %rs3, 1;
	setp.ne.s64	%p3, %rd8, 0;
	and.pred  	%p4, %p2, %p3;
	mov.u32 	%r21, %ntid.x;
	mul.lo.s32 	%r6, %r21, %r1;
	ld.const.u64 	%rd9, [dc_sx];
	cvta.to.global.u64 	%rd1, %rd9;
	ld.const.f64 	%fd4, [dc_dy];
	ld.const.f64 	%fd5, [dc_dx];
	mul.f64 	%fd1, %fd5, %fd4;
	@%p4 bra 	BB17_6;
	bra.uni 	BB17_2;

BB17_6:
	ld.const.u64 	%rd20, [dc_areaFactor];
	cvta.to.global.u64 	%rd3, %rd20;

BB17_7:
	cvta.to.global.u64 	%rd21, %rd7;
	cvt.s64.s32	%rd4, %r28;
	mul.wide.s32 	%rd22, %r28, 8;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.f64 	%fd3, [%rd23];
	setp.eq.f64	%p14, %fd3, 0d0000000000000000;
	@%p14 bra 	BB17_10;

	cvta.to.global.u64 	%rd24, %rd5;
	shl.b64 	%rd25, %rd4, 2;
	add.s64 	%rd26, %rd24, %rd25;
	cvta.to.global.u64 	%rd27, %rd6;
	add.s64 	%rd28, %rd27, %rd25;
	ld.global.u32 	%r24, [%rd28];
	sub.s32 	%r12, %r24, %r15;
	ld.global.u32 	%r13, [%rd26];
	setp.gt.s32	%p15, %r13, 1;
	setp.lt.s32	%p16, %r13, %r3;
	and.pred  	%p17, %p15, %p16;
	setp.gt.s32	%p18, %r12, 1;
	and.pred  	%p19, %p17, %p18;
	setp.lt.s32	%p20, %r12, %r4;
	and.pred  	%p21, %p19, %p20;
	@!%p21 bra 	BB17_10;
	bra.uni 	BB17_9;

BB17_9:
	mad.lo.s32 	%r25, %r5, %r12, %r13;
	mul.wide.s32 	%rd29, %r25, 8;
	add.s64 	%rd30, %rd1, %rd29;
	div.rn.f64 	%fd9, %fd3, %fd1;
	ld.global.f64 	%fd10, [%rd30];
	add.f64 	%fd11, %fd10, %fd9;
	st.global.f64 	[%rd30], %fd11;
	cvta.to.global.u64 	%rd31, %rd8;
	shl.b64 	%rd32, %rd4, 3;
	add.s64 	%rd33, %rd31, %rd32;
	ld.global.f64 	%fd12, [%rd33];
	add.s64 	%rd34, %rd3, %rd29;
	st.global.f64 	[%rd34], %fd12;

BB17_10:
	mad.lo.s32 	%r28, %r21, %r1, %r28;
	setp.lt.s32	%p22, %r28, %r16;
	@%p22 bra 	BB17_7;
	bra.uni 	BB17_11;

BB17_2:
	cvta.to.global.u64 	%rd10, %rd7;
	cvt.s64.s32	%rd2, %r28;
	mul.wide.s32 	%rd11, %r28, 8;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.f64 	%fd2, [%rd12];
	setp.eq.f64	%p5, %fd2, 0d0000000000000000;
	@%p5 bra 	BB17_5;

	cvta.to.global.u64 	%rd13, %rd5;
	shl.b64 	%rd14, %rd2, 2;
	add.s64 	%rd15, %rd13, %rd14;
	cvta.to.global.u64 	%rd16, %rd6;
	add.s64 	%rd17, %rd16, %rd14;
	ld.global.u32 	%r22, [%rd17];
	sub.s32 	%r8, %r22, %r15;
	ld.global.u32 	%r9, [%rd15];
	setp.gt.s32	%p6, %r9, 1;
	setp.lt.s32	%p7, %r9, %r3;
	and.pred  	%p8, %p6, %p7;
	setp.gt.s32	%p9, %r8, 1;
	and.pred  	%p10, %p8, %p9;
	setp.lt.s32	%p11, %r8, %r4;
	and.pred  	%p12, %p10, %p11;
	@!%p12 bra 	BB17_5;
	bra.uni 	BB17_4;

BB17_4:
	mad.lo.s32 	%r23, %r5, %r8, %r9;
	mul.wide.s32 	%rd18, %r23, 8;
	add.s64 	%rd19, %rd1, %rd18;
	div.rn.f64 	%fd6, %fd2, %fd1;
	ld.global.f64 	%fd7, [%rd19];
	add.f64 	%fd8, %fd7, %fd6;
	st.global.f64 	[%rd19], %fd8;

BB17_5:
	add.s32 	%r28, %r6, %r28;
	setp.lt.s32	%p13, %r28, %r16;
	@%p13 bra 	BB17_2;

BB17_11:
	ret;
}

	// .globl	gpu_calcNut
.visible .entry gpu_calcNut(
	.param .u32 gpu_calcNut_param_0,
	.param .u64 gpu_calcNut_param_1,
	.param .u64 gpu_calcNut_param_2,
	.param .u64 gpu_calcNut_param_3,
	.param .u64 gpu_calcNut_param_4
)
{
	.reg .pred 	%p<58>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<157>;
	.reg .b64 	%rd<115>;


	ld.param.u64 	%rd17, [gpu_calcNut_param_1];
	ld.param.u64 	%rd14, [gpu_calcNut_param_2];
	ld.param.u64 	%rd15, [gpu_calcNut_param_3];
	ld.param.u64 	%rd16, [gpu_calcNut_param_4];
	cvta.to.global.u64 	%rd1, %rd17;
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %tid.x;
	mad.lo.s32 	%r1, %r12, %r13, %r14;
	mov.u32 	%r15, %ntid.y;
	mov.u32 	%r16, %ctaid.y;
	mov.u32 	%r17, %tid.y;
	mad.lo.s32 	%r2, %r15, %r16, %r17;
	setp.gt.s32	%p2, %r1, 1;
	ld.const.u32 	%r18, [dc_ny];
	add.s32 	%r19, %r18, -2;
	setp.lt.s32	%p3, %r1, %r19;
	and.pred  	%p4, %p2, %p3;
	setp.gt.s32	%p5, %r2, 1;
	and.pred  	%p6, %p4, %p5;
	ld.const.u32 	%r20, [dc_nx];
	add.s32 	%r21, %r20, -2;
	setp.lt.s32	%p7, %r2, %r21;
	and.pred  	%p8, %p6, %p7;
	@!%p8 bra 	BB18_39;
	bra.uni 	BB18_1;

BB18_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	ld.const.u64 	%rd18, [dc_a];
	cvta.to.global.u64 	%rd2, %rd18;
	cvt.u64.u32	%rd3, %r4;
	mul.wide.u32 	%rd19, %r4, 4;
	add.s64 	%rd20, %rd2, %rd19;
	ld.global.u8 	%r22, [%rd20];
	setp.ne.s32	%p9, %r22, 0;
	@%p9 bra 	BB18_39;

	shl.b64 	%rd21, %rd3, 3;
	add.s64 	%rd22, %rd1, %rd21;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.global.f64 	%fd2, [%rd22];
	setp.leu.f64	%p10, %fd2, %fd1;
	@%p10 bra 	BB18_37;
	bra.uni 	BB18_3;

BB18_37:
	ld.const.u64 	%rd101, [dc_nut];
	cvta.to.global.u64 	%rd102, %rd101;
	add.s64 	%rd104, %rd102, %rd21;
	mov.u64 	%rd105, 0;
	st.global.u64 	[%rd104], %rd105;
	ld.const.u32 	%r52, [dc_turbulenceModel];
	setp.ne.s32	%p57, %r52, 1;
	@%p57 bra 	BB18_39;

	cvta.to.global.u64 	%rd106, %rd16;
	add.s64 	%rd108, %rd106, %rd21;
	st.global.u64 	[%rd108], %rd105;
	ld.const.u64 	%rd110, [dc_l];
	cvta.to.global.u64 	%rd111, %rd110;
	add.s64 	%rd112, %rd111, %rd21;
	st.global.u64 	[%rd112], %rd105;
	bra.uni 	BB18_39;

BB18_3:
	cvta.to.global.u64 	%rd23, %rd15;
	cvta.to.global.u64 	%rd4, %rd14;
	sub.s32 	%r5, %r4, %r3;
	cvt.u64.u32	%rd5, %r5;
	mul.wide.u32 	%rd24, %r5, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.global.u8 	%r6, [%rd25];
	add.s32 	%r23, %r3, %r4;
	cvt.u64.u32	%rd6, %r23;
	mul.wide.u32 	%rd26, %r23, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.global.u8 	%r7, [%rd27];
	add.s32 	%r24, %r4, -1;
	cvt.u64.u32	%rd7, %r24;
	mul.wide.u32 	%rd28, %r24, 4;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.u8 	%r8, [%rd29];
	add.s32 	%r25, %r4, 1;
	cvt.u64.u32	%rd8, %r25;
	mul.wide.u32 	%rd30, %r25, 4;
	add.s64 	%rd31, %rd2, %rd30;
	ld.global.u8 	%r9, [%rd31];
	add.s32 	%r26, %r5, -1;
	cvt.u64.u32	%rd9, %r26;
	mul.wide.u32 	%rd32, %r5, 8;
	add.s64 	%rd33, %rd4, %rd32;
	mul.wide.u32 	%rd34, %r26, 8;
	add.s64 	%rd35, %rd23, %rd34;
	ld.global.f64 	%fd3, [%rd35];
	add.s64 	%rd36, %rd23, %rd32;
	ld.global.f64 	%fd4, [%rd36];
	mul.wide.u32 	%rd37, %r24, 8;
	add.s64 	%rd38, %rd23, %rd37;
	add.s32 	%r27, %r23, -1;
	mul.wide.u32 	%rd39, %r27, 8;
	add.s64 	%rd40, %rd23, %rd39;
	ld.global.f64 	%fd5, [%rd40];
	mul.wide.u32 	%rd41, %r23, 8;
	add.s64 	%rd42, %rd23, %rd41;
	ld.global.f64 	%fd6, [%rd42];
	add.s64 	%rd43, %rd1, %rd32;
	add.s64 	%rd44, %rd1, %rd41;
	add.s64 	%rd45, %rd1, %rd37;
	mul.wide.u32 	%rd46, %r25, 8;
	add.s64 	%rd47, %rd1, %rd46;
	setp.eq.s32	%p11, %r6, 0;
	ld.global.f64 	%fd48, [%rd43];
	setp.gt.f64	%p12, %fd48, %fd1;
	and.pred  	%p13, %p11, %p12;
	add.f64 	%fd49, %fd2, %fd48;
	selp.f64	%fd7, %fd49, 0d0000000000000000, %p13;
	setp.eq.s32	%p14, %r7, 0;
	ld.global.f64 	%fd50, [%rd44];
	setp.gt.f64	%p15, %fd50, %fd1;
	and.pred  	%p16, %p14, %p15;
	add.f64 	%fd51, %fd2, %fd50;
	selp.f64	%fd8, %fd51, 0d0000000000000000, %p16;
	setp.eq.s32	%p17, %r8, 0;
	ld.global.f64 	%fd52, [%rd45];
	setp.gt.f64	%p18, %fd52, %fd1;
	and.pred  	%p19, %p17, %p18;
	add.f64 	%fd53, %fd2, %fd52;
	selp.f64	%fd9, %fd53, 0d0000000000000000, %p19;
	setp.eq.s32	%p20, %r9, 0;
	ld.global.f64 	%fd54, [%rd47];
	setp.gt.f64	%p21, %fd54, %fd1;
	and.pred  	%p22, %p20, %p21;
	add.f64 	%fd55, %fd2, %fd54;
	selp.f64	%fd10, %fd55, 0d0000000000000000, %p22;
	add.s64 	%rd49, %rd4, %rd21;
	ld.global.f64 	%fd11, [%rd49];
	ld.global.f64 	%fd12, [%rd33];
	sub.f64 	%fd56, %fd11, %fd12;
	ld.const.f64 	%fd13, [dc_dx];
	div.rn.f64 	%fd14, %fd56, %fd13;
	add.s64 	%rd50, %rd23, %rd21;
	ld.global.f64 	%fd15, [%rd50];
	ld.global.f64 	%fd16, [%rd38];
	sub.f64 	%fd57, %fd15, %fd16;
	ld.const.f64 	%fd17, [dc_dy];
	div.rn.f64 	%fd18, %fd57, %fd17;
	add.f64 	%fd19, %fd9, %fd10;
	mov.f64 	%fd47, 0d0000000000000000;
	setp.leu.f64	%p23, %fd19, 0d0000000000000000;
	mov.f64 	%fd148, %fd47;
	@%p23 bra 	BB18_5;

	shl.b64 	%rd51, %rd9, 3;
	add.s64 	%rd52, %rd4, %rd51;
	shl.b64 	%rd53, %rd7, 3;
	add.s64 	%rd54, %rd4, %rd53;
	add.s32 	%r28, %r5, 1;
	mul.wide.u32 	%rd55, %r28, 8;
	add.s64 	%rd56, %rd4, %rd55;
	shl.b64 	%rd57, %rd8, 3;
	add.s64 	%rd58, %rd4, %rd57;
	ld.global.f64 	%fd58, [%rd58];
	ld.global.f64 	%fd59, [%rd52];
	ld.global.f64 	%fd60, [%rd54];
	add.f64 	%fd61, %fd60, %fd59;
	add.f64 	%fd62, %fd12, %fd11;
	sub.f64 	%fd63, %fd62, %fd61;
	mul.f64 	%fd64, %fd9, %fd63;
	ld.global.f64 	%fd65, [%rd56];
	add.f64 	%fd66, %fd58, %fd65;
	sub.f64 	%fd67, %fd66, %fd62;
	fma.rn.f64 	%fd68, %fd10, %fd67, %fd64;
	add.f64 	%fd69, %fd19, %fd19;
	mul.f64 	%fd70, %fd69, %fd17;
	div.rn.f64 	%fd20, %fd68, %fd70;
	mov.f64 	%fd148, %fd20;

BB18_5:
	mov.f64 	%fd21, %fd148;
	add.f64 	%fd22, %fd7, %fd8;
	setp.leu.f64	%p24, %fd22, 0d0000000000000000;
	mov.f64 	%fd147, %fd47;
	@%p24 bra 	BB18_7;

	add.f64 	%fd72, %fd16, %fd15;
	add.f64 	%fd73, %fd3, %fd4;
	sub.f64 	%fd74, %fd72, %fd73;
	add.f64 	%fd75, %fd5, %fd6;
	sub.f64 	%fd76, %fd75, %fd72;
	mul.f64 	%fd77, %fd76, %fd8;
	fma.rn.f64 	%fd78, %fd74, %fd7, %fd77;
	add.f64 	%fd79, %fd22, %fd22;
	mul.f64 	%fd80, %fd79, %fd13;
	div.rn.f64 	%fd147, %fd78, %fd80;

BB18_7:
	ld.const.u32 	%r29, [dc_turbulenceModel];
	setp.eq.s32	%p25, %r29, 0;
	@%p25 bra 	BB18_36;
	bra.uni 	BB18_8;

BB18_36:
	ld.const.f64 	%fd135, [dc_nutM];
	mul.f64 	%fd136, %fd135, %fd13;
	mul.f64 	%fd137, %fd136, %fd17;
	mul.f64 	%fd138, %fd18, %fd18;
	fma.rn.f64 	%fd139, %fd14, %fd14, %fd138;
	add.f64 	%fd140, %fd21, %fd147;
	mul.f64 	%fd141, %fd140, 0d3FE0000000000000;
	fma.rn.f64 	%fd142, %fd140, %fd141, %fd139;
	sqrt.rn.f64 	%fd143, %fd142;
	ld.const.f64 	%fd144, [dc_nutC];
	fma.rn.f64 	%fd145, %fd137, %fd143, %fd144;
	ld.const.u64 	%rd97, [dc_nut];
	cvta.to.global.u64 	%rd98, %rd97;
	add.s64 	%rd100, %rd98, %rd21;
	st.global.f64 	[%rd100], %fd145;
	bra.uni 	BB18_39;

BB18_8:
	setp.ne.s32	%p26, %r29, 1;
	@%p26 bra 	BB18_39;

	mov.f64 	%fd149, 0d479E17B84357691B;
	@%p11 bra 	BB18_11;

	setp.ne.s32	%p28, %r6, 255;
	@%p28 bra 	BB18_12;

BB18_11:
	ld.const.u64 	%rd59, [dc_l];
	cvta.to.global.u64 	%rd60, %rd59;
	shl.b64 	%rd61, %rd5, 3;
	add.s64 	%rd62, %rd60, %rd61;
	ld.global.f64 	%fd82, [%rd62];
	setp.lt.f64	%p29, %fd82, 0d479E17B84357691B;
	selp.f64	%fd149, %fd82, 0d479E17B84357691B, %p29;

BB18_12:
	@%p14 bra 	BB18_14;

	setp.ne.s32	%p31, %r7, 255;
	@%p31 bra 	BB18_15;

BB18_14:
	ld.const.u64 	%rd63, [dc_l];
	cvta.to.global.u64 	%rd64, %rd63;
	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd64, %rd65;
	ld.global.f64 	%fd83, [%rd66];
	setp.lt.f64	%p32, %fd83, %fd149;
	selp.f64	%fd149, %fd83, %fd149, %p32;

BB18_15:
	@%p17 bra 	BB18_17;

	setp.ne.s32	%p34, %r8, 255;
	@%p34 bra 	BB18_18;

BB18_17:
	ld.const.u64 	%rd67, [dc_l];
	cvta.to.global.u64 	%rd68, %rd67;
	shl.b64 	%rd69, %rd7, 3;
	add.s64 	%rd70, %rd68, %rd69;
	ld.global.f64 	%fd84, [%rd70];
	setp.lt.f64	%p35, %fd84, %fd149;
	selp.f64	%fd149, %fd84, %fd149, %p35;

BB18_18:
	@%p20 bra 	BB18_20;

	setp.ne.s32	%p37, %r9, 255;
	@%p37 bra 	BB18_21;

BB18_20:
	ld.const.u64 	%rd114, [dc_l];
	cvta.to.global.u64 	%rd71, %rd114;
	shl.b64 	%rd72, %rd8, 3;
	add.s64 	%rd73, %rd71, %rd72;
	ld.global.f64 	%fd85, [%rd73];
	setp.lt.f64	%p38, %fd85, %fd149;
	selp.f64	%fd149, %fd85, %fd149, %p38;
	bra.uni 	BB18_22;

BB18_21:
	ld.const.u64 	%rd114, [dc_l];

BB18_22:
	ld.param.u64 	%rd113, [gpu_calcNut_param_4];
	ld.const.f64 	%fd86, [dc_nutM];
	mul.f64 	%fd87, %fd86, 0d3FE0000000000000;
	mul.f64 	%fd88, %fd87, %fd13;
	fma.rn.f64 	%fd89, %fd86, %fd13, %fd149;
	setp.eq.f64	%p39, %fd149, 0d0000000000000000;
	selp.f64	%fd90, %fd88, %fd89, %p39;
	mul.f64 	%fd91, %fd2, %fd86;
	setp.lt.f64	%p40, %fd90, %fd91;
	selp.f64	%fd92, %fd90, %fd91, %p40;
	add.f64 	%fd93, %fd12, %fd11;
	mul.f64 	%fd94, %fd93, 0d3FE0000000000000;
	add.f64 	%fd95, %fd16, %fd15;
	mul.f64 	%fd96, %fd95, 0d3FE0000000000000;
	mul.f64 	%fd97, %fd96, %fd96;
	fma.rn.f64 	%fd98, %fd94, %fd94, %fd97;
	sqrt.rn.f64 	%fd99, %fd98;
	cvta.to.global.u64 	%rd74, %rd113;
	add.s64 	%rd76, %rd74, %rd21;
	ld.global.f64 	%fd100, [%rd76];
	sqrt.rn.f64 	%fd101, %fd100;
	ld.const.f64 	%fd102, [dc_nutC];
	fma.rn.f64 	%fd103, %fd101, %fd92, %fd102;
	add.f64 	%fd104, %fd14, %fd18;
	mul.f64 	%fd105, %fd104, 0d3FE0000000000000;
	sub.f64 	%fd106, %fd14, %fd105;
	add.f64 	%fd107, %fd21, %fd147;
	mul.f64 	%fd108, %fd107, 0d3FE0000000000000;
	sub.f64 	%fd109, %fd18, %fd105;
	ld.const.f64 	%fd110, [dc_nUnitsFactor];
	mul.f64 	%fd111, %fd110, 0d3FD0000000000000;
	ld.const.u64 	%rd77, [dc_mnu];
	cvta.to.global.u64 	%rd78, %rd77;
	shl.b64 	%rd79, %rd5, 3;
	add.s64 	%rd80, %rd78, %rd79;
	add.s64 	%rd81, %rd78, %rd21;
	ld.global.f64 	%fd112, [%rd81];
	ld.global.f64 	%fd113, [%rd80];
	add.f64 	%fd114, %fd113, %fd112;
	ld.const.u64 	%rd82, [dc_mnv];
	cvta.to.global.u64 	%rd83, %rd82;
	shl.b64 	%rd84, %rd7, 3;
	add.s64 	%rd85, %rd83, %rd84;
	ld.global.f64 	%fd115, [%rd85];
	add.f64 	%fd116, %fd114, %fd115;
	add.s64 	%rd86, %rd83, %rd21;
	ld.global.f64 	%fd117, [%rd86];
	add.f64 	%fd118, %fd116, %fd117;
	mul.f64 	%fd119, %fd111, %fd118;
	cvta.to.global.u64 	%rd87, %rd114;
	add.s64 	%rd88, %rd87, %rd21;
	st.global.f64 	[%rd88], %fd92;
	ld.const.u64 	%rd89, [dc_nut];
	cvta.to.global.u64 	%rd90, %rd89;
	add.s64 	%rd91, %rd90, %rd21;
	st.global.f64 	[%rd91], %fd103;
	add.f64 	%fd120, %fd103, %fd103;
	mul.f64 	%fd121, %fd108, %fd108;
	fma.rn.f64 	%fd122, %fd106, %fd106, %fd121;
	fma.rn.f64 	%fd123, %fd109, %fd109, %fd122;
	mul.f64 	%fd33, %fd123, %fd120;
	ld.const.f64 	%fd124, [dc_g];
	mul.f64 	%fd125, %fd119, %fd124;
	mul.f64 	%fd126, %fd119, %fd125;
	mul.f64 	%fd127, %fd98, %fd126;
	mul.f64 	%fd34, %fd99, %fd127;
	mov.f64 	%fd128, 0d3FF5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd128;
	}
	bfe.u32 	%r30, %r10, 20, 11;
	add.s32 	%r31, %r30, -1012;
	mov.u64 	%rd92, 4608683618675807573;
	shl.b64 	%rd13, %rd92, %r31;
	setp.eq.s64	%p41, %rd13, -9223372036854775808;
	abs.f64 	%fd35, %fd2;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd35;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd128;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd156, [retval0+0];
	
	//{
	}// Callseq End 1
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd2;
	}
	setp.lt.s32	%p42, %r11, 0;
	and.pred  	%p1, %p42, %p41;
	@!%p1 bra 	BB18_24;
	bra.uni 	BB18_23;

BB18_23:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd156;
	}
	xor.b32  	%r33, %r32, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd156;
	}
	mov.b64 	%fd156, {%r34, %r33};

BB18_24:
	mov.f64 	%fd155, %fd156;
	setp.eq.f64	%p43, %fd2, 0d0000000000000000;
	@%p43 bra 	BB18_27;
	bra.uni 	BB18_25;

BB18_27:
	selp.b32	%r35, %r11, 0, %p41;
	or.b32  	%r36, %r35, 2146435072;
	setp.lt.s32	%p47, %r10, 0;
	selp.b32	%r37, %r36, %r35, %p47;
	mov.u32 	%r38, 0;
	mov.b64 	%fd155, {%r38, %r37};
	bra.uni 	BB18_28;

BB18_25:
	setp.gt.s32	%p44, %r11, -1;
	@%p44 bra 	BB18_28;

	cvt.rzi.f64.f64	%fd130, %fd128;
	setp.neu.f64	%p45, %fd130, 0d3FF5555555555555;
	selp.f64	%fd155, 0dFFF8000000000000, %fd155, %p45;

BB18_28:
	mov.f64 	%fd41, %fd155;
	add.f64 	%fd42, %fd2, 0d3FF5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd42;
	}
	and.b32  	%r40, %r39, 2146435072;
	setp.ne.s32	%p48, %r40, 2146435072;
	mov.f64 	%fd154, %fd41;
	@%p48 bra 	BB18_35;

	setp.gtu.f64	%p49, %fd35, 0d7FF0000000000000;
	mov.f64 	%fd154, %fd42;
	@%p49 bra 	BB18_35;

	abs.f64 	%fd43, %fd128;
	setp.gtu.f64	%p50, %fd43, 0d7FF0000000000000;
	mov.f64 	%fd153, %fd42;
	mov.f64 	%fd154, %fd153;
	@%p50 bra 	BB18_35;

	setp.eq.f64	%p51, %fd43, 0d7FF0000000000000;
	@%p51 bra 	BB18_34;
	bra.uni 	BB18_32;

BB18_34:
	setp.gt.f64	%p53, %fd35, 0d3FF0000000000000;
	selp.b32	%r47, 2146435072, 0, %p53;
	xor.b32  	%r48, %r47, 2146435072;
	setp.lt.s32	%p54, %r10, 0;
	selp.b32	%r49, %r48, %r47, %p54;
	setp.eq.f64	%p55, %fd2, 0dBFF0000000000000;
	selp.b32	%r50, 1072693248, %r49, %p55;
	mov.u32 	%r51, 0;
	mov.b64 	%fd154, {%r51, %r50};
	bra.uni 	BB18_35;

BB18_32:
	setp.neu.f64	%p52, %fd35, 0d7FF0000000000000;
	mov.f64 	%fd154, %fd41;
	@%p52 bra 	BB18_35;

	shr.s32 	%r41, %r10, 31;
	and.b32  	%r42, %r41, -2146435072;
	add.s32 	%r43, %r42, 2146435072;
	or.b32  	%r44, %r43, -2147483648;
	selp.b32	%r45, %r44, %r43, %p1;
	mov.u32 	%r46, 0;
	mov.b64 	%fd154, {%r46, %r45};

BB18_35:
	setp.eq.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.f64	%fd132, 0d3FF0000000000000, %fd154, %p56;
	div.rn.f64 	%fd133, %fd34, %fd132;
	add.f64 	%fd134, %fd33, %fd133;
	ld.const.u64 	%rd93, [dc_Pk];
	cvta.to.global.u64 	%rd94, %rd93;
	add.s64 	%rd96, %rd94, %rd21;
	st.global.f64 	[%rd96], %fd134;

BB18_39:
	ret;
}

	// .globl	gpu_calcPhi2Phi4
.visible .entry gpu_calcPhi2Phi4(
	.param .u32 gpu_calcPhi2Phi4_param_0,
	.param .u64 gpu_calcPhi2Phi4_param_1,
	.param .u64 gpu_calcPhi2Phi4_param_2,
	.param .u64 gpu_calcPhi2Phi4_param_3
)
{
	.reg .pred 	%p<78>;
	.reg .b16 	%rs<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<152>;
	.reg .b64 	%rd<81>;


	ld.param.u64 	%rd7, [gpu_calcPhi2Phi4_param_1];
	ld.param.u64 	%rd8, [gpu_calcPhi2Phi4_param_2];
	ld.param.u64 	%rd9, [gpu_calcPhi2Phi4_param_3];
	cvta.to.global.u64 	%rd1, %rd7;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r1, %r8, %r9, %r10;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r11, %r12, %r13;
	setp.gt.s32	%p7, %r1, 1;
	ld.const.u32 	%r14, [dc_ny];
	add.s32 	%r15, %r14, -2;
	setp.lt.s32	%p8, %r1, %r15;
	and.pred  	%p9, %p7, %p8;
	setp.gt.s32	%p10, %r2, 1;
	and.pred  	%p11, %p9, %p10;
	ld.const.u32 	%r16, [dc_nx];
	add.s32 	%r17, %r16, -2;
	setp.lt.s32	%p12, %r2, %r17;
	and.pred  	%p13, %p11, %p12;
	@!%p13 bra 	BB19_50;
	bra.uni 	BB19_1;

BB19_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	ld.const.u64 	%rd10, [dc_a];
	cvta.to.global.u64 	%rd2, %rd10;
	cvt.u64.u32	%rd3, %r4;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd2, %rd11;
	ld.global.u8 	%r5, [%rd12];
	setp.eq.s32	%p14, %r5, 255;
	@%p14 bra 	BB19_49;
	bra.uni 	BB19_2;

BB19_49:
	ld.const.u64 	%rd73, [dc_phi2];
	cvta.to.global.u64 	%rd74, %rd73;
	shl.b64 	%rd75, %rd3, 3;
	add.s64 	%rd76, %rd74, %rd75;
	mov.u64 	%rd77, 0;
	st.global.u64 	[%rd76], %rd77;
	ld.const.u64 	%rd78, [dc_phi4];
	cvta.to.global.u64 	%rd79, %rd78;
	add.s64 	%rd80, %rd79, %rd75;
	st.global.u64 	[%rd80], %rd77;
	bra.uni 	BB19_50;

BB19_2:
	ld.const.u64 	%rd13, [dc_zc];
	cvta.to.global.u64 	%rd4, %rd13;
	shl.b64 	%rd14, %rd3, 3;
	add.s64 	%rd15, %rd4, %rd14;
	ld.global.f64 	%fd1, [%rd15];
	ld.const.f64 	%fd2, [dc_wetDepthThreshold];
	add.s64 	%rd16, %rd1, %rd14;
	ld.global.f64 	%fd68, [%rd16];
	setp.gt.f64	%p15, %fd68, %fd2;
	ld.const.f64 	%fd3, [dc_dryDepthThreshold];
	selp.f64	%fd4, %fd68, %fd3, %p15;
	add.s32 	%r18, %r3, %r4;
	cvt.u64.u32	%rd5, %r18;
	mul.wide.u32 	%rd17, %r18, 4;
	add.s64 	%rd18, %rd2, %rd17;
	ld.global.u8 	%r19, [%rd18];
	setp.ne.s32	%p16, %r19, 255;
	setp.eq.s32	%p17, %r5, 0;
	and.pred  	%p18, %p17, %p16;
	setp.eq.s32	%p19, %r19, 0;
	setp.ne.s32	%p20, %r5, 0;
	and.pred  	%p21, %p19, %p20;
	or.pred  	%p22, %p18, %p21;
	mov.f64 	%fd67, 0d0000000000000000;
	mov.f64 	%fd151, %fd67;
	@!%p22 bra 	BB19_25;
	bra.uni 	BB19_3;

BB19_3:
	ld.const.u8 	%rs1, [dc_switches+1];
	and.b16  	%rs2, %rs1, 4;
	setp.eq.s16	%p23, %rs2, 0;
	mov.f64 	%fd124, 0d3FF0000000000000;
	@%p23 bra 	BB19_5;

	ld.const.u64 	%rd19, [dc_uFlowWidth];
	cvta.to.global.u64 	%rd20, %rd19;
	add.s64 	%rd22, %rd20, %rd14;
	ld.global.f64 	%fd124, [%rd22];

BB19_5:
	cvta.to.global.u64 	%rd23, %rd8;
	ld.const.u64 	%rd24, [dc_zu];
	cvta.to.global.u64 	%rd25, %rd24;
	add.s64 	%rd27, %rd25, %rd14;
	ld.global.f64 	%fd7, [%rd27];
	shl.b64 	%rd28, %rd5, 3;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f64 	%fd70, [%rd29];
	setp.gt.f64	%p24, %fd70, %fd2;
	selp.f64	%fd8, %fd70, %fd3, %p24;
	add.s64 	%rd30, %rd4, %rd28;
	ld.global.f64 	%fd71, [%rd30];
	add.f64 	%fd9, %fd71, %fd8;
	add.s64 	%rd31, %rd23, %rd14;
	ld.global.f64 	%fd10, [%rd31];
	setp.gt.f64	%p25, %fd10, 0d0000000000000000;
	add.f64 	%fd11, %fd1, %fd4;
	setp.gt.f64	%p76, %fd11, %fd71;
	and.pred  	%p26, %p25, %p76;
	@%p26 bra 	BB19_7;
	bra.uni 	BB19_6;

BB19_7:
	sub.f64 	%fd125, %fd11, %fd7;
	bra.uni 	BB19_8;

BB19_6:
	setp.lt.f64	%p27, %fd10, 0d0000000000000000;
	setp.gt.f64	%p28, %fd9, %fd1;
	and.pred  	%p29, %p27, %p28;
	sub.f64 	%fd72, %fd9, %fd7;
	selp.f64	%fd125, %fd72, 0d0000000000000000, %p29;

BB19_8:
	setp.leu.f64	%p30, %fd125, 0d0000000000000000;
	mov.f64 	%fd149, %fd67;
	mov.f64 	%fd151, %fd149;
	@%p30 bra 	BB19_25;

	ld.const.u32 	%r6, [dc_spatialOrder];
	setp.lt.s32	%p31, %r6, 2;
	@%p31 bra 	BB19_13;

	setp.leu.f64	%p32, %fd10, 0d0000000000000000;
	@%p32 bra 	BB19_12;

	setp.lt.f64	%p76, %fd1, %fd9;

BB19_12:
	@%p76 bra 	BB19_14;
	bra.uni 	BB19_13;

BB19_14:
	mad.lo.s32 	%r20, %r3, 2, %r4;
	sub.s32 	%r21, %r4, %r3;
	mul.wide.u32 	%rd32, %r21, 4;
	add.s64 	%rd33, %rd2, %rd32;
	ld.global.u8 	%r22, [%rd33];
	mul.wide.u32 	%rd34, %r20, 4;
	add.s64 	%rd35, %rd2, %rd34;
	ld.global.u8 	%r23, [%rd35];
	mul.wide.u32 	%rd37, %r21, 8;
	add.s64 	%rd38, %rd1, %rd37;
	mul.wide.u32 	%rd39, %r20, 8;
	add.s64 	%rd40, %rd1, %rd39;
	ld.global.f64 	%fd74, [%rd38];
	setp.gt.f64	%p35, %fd74, %fd2;
	selp.f64	%fd75, %fd74, %fd3, %p35;
	ld.global.f64 	%fd76, [%rd40];
	setp.gt.f64	%p36, %fd76, %fd2;
	selp.f64	%fd77, %fd76, %fd3, %p36;
	setp.eq.s32	%p37, %r22, 255;
	selp.f64	%fd16, %fd4, %fd75, %p37;
	setp.eq.s32	%p38, %r23, 255;
	selp.f64	%fd17, %fd8, %fd77, %p38;
	@%p25 bra 	BB19_16;
	bra.uni 	BB19_15;

BB19_16:
	sub.f64 	%fd126, %fd4, %fd16;
	sub.f64 	%fd127, %fd8, %fd16;
	sub.f64 	%fd128, %fd8, %fd4;
	mov.f64 	%fd146, %fd4;
	bra.uni 	BB19_17;

BB19_13:
	selp.f64	%fd144, %fd4, %fd8, %p25;

BB19_24:
	setp.lt.f64	%p44, %fd144, %fd125;
	selp.f64	%fd91, %fd144, %fd125, %p44;
	setp.gt.f64	%p45, %fd91, %fd2;
	ld.const.f64 	%fd92, [dc_dy];
	mul.f64 	%fd93, %fd124, %fd92;
	mul.f64 	%fd94, %fd91, %fd93;
	mul.f64 	%fd95, %fd10, %fd94;
	selp.f64	%fd34, %fd95, 0d0000000000000000, %p45;
	mov.f64 	%fd151, %fd34;

BB19_25:
	mov.f64 	%fd35, %fd151;
	add.s32 	%r24, %r4, 1;
	cvt.u64.u32	%rd6, %r24;
	mul.wide.u32 	%rd41, %r24, 4;
	add.s64 	%rd42, %rd2, %rd41;
	ld.global.u8 	%r25, [%rd42];
	setp.ne.s32	%p46, %r25, 255;
	and.pred  	%p48, %p17, %p46;
	setp.eq.s32	%p49, %r25, 0;
	and.pred  	%p51, %p49, %p20;
	or.pred  	%p52, %p48, %p51;
	mov.f64 	%fd150, %fd67;
	@!%p52 bra 	BB19_48;
	bra.uni 	BB19_26;

BB19_26:
	ld.const.u8 	%rs3, [dc_switches+1];
	and.b16  	%rs4, %rs3, 4;
	setp.eq.s16	%p53, %rs4, 0;
	mov.f64 	%fd129, 0d3FF0000000000000;
	@%p53 bra 	BB19_28;

	ld.const.u64 	%rd43, [dc_vFlowWidth];
	cvta.to.global.u64 	%rd44, %rd43;
	add.s64 	%rd46, %rd44, %rd14;
	ld.global.f64 	%fd129, [%rd46];

BB19_28:
	ld.const.u64 	%rd47, [dc_zv];
	cvta.to.global.u64 	%rd48, %rd47;
	add.s64 	%rd50, %rd48, %rd14;
	ld.global.f64 	%fd38, [%rd50];
	shl.b64 	%rd52, %rd6, 3;
	add.s64 	%rd53, %rd1, %rd52;
	ld.global.f64 	%fd98, [%rd53];
	setp.gt.f64	%p54, %fd98, %fd2;
	selp.f64	%fd39, %fd98, %fd3, %p54;
	cvta.to.global.u64 	%rd54, %rd9;
	add.s64 	%rd55, %rd54, %rd14;
	add.s64 	%rd56, %rd4, %rd52;
	ld.global.f64 	%fd99, [%rd56];
	add.f64 	%fd40, %fd99, %fd39;
	ld.global.f64 	%fd41, [%rd55];
	setp.gt.f64	%p55, %fd41, 0d0000000000000000;
	add.f64 	%fd42, %fd1, %fd4;
	setp.gt.f64	%p77, %fd42, %fd99;
	and.pred  	%p56, %p55, %p77;
	@%p56 bra 	BB19_30;
	bra.uni 	BB19_29;

BB19_30:
	sub.f64 	%fd130, %fd42, %fd38;
	bra.uni 	BB19_31;

BB19_29:
	setp.lt.f64	%p57, %fd41, 0d0000000000000000;
	setp.gt.f64	%p58, %fd40, %fd1;
	and.pred  	%p59, %p57, %p58;
	sub.f64 	%fd100, %fd40, %fd38;
	selp.f64	%fd130, %fd100, 0d0000000000000000, %p59;

BB19_31:
	setp.leu.f64	%p60, %fd130, 0d0000000000000000;
	mov.f64 	%fd150, %fd67;
	@%p60 bra 	BB19_48;

	ld.const.u32 	%r7, [dc_spatialOrder];
	setp.lt.s32	%p61, %r7, 2;
	@%p61 bra 	BB19_36;

	setp.leu.f64	%p62, %fd41, 0d0000000000000000;
	@%p62 bra 	BB19_35;

	setp.lt.f64	%p77, %fd1, %fd40;

BB19_35:
	@%p77 bra 	BB19_37;
	bra.uni 	BB19_36;

BB19_37:
	add.s32 	%r26, %r4, -1;
	mul.wide.u32 	%rd57, %r26, 4;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.u8 	%r27, [%rd58];
	add.s32 	%r28, %r4, 2;
	mul.wide.u32 	%rd59, %r28, 4;
	add.s64 	%rd60, %rd2, %rd59;
	ld.global.u8 	%r29, [%rd60];
	mul.wide.u32 	%rd62, %r26, 8;
	add.s64 	%rd63, %rd1, %rd62;
	mul.wide.u32 	%rd64, %r28, 8;
	add.s64 	%rd65, %rd1, %rd64;
	ld.global.f64 	%fd102, [%rd63];
	setp.gt.f64	%p65, %fd102, %fd2;
	selp.f64	%fd103, %fd102, %fd3, %p65;
	ld.global.f64 	%fd104, [%rd65];
	setp.gt.f64	%p66, %fd104, %fd2;
	selp.f64	%fd105, %fd104, %fd3, %p66;
	setp.eq.s32	%p67, %r27, 255;
	selp.f64	%fd47, %fd4, %fd103, %p67;
	setp.eq.s32	%p68, %r29, 255;
	selp.f64	%fd48, %fd39, %fd105, %p68;
	@%p55 bra 	BB19_39;
	bra.uni 	BB19_38;

BB19_39:
	sub.f64 	%fd131, %fd4, %fd47;
	sub.f64 	%fd132, %fd39, %fd47;
	sub.f64 	%fd133, %fd39, %fd4;
	mov.f64 	%fd134, %fd4;
	mov.f64 	%fd143, %fd134;
	bra.uni 	BB19_40;

BB19_36:
	selp.f64	%fd141, %fd4, %fd39, %p55;

BB19_47:
	setp.lt.f64	%p74, %fd141, %fd130;
	selp.f64	%fd119, %fd141, %fd130, %p74;
	setp.gt.f64	%p75, %fd119, %fd2;
	ld.const.f64 	%fd120, [dc_dx];
	mul.f64 	%fd121, %fd129, %fd120;
	mul.f64 	%fd122, %fd119, %fd121;
	mul.f64 	%fd123, %fd41, %fd122;
	selp.f64	%fd150, %fd123, 0d0000000000000000, %p75;

BB19_48:
	ld.const.u64 	%rd66, [dc_phi2];
	cvta.to.global.u64 	%rd67, %rd66;
	add.s64 	%rd69, %rd67, %rd14;
	st.global.f64 	[%rd69], %fd35;
	ld.const.u64 	%rd70, [dc_phi4];
	cvta.to.global.u64 	%rd71, %rd70;
	add.s64 	%rd72, %rd71, %rd14;
	st.global.f64 	[%rd72], %fd150;

BB19_50:
	ret;

BB19_15:
	sub.f64 	%fd126, %fd8, %fd17;
	sub.f64 	%fd127, %fd4, %fd17;
	sub.f64 	%fd128, %fd4, %fd8;
	mov.f64 	%fd146, %fd8;

BB19_17:
	mov.f64 	%fd135, %fd146;
	mov.f64 	%fd24, %fd135;
	mul.f64 	%fd78, %fd126, %fd128;
	setp.leu.f64	%p39, %fd78, 0d0000000000000000;
	mov.f64 	%fd144, %fd24;
	@%p39 bra 	BB19_24;

	setp.eq.s32	%p40, %r6, 2;
	@%p40 bra 	BB19_21;
	bra.uni 	BB19_19;

BB19_21:
	add.f64 	%fd83, %fd4, %fd8;
	mul.f64 	%fd145, %fd83, 0d3FE0000000000000;
	bra.uni 	BB19_22;

BB19_38:
	sub.f64 	%fd131, %fd39, %fd48;
	sub.f64 	%fd132, %fd4, %fd48;
	sub.f64 	%fd133, %fd4, %fd39;
	mov.f64 	%fd143, %fd39;

BB19_40:
	mov.f64 	%fd138, %fd143;
	mov.f64 	%fd55, %fd138;
	mul.f64 	%fd106, %fd131, %fd133;
	setp.leu.f64	%p69, %fd106, 0d0000000000000000;
	mov.f64 	%fd141, %fd55;
	@%p69 bra 	BB19_47;

	setp.eq.s32	%p70, %r7, 2;
	@%p70 bra 	BB19_44;
	bra.uni 	BB19_42;

BB19_44:
	add.f64 	%fd111, %fd4, %fd39;
	mul.f64 	%fd142, %fd111, 0d3FE0000000000000;
	bra.uni 	BB19_45;

BB19_19:
	setp.ne.s32	%p41, %r6, 4;
	mov.f64 	%fd145, %fd24;
	@%p41 bra 	BB19_22;

	add.f64 	%fd79, %fd4, %fd8;
	mul.f64 	%fd80, %fd79, 0d4022000000000000;
	add.f64 	%fd81, %fd16, %fd17;
	sub.f64 	%fd82, %fd80, %fd81;
	mul.f64 	%fd145, %fd82, 0d3FB0000000000000;

BB19_22:
	mov.f64 	%fd30, %fd145;
	div.rn.f64 	%fd84, %fd126, %fd127;
	setp.lt.f64	%p42, %fd84, 0d3FE0000000000000;
	mov.f64 	%fd85, 0d3FF0000000000000;
	sub.f64 	%fd86, %fd85, %fd84;
	selp.f64	%fd87, %fd84, %fd86, %p42;
	mul.f64 	%fd31, %fd87, 0d4024000000000000;
	setp.geu.f64	%p43, %fd31, 0d3FF0000000000000;
	mov.f64 	%fd144, %fd30;
	@%p43 bra 	BB19_24;

	sub.f64 	%fd89, %fd85, %fd31;
	mul.f64 	%fd90, %fd24, %fd89;
	fma.rn.f64 	%fd144, %fd30, %fd31, %fd90;
	bra.uni 	BB19_24;

BB19_42:
	setp.ne.s32	%p71, %r7, 4;
	mov.f64 	%fd142, %fd55;
	@%p71 bra 	BB19_45;

	add.f64 	%fd107, %fd4, %fd39;
	mul.f64 	%fd108, %fd107, 0d4022000000000000;
	add.f64 	%fd109, %fd47, %fd48;
	sub.f64 	%fd110, %fd108, %fd109;
	mul.f64 	%fd142, %fd110, 0d3FB0000000000000;

BB19_45:
	mov.f64 	%fd61, %fd142;
	div.rn.f64 	%fd112, %fd131, %fd132;
	setp.lt.f64	%p72, %fd112, 0d3FE0000000000000;
	mov.f64 	%fd113, 0d3FF0000000000000;
	sub.f64 	%fd114, %fd113, %fd112;
	selp.f64	%fd115, %fd112, %fd114, %p72;
	mul.f64 	%fd62, %fd115, 0d4024000000000000;
	setp.geu.f64	%p73, %fd62, 0d3FF0000000000000;
	mov.f64 	%fd141, %fd61;
	@%p73 bra 	BB19_47;

	sub.f64 	%fd117, %fd113, %fd62;
	mul.f64 	%fd118, %fd55, %fd117;
	fma.rn.f64 	%fd141, %fd61, %fd62, %fd118;
	bra.uni 	BB19_47;
}

	// .globl	gpu_calcDerivsSpatialHKB
.visible .entry gpu_calcDerivsSpatialHKB(
	.param .u32 gpu_calcDerivsSpatialHKB_param_0,
	.param .f64 gpu_calcDerivsSpatialHKB_param_1,
	.param .f64 gpu_calcDerivsSpatialHKB_param_2,
	.param .u64 gpu_calcDerivsSpatialHKB_param_3,
	.param .u64 gpu_calcDerivsSpatialHKB_param_4,
	.param .u64 gpu_calcDerivsSpatialHKB_param_5,
	.param .u64 gpu_calcDerivsSpatialHKB_param_6,
	.param .u64 gpu_calcDerivsSpatialHKB_param_7,
	.param .u64 gpu_calcDerivsSpatialHKB_param_8,
	.param .u64 gpu_calcDerivsSpatialHKB_param_9,
	.param .u64 gpu_calcDerivsSpatialHKB_param_10,
	.param .u64 gpu_calcDerivsSpatialHKB_param_11
)
{
	.local .align 8 .b8 	__local_depot20[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<115>;
	.reg .f32 	%f<17>;
	.reg .b32 	%r<66>;
	.reg .f64 	%fd<506>;
	.reg .b64 	%rd<174>;


	mov.u64 	%rd173, __local_depot20;
	cvta.local.u64 	%SP, %rd173;
	ld.param.f64 	%fd190, [gpu_calcDerivsSpatialHKB_param_2];
	ld.param.u64 	%rd20, [gpu_calcDerivsSpatialHKB_param_3];
	ld.param.u64 	%rd25, [gpu_calcDerivsSpatialHKB_param_6];
	ld.param.u64 	%rd22, [gpu_calcDerivsSpatialHKB_param_8];
	ld.param.u64 	%rd26, [gpu_calcDerivsSpatialHKB_param_11];
	cvta.to.global.u64 	%rd1, %rd25;
	cvta.to.global.u64 	%rd2, %rd26;
	add.u64 	%rd27, %SP, 0;
	cvta.to.local.u64 	%rd3, %rd27;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r3, %r1, %r17, %r2;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r4, %tid.y;
	mad.lo.s32 	%r5, %r18, %r19, %r4;
	setp.gt.s32	%p1, %r3, 1;
	ld.const.u32 	%r20, [dc_ny];
	add.s32 	%r21, %r20, -2;
	setp.lt.s32	%p2, %r3, %r21;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r5, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r22, [dc_nx];
	add.s32 	%r23, %r22, -2;
	setp.lt.s32	%p6, %r5, %r23;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB20_123;
	bra.uni 	BB20_1;

BB20_1:
	ld.const.u32 	%r6, [dc_nyPadded];
	mad.lo.s32 	%r7, %r6, %r5, %r3;
	ld.const.u64 	%rd28, [dc_a];
	cvta.to.global.u64 	%rd4, %rd28;
	cvt.u64.u32	%rd5, %r7;
	mul.wide.u32 	%rd29, %r7, 4;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%r8, [%rd30];
	setp.eq.s32	%p8, %r8, 255;
	@%p8 bra 	BB20_123;

	sub.s32 	%r24, %r7, %r6;
	cvt.u64.u32	%rd6, %r24;
	mul.wide.u32 	%rd31, %r24, 4;
	add.s64 	%rd32, %rd4, %rd31;
	ld.global.u8 	%r9, [%rd32];
	add.s32 	%r25, %r6, %r7;
	cvt.u64.u32	%rd7, %r25;
	mul.wide.u32 	%rd33, %r25, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.u8 	%r10, [%rd34];
	add.s32 	%r26, %r7, -1;
	cvt.u64.u32	%rd8, %r26;
	mul.wide.u32 	%rd35, %r26, 4;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.u8 	%r11, [%rd36];
	add.s32 	%r27, %r7, 1;
	cvt.u64.u32	%rd9, %r27;
	mul.wide.u32 	%rd37, %r27, 4;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u8 	%r12, [%rd38];
	ld.const.u64 	%rd39, [dc_phi2];
	cvta.to.global.u64 	%rd40, %rd39;
	mul.wide.u32 	%rd41, %r24, 8;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.f64 	%fd1, [%rd42];
	shl.b64 	%rd43, %rd5, 3;
	add.s64 	%rd44, %rd40, %rd43;
	ld.global.f64 	%fd2, [%rd44];
	ld.const.u64 	%rd45, [dc_phi4];
	cvta.to.global.u64 	%rd46, %rd45;
	mul.wide.u32 	%rd47, %r26, 8;
	add.s64 	%rd48, %rd46, %rd47;
	ld.global.f64 	%fd4, [%rd48];
	add.s64 	%rd49, %rd46, %rd43;
	ld.global.f64 	%fd5, [%rd49];
	ld.const.f64 	%fd7, [dc_dx];
	ld.const.f64 	%fd8, [dc_dy];
	mul.f64 	%fd9, %fd8, %fd7;
	ld.const.u32 	%r13, [dc_switches];
	and.b32  	%r28, %r13, 1024;
	setp.eq.s32	%p9, %r28, 0;
	mov.f64 	%fd423, 0d3FF0000000000000;
	@%p9 bra 	BB20_4;

	ld.const.u64 	%rd50, [dc_areaFactor];
	cvta.to.global.u64 	%rd51, %rd50;
	add.s64 	%rd53, %rd51, %rd43;
	ld.global.f64 	%fd423, [%rd53];

BB20_4:
	ld.const.u64 	%rd54, [dc_rf];
	cvta.to.global.u64 	%rd55, %rd54;
	add.s64 	%rd57, %rd55, %rd43;
	ld.const.u64 	%rd58, [dc_sa];
	cvta.to.global.u64 	%rd59, %rd58;
	add.s64 	%rd60, %rd59, %rd43;
	ld.global.f64 	%fd192, [%rd60];
	ld.global.f64 	%fd193, [%rd57];
	add.f64 	%fd424, %fd193, %fd192;
	and.b32  	%r29, %r13, 8;
	setp.eq.s32	%p10, %r29, 0;
	@%p10 bra 	BB20_6;

	ld.const.u64 	%rd61, [dc_ir];
	cvta.to.global.u64 	%rd62, %rd61;
	add.s64 	%rd64, %rd62, %rd43;
	ld.global.f64 	%fd194, [%rd64];
	mul.f64 	%fd195, %fd423, %fd194;
	sub.f64 	%fd424, %fd424, %fd195;

BB20_6:
	and.b32  	%r30, %r13, 458752;
	setp.eq.s32	%p11, %r30, 0;
	mov.f64 	%fd425, 0d0000000000000000;
	@%p11 bra 	BB20_8;

	ld.const.u64 	%rd65, [dc_sx];
	cvta.to.global.u64 	%rd66, %rd65;
	add.s64 	%rd68, %rd66, %rd43;
	ld.global.f64 	%fd425, [%rd68];

BB20_8:
	sub.f64 	%fd197, %fd1, %fd2;
	add.f64 	%fd198, %fd197, %fd4;
	sub.f64 	%fd17, %fd198, %fd5;
	and.b32  	%r31, %r13, 2048;
	setp.eq.s32	%p12, %r31, 0;
	@%p12 bra 	BB20_32;

	mov.u64 	%rd69, 0;
	st.local.u64 	[%rd3], %rd69;
	st.local.u64 	[%rd3+8], %rd69;
	st.local.u64 	[%rd3+16], %rd69;
	st.local.u64 	[%rd3+24], %rd69;
	st.local.u64 	[%rd3+32], %rd69;
	st.local.u64 	[%rd3+40], %rd69;
	st.local.u64 	[%rd3+48], %rd69;
	st.local.u64 	[%rd3+56], %rd69;
	setp.eq.s32	%p13, %r8, 0;
	@%p13 bra 	BB20_13;

	setp.eq.s32	%p14, %r8, 254;
	setp.eq.s32	%p15, %r8, 253;
	selp.b32	%r32, 6, 2, %p15;
	selp.b32	%r14, 4, %r32, %p14;
	setp.gt.f64	%p16, %fd17, 0d0000000000000000;
	@%p16 bra 	BB20_12;
	bra.uni 	BB20_11;

BB20_12:
	add.s32 	%r33, %r14, 1;
	mul.wide.u32 	%rd72, %r33, 8;
	add.s64 	%rd73, %rd3, %rd72;
	st.local.f64 	[%rd73], %fd17;
	bra.uni 	BB20_16;

BB20_13:
	setp.lt.f64	%p17, %fd424, 0d0000000000000000;
	mul.f64 	%fd18, %fd9, %fd424;
	@%p17 bra 	BB20_15;
	bra.uni 	BB20_14;

BB20_15:
	neg.f64 	%fd200, %fd18;
	st.local.f64 	[%rd3+8], %fd200;
	bra.uni 	BB20_16;

BB20_11:
	neg.f64 	%fd199, %fd17;
	mul.wide.u32 	%rd70, %r14, 8;
	add.s64 	%rd71, %rd3, %rd70;
	st.local.f64 	[%rd71], %fd199;
	bra.uni 	BB20_16;

BB20_14:
	st.local.f64 	[%rd3], %fd18;

BB20_16:
	mad.lo.s32 	%r34, %r4, %r1, %r2;
	and.b32  	%r35, %r34, 31;
	shl.b32 	%r36, %r35, 3;
	cvt.u64.u32	%rd11, %r36;
	ld.local.f64 	%fd19, [%rd3];
	setp.leu.f64	%p18, %fd19, 0d0000000000000000;
	@%p18 bra 	BB20_18;

	shl.b64 	%rd74, %rd11, 2;
	add.s64 	%rd75, %rd2, %rd74;
	cvt.rn.f32.f64	%f1, %fd19;
	atom.global.add.f32 	%f2, [%rd75], %f1;

BB20_18:
	ld.local.f64 	%fd20, [%rd3+8];
	setp.leu.f64	%p19, %fd20, 0d0000000000000000;
	@%p19 bra 	BB20_20;

	shl.b64 	%rd76, %rd11, 2;
	add.s64 	%rd77, %rd76, %rd2;
	add.s64 	%rd78, %rd77, 4;
	cvt.rn.f32.f64	%f3, %fd20;
	atom.global.add.f32 	%f4, [%rd78], %f3;

BB20_20:
	ld.local.f64 	%fd21, [%rd3+16];
	setp.leu.f64	%p20, %fd21, 0d0000000000000000;
	@%p20 bra 	BB20_22;

	shl.b64 	%rd79, %rd11, 2;
	add.s64 	%rd80, %rd79, %rd2;
	add.s64 	%rd81, %rd80, 8;
	cvt.rn.f32.f64	%f5, %fd21;
	atom.global.add.f32 	%f6, [%rd81], %f5;

BB20_22:
	ld.local.f64 	%fd22, [%rd3+24];
	setp.leu.f64	%p21, %fd22, 0d0000000000000000;
	@%p21 bra 	BB20_24;

	shl.b64 	%rd82, %rd11, 2;
	add.s64 	%rd83, %rd82, %rd2;
	add.s64 	%rd84, %rd83, 12;
	cvt.rn.f32.f64	%f7, %fd22;
	atom.global.add.f32 	%f8, [%rd84], %f7;

BB20_24:
	ld.local.f64 	%fd23, [%rd3+32];
	setp.leu.f64	%p22, %fd23, 0d0000000000000000;
	@%p22 bra 	BB20_26;

	shl.b64 	%rd85, %rd11, 2;
	add.s64 	%rd86, %rd85, %rd2;
	add.s64 	%rd87, %rd86, 16;
	cvt.rn.f32.f64	%f9, %fd23;
	atom.global.add.f32 	%f10, [%rd87], %f9;

BB20_26:
	ld.local.f64 	%fd24, [%rd3+40];
	setp.leu.f64	%p23, %fd24, 0d0000000000000000;
	@%p23 bra 	BB20_28;

	shl.b64 	%rd88, %rd11, 2;
	add.s64 	%rd89, %rd88, %rd2;
	add.s64 	%rd90, %rd89, 20;
	cvt.rn.f32.f64	%f11, %fd24;
	atom.global.add.f32 	%f12, [%rd90], %f11;

BB20_28:
	ld.local.f64 	%fd25, [%rd3+48];
	setp.leu.f64	%p24, %fd25, 0d0000000000000000;
	@%p24 bra 	BB20_30;

	shl.b64 	%rd91, %rd11, 2;
	add.s64 	%rd92, %rd91, %rd2;
	add.s64 	%rd93, %rd92, 24;
	cvt.rn.f32.f64	%f13, %fd25;
	atom.global.add.f32 	%f14, [%rd93], %f13;

BB20_30:
	ld.local.f64 	%fd26, [%rd3+56];
	setp.leu.f64	%p25, %fd26, 0d0000000000000000;
	@%p25 bra 	BB20_32;

	shl.b64 	%rd94, %rd11, 2;
	add.s64 	%rd95, %rd94, %rd2;
	add.s64 	%rd96, %rd95, 28;
	cvt.rn.f32.f64	%f15, %fd26;
	atom.global.add.f32 	%f16, [%rd96], %f15;

BB20_32:
	setp.ne.s32	%p26, %r8, 0;
	@%p26 bra 	BB20_123;

	cvta.to.global.u64 	%rd97, %rd22;
	div.rn.f64 	%fd201, %fd17, %fd9;
	add.f64 	%fd202, %fd424, %fd201;
	add.f64 	%fd203, %fd425, %fd202;
	div.rn.f64 	%fd204, %fd203, %fd423;
	add.s64 	%rd99, %rd97, %rd43;
	st.global.f64 	[%rd99], %fd204;
	ld.const.u32 	%r37, [dc_turbulenceModel];
	shl.b32 	%r38, %r6, 1;
	sub.s32 	%r39, %r7, %r38;
	cvt.u64.u32	%rd12, %r39;
	mul.wide.u32 	%rd100, %r39, 4;
	add.s64 	%rd13, %rd4, %rd100;
	add.s32 	%r40, %r38, %r7;
	cvt.u64.u32	%rd14, %r40;
	mul.wide.u32 	%rd101, %r40, 4;
	add.s64 	%rd15, %rd4, %rd101;
	add.s32 	%r41, %r7, -2;
	cvt.u64.u32	%rd16, %r41;
	mul.wide.u32 	%rd102, %r41, 4;
	add.s64 	%rd17, %rd4, %rd102;
	add.s32 	%r42, %r7, 2;
	cvt.u64.u32	%rd18, %r42;
	mul.wide.u32 	%rd103, %r42, 4;
	add.s64 	%rd19, %rd4, %rd103;
	setp.ne.s32	%p27, %r37, 1;
	@%p27 bra 	BB20_78;

	cvta.to.global.u64 	%rd104, %rd20;
	add.s64 	%rd106, %rd104, %rd43;
	ld.global.f64 	%fd27, [%rd106];
	shl.b64 	%rd107, %rd6, 3;
	add.s64 	%rd108, %rd104, %rd107;
	ld.global.f64 	%fd28, [%rd108];
	shl.b64 	%rd109, %rd7, 3;
	add.s64 	%rd110, %rd104, %rd109;
	ld.global.f64 	%fd29, [%rd110];
	shl.b64 	%rd111, %rd8, 3;
	add.s64 	%rd112, %rd104, %rd111;
	ld.global.f64 	%fd30, [%rd112];
	shl.b64 	%rd113, %rd9, 3;
	add.s64 	%rd114, %rd104, %rd113;
	ld.global.f64 	%fd31, [%rd114];
	setp.eq.s32	%p28, %r9, 255;
	add.s64 	%rd115, %rd1, %rd107;
	ld.global.f64 	%fd205, [%rd115];
	add.s64 	%rd116, %rd1, %rd43;
	ld.global.f64 	%fd32, [%rd116];
	selp.f64	%fd33, %fd32, %fd205, %p28;
	setp.eq.s32	%p29, %r10, 255;
	add.s64 	%rd117, %rd1, %rd109;
	ld.global.f64 	%fd206, [%rd117];
	selp.f64	%fd34, %fd32, %fd206, %p29;
	setp.eq.s32	%p30, %r11, 255;
	add.s64 	%rd118, %rd1, %rd111;
	ld.global.f64 	%fd207, [%rd118];
	selp.f64	%fd35, %fd32, %fd207, %p30;
	setp.eq.s32	%p31, %r12, 255;
	add.s64 	%rd119, %rd1, %rd113;
	ld.global.f64 	%fd208, [%rd119];
	selp.f64	%fd36, %fd32, %fd208, %p31;
	ld.const.u64 	%rd120, [dc_l];
	cvta.to.global.u64 	%rd121, %rd120;
	add.s64 	%rd122, %rd121, %rd43;
	ld.global.f64 	%fd37, [%rd122];
	ld.const.u64 	%rd123, [dc_nut];
	cvta.to.global.u64 	%rd124, %rd123;
	add.s64 	%rd125, %rd124, %rd43;
	ld.global.f64 	%fd38, [%rd125];
	add.s64 	%rd126, %rd124, %rd107;
	ld.global.f64 	%fd39, [%rd126];
	add.s64 	%rd127, %rd124, %rd109;
	ld.global.f64 	%fd40, [%rd127];
	add.s64 	%rd128, %rd124, %rd111;
	ld.global.f64 	%fd41, [%rd128];
	add.s64 	%rd129, %rd124, %rd113;
	ld.global.f64 	%fd42, [%rd129];
	ld.const.u32 	%r15, [dc_spatialOrder];
	setp.gt.s32	%p32, %r15, 1;
	@%p32 bra 	BB20_36;
	bra.uni 	BB20_35;

BB20_36:
	setp.gt.f64	%p37, %fd1, 0d0000000000000000;
	ld.global.u8 	%r46, [%rd13];
	ld.global.u8 	%r47, [%rd15];
	ld.global.u8 	%r49, [%rd17];
	ld.global.u8 	%r51, [%rd19];
	mul.wide.u32 	%rd130, %r39, 8;
	add.s64 	%rd131, %rd1, %rd130;
	mul.wide.u32 	%rd132, %r40, 8;
	add.s64 	%rd133, %rd1, %rd132;
	mul.wide.u32 	%rd134, %r41, 8;
	add.s64 	%rd135, %rd1, %rd134;
	mul.wide.u32 	%rd136, %r42, 8;
	add.s64 	%rd137, %rd1, %rd136;
	setp.eq.s32	%p38, %r46, 255;
	ld.global.f64 	%fd216, [%rd131];
	selp.f64	%fd44, %fd33, %fd216, %p38;
	setp.eq.s32	%p39, %r47, 255;
	ld.global.f64 	%fd217, [%rd133];
	selp.f64	%fd45, %fd34, %fd217, %p39;
	setp.eq.s32	%p40, %r49, 255;
	ld.global.f64 	%fd218, [%rd135];
	selp.f64	%fd46, %fd35, %fd218, %p40;
	setp.eq.s32	%p41, %r51, 255;
	ld.global.f64 	%fd219, [%rd137];
	selp.f64	%fd47, %fd36, %fd219, %p41;
	@%p37 bra 	BB20_38;
	bra.uni 	BB20_37;

BB20_38:
	sub.f64 	%fd426, %fd33, %fd44;
	sub.f64 	%fd427, %fd32, %fd44;
	sub.f64 	%fd428, %fd32, %fd33;
	mov.f64 	%fd464, %fd33;
	bra.uni 	BB20_39;

BB20_35:
	neg.f64 	%fd422, %fd5;
	neg.f64 	%fd421, %fd2;
	setp.gt.f64	%p33, %fd1, 0d0000000000000000;
	selp.f64	%fd209, %fd33, %fd32, %p33;
	fma.rn.f64 	%fd210, %fd1, %fd209, 0d0000000000000000;
	setp.lt.f64	%p34, %fd2, 0d8000000000000000;
	selp.f64	%fd211, %fd34, %fd32, %p34;
	fma.rn.f64 	%fd212, %fd211, %fd421, %fd210;
	setp.gt.f64	%p35, %fd4, 0d0000000000000000;
	selp.f64	%fd213, %fd35, %fd32, %p35;
	fma.rn.f64 	%fd214, %fd4, %fd213, %fd212;
	setp.lt.f64	%p36, %fd5, 0d8000000000000000;
	selp.f64	%fd215, %fd36, %fd32, %p36;
	fma.rn.f64 	%fd465, %fd215, %fd422, %fd214;
	bra.uni 	BB20_77;

BB20_37:
	sub.f64 	%fd426, %fd32, %fd34;
	sub.f64 	%fd427, %fd33, %fd34;
	sub.f64 	%fd428, %fd33, %fd32;
	mov.f64 	%fd464, %fd32;

BB20_39:
	mov.f64 	%fd441, %fd464;
	mov.f64 	%fd54, %fd441;
	mul.f64 	%fd220, %fd426, %fd428;
	setp.leu.f64	%p42, %fd220, 0d0000000000000000;
	mov.f64 	%fd462, %fd54;
	@%p42 bra 	BB20_46;

	ld.const.u32 	%r64, [dc_spatialOrder];
	setp.eq.s32	%p43, %r64, 2;
	@%p43 bra 	BB20_43;
	bra.uni 	BB20_41;

BB20_43:
	add.f64 	%fd225, %fd32, %fd33;
	mul.f64 	%fd463, %fd225, 0d3FE0000000000000;
	bra.uni 	BB20_44;

BB20_41:
	ld.const.u32 	%r65, [dc_spatialOrder];
	setp.ne.s32	%p44, %r65, 4;
	mov.f64 	%fd463, %fd54;
	@%p44 bra 	BB20_44;

	add.f64 	%fd221, %fd32, %fd33;
	mul.f64 	%fd222, %fd221, 0d4022000000000000;
	add.f64 	%fd223, %fd34, %fd44;
	sub.f64 	%fd224, %fd222, %fd223;
	mul.f64 	%fd463, %fd224, 0d3FB0000000000000;

BB20_44:
	mov.f64 	%fd60, %fd463;
	div.rn.f64 	%fd226, %fd426, %fd427;
	setp.lt.f64	%p45, %fd226, 0d3FE0000000000000;
	mov.f64 	%fd227, 0d3FF0000000000000;
	sub.f64 	%fd228, %fd227, %fd226;
	selp.f64	%fd229, %fd226, %fd228, %p45;
	mul.f64 	%fd61, %fd229, 0d4024000000000000;
	setp.geu.f64	%p46, %fd61, 0d3FF0000000000000;
	mov.f64 	%fd462, %fd60;
	@%p46 bra 	BB20_46;

	sub.f64 	%fd231, %fd227, %fd61;
	mul.f64 	%fd232, %fd54, %fd231;
	fma.rn.f64 	%fd462, %fd60, %fd61, %fd232;

BB20_46:
	setp.gt.f64	%p47, %fd2, 0d0000000000000000;
	@%p47 bra 	BB20_48;
	bra.uni 	BB20_47;

BB20_48:
	sub.f64 	%fd429, %fd32, %fd33;
	sub.f64 	%fd430, %fd34, %fd33;
	sub.f64 	%fd431, %fd34, %fd32;
	mov.f64 	%fd438, %fd32;
	mov.f64 	%fd461, %fd438;
	bra.uni 	BB20_49;

BB20_47:
	sub.f64 	%fd429, %fd34, %fd45;
	sub.f64 	%fd430, %fd32, %fd45;
	sub.f64 	%fd431, %fd32, %fd34;
	mov.f64 	%fd461, %fd34;

BB20_49:
	mov.f64 	%fd444, %fd461;
	mov.f64 	%fd70, %fd444;
	mul.f64 	%fd233, %fd429, %fd431;
	setp.leu.f64	%p48, %fd233, 0d0000000000000000;
	mov.f64 	%fd459, %fd70;
	@%p48 bra 	BB20_56;

	ld.const.u32 	%r62, [dc_spatialOrder];
	setp.eq.s32	%p49, %r62, 2;
	@%p49 bra 	BB20_53;
	bra.uni 	BB20_51;

BB20_53:
	add.f64 	%fd238, %fd32, %fd34;
	mul.f64 	%fd460, %fd238, 0d3FE0000000000000;
	bra.uni 	BB20_54;

BB20_51:
	ld.const.u32 	%r63, [dc_spatialOrder];
	setp.ne.s32	%p50, %r63, 4;
	mov.f64 	%fd460, %fd70;
	@%p50 bra 	BB20_54;

	add.f64 	%fd234, %fd32, %fd34;
	mul.f64 	%fd235, %fd234, 0d4022000000000000;
	add.f64 	%fd236, %fd33, %fd45;
	sub.f64 	%fd237, %fd235, %fd236;
	mul.f64 	%fd460, %fd237, 0d3FB0000000000000;

BB20_54:
	mov.f64 	%fd76, %fd460;
	div.rn.f64 	%fd239, %fd429, %fd430;
	setp.lt.f64	%p51, %fd239, 0d3FE0000000000000;
	mov.f64 	%fd240, 0d3FF0000000000000;
	sub.f64 	%fd241, %fd240, %fd239;
	selp.f64	%fd242, %fd239, %fd241, %p51;
	mul.f64 	%fd77, %fd242, 0d4024000000000000;
	setp.geu.f64	%p52, %fd77, 0d3FF0000000000000;
	mov.f64 	%fd459, %fd76;
	@%p52 bra 	BB20_56;

	sub.f64 	%fd244, %fd240, %fd77;
	mul.f64 	%fd245, %fd70, %fd244;
	fma.rn.f64 	%fd459, %fd76, %fd77, %fd245;

BB20_56:
	setp.gt.f64	%p53, %fd4, 0d0000000000000000;
	@%p53 bra 	BB20_58;
	bra.uni 	BB20_57;

BB20_58:
	sub.f64 	%fd432, %fd35, %fd46;
	sub.f64 	%fd433, %fd32, %fd46;
	sub.f64 	%fd434, %fd32, %fd35;
	mov.f64 	%fd458, %fd35;
	bra.uni 	BB20_59;

BB20_57:
	sub.f64 	%fd432, %fd32, %fd36;
	sub.f64 	%fd433, %fd35, %fd36;
	sub.f64 	%fd434, %fd35, %fd32;
	mov.f64 	%fd439, %fd32;
	mov.f64 	%fd458, %fd439;

BB20_59:
	mov.f64 	%fd447, %fd458;
	mov.f64 	%fd86, %fd447;
	mul.f64 	%fd246, %fd432, %fd434;
	setp.leu.f64	%p54, %fd246, 0d0000000000000000;
	mov.f64 	%fd456, %fd86;
	@%p54 bra 	BB20_66;

	ld.const.u32 	%r60, [dc_spatialOrder];
	setp.eq.s32	%p55, %r60, 2;
	@%p55 bra 	BB20_63;
	bra.uni 	BB20_61;

BB20_63:
	add.f64 	%fd251, %fd32, %fd35;
	mul.f64 	%fd457, %fd251, 0d3FE0000000000000;
	bra.uni 	BB20_64;

BB20_61:
	ld.const.u32 	%r61, [dc_spatialOrder];
	setp.ne.s32	%p56, %r61, 4;
	mov.f64 	%fd457, %fd86;
	@%p56 bra 	BB20_64;

	add.f64 	%fd247, %fd32, %fd35;
	mul.f64 	%fd248, %fd247, 0d4022000000000000;
	add.f64 	%fd249, %fd36, %fd46;
	sub.f64 	%fd250, %fd248, %fd249;
	mul.f64 	%fd457, %fd250, 0d3FB0000000000000;

BB20_64:
	mov.f64 	%fd92, %fd457;
	div.rn.f64 	%fd252, %fd432, %fd433;
	setp.lt.f64	%p57, %fd252, 0d3FE0000000000000;
	mov.f64 	%fd253, 0d3FF0000000000000;
	sub.f64 	%fd254, %fd253, %fd252;
	selp.f64	%fd255, %fd252, %fd254, %p57;
	mul.f64 	%fd93, %fd255, 0d4024000000000000;
	setp.geu.f64	%p58, %fd93, 0d3FF0000000000000;
	mov.f64 	%fd456, %fd92;
	@%p58 bra 	BB20_66;

	sub.f64 	%fd257, %fd253, %fd93;
	mul.f64 	%fd258, %fd86, %fd257;
	fma.rn.f64 	%fd456, %fd92, %fd93, %fd258;

BB20_66:
	setp.gt.f64	%p59, %fd5, 0d0000000000000000;
	@%p59 bra 	BB20_68;
	bra.uni 	BB20_67;

BB20_68:
	sub.f64 	%fd435, %fd32, %fd35;
	sub.f64 	%fd436, %fd36, %fd35;
	sub.f64 	%fd437, %fd36, %fd32;
	mov.f64 	%fd440, %fd32;
	mov.f64 	%fd455, %fd440;
	bra.uni 	BB20_69;

BB20_67:
	sub.f64 	%fd435, %fd36, %fd47;
	sub.f64 	%fd436, %fd32, %fd47;
	sub.f64 	%fd437, %fd32, %fd36;
	mov.f64 	%fd455, %fd36;

BB20_69:
	mov.f64 	%fd450, %fd455;
	mov.f64 	%fd102, %fd450;
	mul.f64 	%fd259, %fd435, %fd437;
	setp.leu.f64	%p60, %fd259, 0d0000000000000000;
	mov.f64 	%fd453, %fd102;
	@%p60 bra 	BB20_76;

	ld.const.u32 	%r58, [dc_spatialOrder];
	setp.eq.s32	%p61, %r58, 2;
	@%p61 bra 	BB20_73;
	bra.uni 	BB20_71;

BB20_73:
	add.f64 	%fd264, %fd32, %fd36;
	mul.f64 	%fd454, %fd264, 0d3FE0000000000000;
	bra.uni 	BB20_74;

BB20_71:
	ld.const.u32 	%r59, [dc_spatialOrder];
	setp.ne.s32	%p62, %r59, 4;
	mov.f64 	%fd454, %fd102;
	@%p62 bra 	BB20_74;

	add.f64 	%fd260, %fd32, %fd36;
	mul.f64 	%fd261, %fd260, 0d4022000000000000;
	add.f64 	%fd262, %fd35, %fd47;
	sub.f64 	%fd263, %fd261, %fd262;
	mul.f64 	%fd454, %fd263, 0d3FB0000000000000;

BB20_74:
	mov.f64 	%fd108, %fd454;
	div.rn.f64 	%fd265, %fd435, %fd436;
	setp.lt.f64	%p63, %fd265, 0d3FE0000000000000;
	mov.f64 	%fd266, 0d3FF0000000000000;
	sub.f64 	%fd267, %fd266, %fd265;
	selp.f64	%fd268, %fd265, %fd267, %p63;
	mul.f64 	%fd109, %fd268, 0d4024000000000000;
	setp.geu.f64	%p64, %fd109, 0d3FF0000000000000;
	mov.f64 	%fd453, %fd108;
	@%p64 bra 	BB20_76;

	sub.f64 	%fd270, %fd266, %fd109;
	mul.f64 	%fd271, %fd102, %fd270;
	fma.rn.f64 	%fd453, %fd108, %fd109, %fd271;

BB20_76:
	neg.f64 	%fd416, %fd5;
	neg.f64 	%fd415, %fd2;
	fma.rn.f64 	%fd272, %fd1, %fd462, 0d0000000000000000;
	fma.rn.f64 	%fd273, %fd459, %fd415, %fd272;
	fma.rn.f64 	%fd274, %fd4, %fd456, %fd273;
	fma.rn.f64 	%fd465, %fd453, %fd416, %fd274;

BB20_77:
	ld.param.u64 	%rd169, [gpu_calcDerivsSpatialHKB_param_9];
	ld.const.f64 	%fd414, [dc_dx];
	ld.const.f64 	%fd413, [dc_dy];
	ld.const.f64 	%fd275, [dc_wetDepthThreshold];
	setp.gt.f64	%p65, %fd27, %fd275;
	ld.const.f64 	%fd276, [dc_dryDepthThreshold];
	selp.f64	%fd277, %fd27, %fd276, %p65;
	setp.gt.f64	%p66, %fd28, %fd275;
	selp.f64	%fd278, %fd28, %fd276, %p66;
	setp.gt.f64	%p67, %fd29, %fd275;
	selp.f64	%fd279, %fd29, %fd276, %p67;
	setp.gt.f64	%p68, %fd30, %fd275;
	selp.f64	%fd280, %fd30, %fd276, %p68;
	setp.gt.f64	%p69, %fd31, %fd275;
	selp.f64	%fd281, %fd31, %fd276, %p69;
	setp.lt.f64	%p70, %fd278, %fd277;
	selp.f64	%fd282, %fd278, %fd277, %p70;
	mul.f64 	%fd283, %fd282, %fd413;
	add.f64 	%fd284, %fd38, %fd39;
	mul.f64 	%fd285, %fd284, %fd283;
	mul.f64 	%fd286, %fd285, 0d3FE0000000000000;
	sub.f64 	%fd287, %fd33, %fd32;
	mul.f64 	%fd288, %fd287, %fd286;
	div.rn.f64 	%fd289, %fd288, %fd414;
	add.f64 	%fd290, %fd465, %fd289;
	setp.lt.f64	%p71, %fd279, %fd277;
	selp.f64	%fd291, %fd279, %fd277, %p71;
	mul.f64 	%fd292, %fd291, %fd413;
	add.f64 	%fd293, %fd38, %fd40;
	mul.f64 	%fd294, %fd293, %fd292;
	mul.f64 	%fd295, %fd294, 0d3FE0000000000000;
	sub.f64 	%fd296, %fd34, %fd32;
	mul.f64 	%fd297, %fd296, %fd295;
	div.rn.f64 	%fd298, %fd297, %fd414;
	add.f64 	%fd299, %fd290, %fd298;
	setp.lt.f64	%p72, %fd280, %fd277;
	selp.f64	%fd300, %fd280, %fd277, %p72;
	mul.f64 	%fd301, %fd300, %fd414;
	add.f64 	%fd302, %fd38, %fd41;
	mul.f64 	%fd303, %fd302, %fd301;
	mul.f64 	%fd304, %fd303, 0d3FE0000000000000;
	sub.f64 	%fd305, %fd35, %fd32;
	mul.f64 	%fd306, %fd305, %fd304;
	div.rn.f64 	%fd307, %fd306, %fd413;
	add.f64 	%fd308, %fd299, %fd307;
	setp.lt.f64	%p73, %fd281, %fd277;
	selp.f64	%fd309, %fd281, %fd277, %p73;
	mul.f64 	%fd310, %fd309, %fd414;
	add.f64 	%fd311, %fd38, %fd42;
	mul.f64 	%fd312, %fd311, %fd310;
	mul.f64 	%fd313, %fd312, 0d3FE0000000000000;
	sub.f64 	%fd314, %fd36, %fd32;
	mul.f64 	%fd315, %fd314, %fd313;
	div.rn.f64 	%fd316, %fd315, %fd413;
	add.f64 	%fd317, %fd308, %fd316;
	mul.f64 	%fd318, %fd17, %fd32;
	sub.f64 	%fd319, %fd317, %fd318;
	mul.f64 	%fd320, %fd9, %fd277;
	div.rn.f64 	%fd321, %fd319, %fd320;
	ld.const.u64 	%rd138, [dc_Pk];
	cvta.to.global.u64 	%rd139, %rd138;
	add.s64 	%rd141, %rd139, %rd43;
	ld.global.f64 	%fd322, [%rd141];
	add.f64 	%fd323, %fd321, %fd322;
	sqrt.rn.f64 	%fd324, %fd32;
	mul.f64 	%fd325, %fd32, 0dBFB47AE147AE147B;
	mul.f64 	%fd326, %fd325, %fd324;
	div.rn.f64 	%fd327, %fd326, %fd37;
	add.f64 	%fd328, %fd323, %fd327;
	neg.f64 	%fd329, %fd32;
	div.rn.f64 	%fd330, %fd329, %fd190;
	setp.gt.f64	%p74, %fd328, %fd330;
	selp.f64	%fd331, %fd328, %fd330, %p74;
	cvta.to.global.u64 	%rd142, %rd169;
	add.s64 	%rd143, %rd142, %rd43;
	st.global.f64 	[%rd143], %fd331;

BB20_78:
	ld.const.u32 	%r57, [dc_switches];
	and.b32  	%r52, %r57, 8192;
	setp.eq.s32	%p75, %r52, 0;
	@%p75 bra 	BB20_123;

	ld.param.u64 	%rd170, [gpu_calcDerivsSpatialHKB_param_7];
	cvta.to.global.u64 	%rd144, %rd170;
	add.s64 	%rd146, %rd144, %rd43;
	shl.b64 	%rd147, %rd6, 3;
	add.s64 	%rd148, %rd144, %rd147;
	shl.b64 	%rd149, %rd7, 3;
	add.s64 	%rd150, %rd144, %rd149;
	shl.b64 	%rd151, %rd8, 3;
	add.s64 	%rd152, %rd144, %rd151;
	shl.b64 	%rd153, %rd9, 3;
	add.s64 	%rd154, %rd144, %rd153;
	setp.eq.s32	%p76, %r9, 255;
	ld.global.f64 	%fd332, [%rd148];
	ld.global.f64 	%fd114, [%rd146];
	selp.f64	%fd115, %fd114, %fd332, %p76;
	setp.eq.s32	%p77, %r10, 255;
	ld.global.f64 	%fd333, [%rd150];
	selp.f64	%fd116, %fd114, %fd333, %p77;
	setp.eq.s32	%p78, %r11, 255;
	ld.global.f64 	%fd334, [%rd152];
	selp.f64	%fd117, %fd114, %fd334, %p78;
	setp.eq.s32	%p79, %r12, 255;
	ld.global.f64 	%fd335, [%rd154];
	selp.f64	%fd118, %fd114, %fd335, %p79;
	ld.const.u32 	%r16, [dc_spatialOrder];
	setp.gt.s32	%p80, %r16, 1;
	@%p80 bra 	BB20_81;
	bra.uni 	BB20_80;

BB20_81:
	setp.gt.f64	%p85, %fd1, 0d0000000000000000;
	ld.global.u8 	%r53, [%rd13];
	ld.global.u8 	%r54, [%rd15];
	ld.global.u8 	%r55, [%rd17];
	ld.global.u8 	%r56, [%rd19];
	shl.b64 	%rd156, %rd12, 3;
	add.s64 	%rd157, %rd144, %rd156;
	shl.b64 	%rd158, %rd14, 3;
	add.s64 	%rd159, %rd144, %rd158;
	shl.b64 	%rd160, %rd16, 3;
	add.s64 	%rd161, %rd144, %rd160;
	shl.b64 	%rd162, %rd18, 3;
	add.s64 	%rd163, %rd144, %rd162;
	setp.eq.s32	%p86, %r53, 255;
	ld.global.f64 	%fd343, [%rd157];
	selp.f64	%fd120, %fd115, %fd343, %p86;
	setp.eq.s32	%p87, %r54, 255;
	ld.global.f64 	%fd344, [%rd159];
	selp.f64	%fd121, %fd116, %fd344, %p87;
	setp.eq.s32	%p88, %r55, 255;
	ld.global.f64 	%fd345, [%rd161];
	selp.f64	%fd122, %fd117, %fd345, %p88;
	setp.eq.s32	%p89, %r56, 255;
	ld.global.f64 	%fd346, [%rd163];
	selp.f64	%fd123, %fd118, %fd346, %p89;
	@%p85 bra 	BB20_83;
	bra.uni 	BB20_82;

BB20_83:
	sub.f64 	%fd466, %fd115, %fd120;
	sub.f64 	%fd467, %fd114, %fd120;
	sub.f64 	%fd468, %fd114, %fd115;
	mov.f64 	%fd504, %fd115;
	bra.uni 	BB20_84;

BB20_80:
	neg.f64 	%fd418, %fd5;
	neg.f64 	%fd417, %fd2;
	setp.gt.f64	%p81, %fd1, 0d0000000000000000;
	selp.f64	%fd336, %fd115, %fd114, %p81;
	fma.rn.f64 	%fd337, %fd1, %fd336, 0d0000000000000000;
	setp.lt.f64	%p82, %fd2, 0d8000000000000000;
	selp.f64	%fd338, %fd116, %fd114, %p82;
	fma.rn.f64 	%fd339, %fd338, %fd417, %fd337;
	setp.gt.f64	%p83, %fd4, 0d0000000000000000;
	selp.f64	%fd340, %fd117, %fd114, %p83;
	fma.rn.f64 	%fd341, %fd4, %fd340, %fd339;
	setp.lt.f64	%p84, %fd5, 0d8000000000000000;
	selp.f64	%fd342, %fd118, %fd114, %p84;
	fma.rn.f64 	%fd505, %fd342, %fd418, %fd341;
	bra.uni 	BB20_122;

BB20_82:
	sub.f64 	%fd466, %fd114, %fd116;
	sub.f64 	%fd467, %fd115, %fd116;
	sub.f64 	%fd468, %fd115, %fd114;
	mov.f64 	%fd504, %fd114;

BB20_84:
	mov.f64 	%fd481, %fd504;
	mov.f64 	%fd130, %fd481;
	mul.f64 	%fd347, %fd466, %fd468;
	setp.leu.f64	%p90, %fd347, 0d0000000000000000;
	mov.f64 	%fd502, %fd130;
	@%p90 bra 	BB20_91;

	setp.eq.s32	%p91, %r16, 2;
	@%p91 bra 	BB20_88;
	bra.uni 	BB20_86;

BB20_88:
	add.f64 	%fd352, %fd114, %fd115;
	mul.f64 	%fd503, %fd352, 0d3FE0000000000000;
	bra.uni 	BB20_89;

BB20_86:
	setp.ne.s32	%p92, %r16, 4;
	mov.f64 	%fd503, %fd130;
	@%p92 bra 	BB20_89;

	add.f64 	%fd348, %fd114, %fd115;
	mul.f64 	%fd349, %fd348, 0d4022000000000000;
	add.f64 	%fd350, %fd116, %fd120;
	sub.f64 	%fd351, %fd349, %fd350;
	mul.f64 	%fd503, %fd351, 0d3FB0000000000000;

BB20_89:
	mov.f64 	%fd136, %fd503;
	div.rn.f64 	%fd353, %fd466, %fd467;
	setp.lt.f64	%p93, %fd353, 0d3FE0000000000000;
	mov.f64 	%fd354, 0d3FF0000000000000;
	sub.f64 	%fd355, %fd354, %fd353;
	selp.f64	%fd356, %fd353, %fd355, %p93;
	mul.f64 	%fd137, %fd356, 0d4024000000000000;
	setp.geu.f64	%p94, %fd137, 0d3FF0000000000000;
	mov.f64 	%fd502, %fd136;
	@%p94 bra 	BB20_91;

	sub.f64 	%fd358, %fd354, %fd137;
	mul.f64 	%fd359, %fd130, %fd358;
	fma.rn.f64 	%fd502, %fd136, %fd137, %fd359;

BB20_91:
	setp.gt.f64	%p95, %fd2, 0d0000000000000000;
	@%p95 bra 	BB20_93;
	bra.uni 	BB20_92;

BB20_93:
	sub.f64 	%fd469, %fd114, %fd115;
	sub.f64 	%fd470, %fd116, %fd115;
	sub.f64 	%fd471, %fd116, %fd114;
	mov.f64 	%fd478, %fd114;
	mov.f64 	%fd501, %fd478;
	bra.uni 	BB20_94;

BB20_92:
	sub.f64 	%fd469, %fd116, %fd121;
	sub.f64 	%fd470, %fd114, %fd121;
	sub.f64 	%fd471, %fd114, %fd116;
	mov.f64 	%fd501, %fd116;

BB20_94:
	mov.f64 	%fd484, %fd501;
	mov.f64 	%fd146, %fd484;
	mul.f64 	%fd360, %fd469, %fd471;
	setp.leu.f64	%p96, %fd360, 0d0000000000000000;
	mov.f64 	%fd499, %fd146;
	@%p96 bra 	BB20_101;

	setp.eq.s32	%p97, %r16, 2;
	@%p97 bra 	BB20_98;
	bra.uni 	BB20_96;

BB20_98:
	add.f64 	%fd365, %fd114, %fd116;
	mul.f64 	%fd500, %fd365, 0d3FE0000000000000;
	bra.uni 	BB20_99;

BB20_96:
	setp.ne.s32	%p98, %r16, 4;
	mov.f64 	%fd500, %fd146;
	@%p98 bra 	BB20_99;

	add.f64 	%fd361, %fd114, %fd116;
	mul.f64 	%fd362, %fd361, 0d4022000000000000;
	add.f64 	%fd363, %fd115, %fd121;
	sub.f64 	%fd364, %fd362, %fd363;
	mul.f64 	%fd500, %fd364, 0d3FB0000000000000;

BB20_99:
	mov.f64 	%fd152, %fd500;
	div.rn.f64 	%fd366, %fd469, %fd470;
	setp.lt.f64	%p99, %fd366, 0d3FE0000000000000;
	mov.f64 	%fd367, 0d3FF0000000000000;
	sub.f64 	%fd368, %fd367, %fd366;
	selp.f64	%fd369, %fd366, %fd368, %p99;
	mul.f64 	%fd153, %fd369, 0d4024000000000000;
	setp.geu.f64	%p100, %fd153, 0d3FF0000000000000;
	mov.f64 	%fd499, %fd152;
	@%p100 bra 	BB20_101;

	sub.f64 	%fd371, %fd367, %fd153;
	mul.f64 	%fd372, %fd146, %fd371;
	fma.rn.f64 	%fd499, %fd152, %fd153, %fd372;

BB20_101:
	setp.gt.f64	%p101, %fd4, 0d0000000000000000;
	@%p101 bra 	BB20_103;
	bra.uni 	BB20_102;

BB20_103:
	sub.f64 	%fd472, %fd117, %fd122;
	sub.f64 	%fd473, %fd114, %fd122;
	sub.f64 	%fd474, %fd114, %fd117;
	mov.f64 	%fd498, %fd117;
	bra.uni 	BB20_104;

BB20_102:
	sub.f64 	%fd472, %fd114, %fd118;
	sub.f64 	%fd473, %fd117, %fd118;
	sub.f64 	%fd474, %fd117, %fd114;
	mov.f64 	%fd479, %fd114;
	mov.f64 	%fd498, %fd479;

BB20_104:
	mov.f64 	%fd487, %fd498;
	mov.f64 	%fd162, %fd487;
	mul.f64 	%fd373, %fd472, %fd474;
	setp.leu.f64	%p102, %fd373, 0d0000000000000000;
	mov.f64 	%fd496, %fd162;
	@%p102 bra 	BB20_111;

	setp.eq.s32	%p103, %r16, 2;
	@%p103 bra 	BB20_108;
	bra.uni 	BB20_106;

BB20_108:
	add.f64 	%fd378, %fd114, %fd117;
	mul.f64 	%fd497, %fd378, 0d3FE0000000000000;
	bra.uni 	BB20_109;

BB20_106:
	setp.ne.s32	%p104, %r16, 4;
	mov.f64 	%fd497, %fd162;
	@%p104 bra 	BB20_109;

	add.f64 	%fd374, %fd114, %fd117;
	mul.f64 	%fd375, %fd374, 0d4022000000000000;
	add.f64 	%fd376, %fd118, %fd122;
	sub.f64 	%fd377, %fd375, %fd376;
	mul.f64 	%fd497, %fd377, 0d3FB0000000000000;

BB20_109:
	mov.f64 	%fd168, %fd497;
	div.rn.f64 	%fd379, %fd472, %fd473;
	setp.lt.f64	%p105, %fd379, 0d3FE0000000000000;
	mov.f64 	%fd380, 0d3FF0000000000000;
	sub.f64 	%fd381, %fd380, %fd379;
	selp.f64	%fd382, %fd379, %fd381, %p105;
	mul.f64 	%fd169, %fd382, 0d4024000000000000;
	setp.geu.f64	%p106, %fd169, 0d3FF0000000000000;
	mov.f64 	%fd496, %fd168;
	@%p106 bra 	BB20_111;

	sub.f64 	%fd384, %fd380, %fd169;
	mul.f64 	%fd385, %fd162, %fd384;
	fma.rn.f64 	%fd496, %fd168, %fd169, %fd385;

BB20_111:
	setp.gt.f64	%p107, %fd5, 0d0000000000000000;
	@%p107 bra 	BB20_113;
	bra.uni 	BB20_112;

BB20_113:
	sub.f64 	%fd475, %fd114, %fd117;
	sub.f64 	%fd476, %fd118, %fd117;
	sub.f64 	%fd477, %fd118, %fd114;
	mov.f64 	%fd480, %fd114;
	mov.f64 	%fd495, %fd480;
	bra.uni 	BB20_114;

BB20_112:
	sub.f64 	%fd475, %fd118, %fd123;
	sub.f64 	%fd476, %fd114, %fd123;
	sub.f64 	%fd477, %fd114, %fd118;
	mov.f64 	%fd495, %fd118;

BB20_114:
	mov.f64 	%fd490, %fd495;
	mov.f64 	%fd178, %fd490;
	mul.f64 	%fd386, %fd475, %fd477;
	setp.leu.f64	%p108, %fd386, 0d0000000000000000;
	mov.f64 	%fd493, %fd178;
	@%p108 bra 	BB20_121;

	setp.eq.s32	%p109, %r16, 2;
	@%p109 bra 	BB20_118;
	bra.uni 	BB20_116;

BB20_118:
	add.f64 	%fd391, %fd114, %fd118;
	mul.f64 	%fd494, %fd391, 0d3FE0000000000000;
	bra.uni 	BB20_119;

BB20_116:
	setp.ne.s32	%p110, %r16, 4;
	mov.f64 	%fd494, %fd178;
	@%p110 bra 	BB20_119;

	add.f64 	%fd387, %fd114, %fd118;
	mul.f64 	%fd388, %fd387, 0d4022000000000000;
	add.f64 	%fd389, %fd117, %fd123;
	sub.f64 	%fd390, %fd388, %fd389;
	mul.f64 	%fd494, %fd390, 0d3FB0000000000000;

BB20_119:
	mov.f64 	%fd184, %fd494;
	div.rn.f64 	%fd392, %fd475, %fd476;
	setp.lt.f64	%p111, %fd392, 0d3FE0000000000000;
	mov.f64 	%fd393, 0d3FF0000000000000;
	sub.f64 	%fd394, %fd393, %fd392;
	selp.f64	%fd395, %fd392, %fd394, %p111;
	mul.f64 	%fd185, %fd395, 0d4024000000000000;
	setp.geu.f64	%p112, %fd185, 0d3FF0000000000000;
	mov.f64 	%fd493, %fd184;
	@%p112 bra 	BB20_121;

	sub.f64 	%fd397, %fd393, %fd185;
	mul.f64 	%fd398, %fd178, %fd397;
	fma.rn.f64 	%fd493, %fd184, %fd185, %fd398;

BB20_121:
	neg.f64 	%fd420, %fd5;
	neg.f64 	%fd419, %fd2;
	fma.rn.f64 	%fd399, %fd1, %fd502, 0d0000000000000000;
	fma.rn.f64 	%fd400, %fd499, %fd419, %fd399;
	fma.rn.f64 	%fd401, %fd4, %fd496, %fd400;
	fma.rn.f64 	%fd505, %fd493, %fd420, %fd401;

BB20_122:
	ld.param.u64 	%rd172, [gpu_calcDerivsSpatialHKB_param_10];
	ld.param.u64 	%rd171, [gpu_calcDerivsSpatialHKB_param_3];
	cvta.to.global.u64 	%rd164, %rd171;
	add.s64 	%rd166, %rd164, %rd43;
	ld.const.f64 	%fd402, [dc_wetDepthThreshold];
	ld.global.f64 	%fd403, [%rd166];
	setp.gt.f64	%p113, %fd403, %fd402;
	ld.const.f64 	%fd404, [dc_dryDepthThreshold];
	selp.f64	%fd405, %fd403, %fd404, %p113;
	mul.f64 	%fd406, %fd17, %fd114;
	sub.f64 	%fd407, %fd505, %fd406;
	mul.f64 	%fd408, %fd9, %fd405;
	div.rn.f64 	%fd409, %fd407, %fd408;
	neg.f64 	%fd410, %fd114;
	div.rn.f64 	%fd411, %fd410, %fd190;
	setp.gt.f64	%p114, %fd409, %fd411;
	selp.f64	%fd412, %fd409, %fd411, %p114;
	cvta.to.global.u64 	%rd167, %rd172;
	add.s64 	%rd168, %rd167, %rd43;
	st.global.f64 	[%rd168], %fd412;

BB20_123:
	ret;
}

	// .globl	gpu_calcDerivsSpatialU
.visible .entry gpu_calcDerivsSpatialU(
	.param .u32 gpu_calcDerivsSpatialU_param_0,
	.param .f64 gpu_calcDerivsSpatialU_param_1,
	.param .f64 gpu_calcDerivsSpatialU_param_2,
	.param .f64 gpu_calcDerivsSpatialU_param_3,
	.param .u64 gpu_calcDerivsSpatialU_param_4,
	.param .u64 gpu_calcDerivsSpatialU_param_5,
	.param .u64 gpu_calcDerivsSpatialU_param_6,
	.param .u64 gpu_calcDerivsSpatialU_param_7
)
{
	.local .align 8 .b8 	__local_depot21[176];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<191>;
	.reg .b32 	%r<150>;
	.reg .f64 	%fd<659>;
	.reg .b64 	%rd<218>;


	mov.u64 	%rd217, __local_depot21;
	cvta.local.u64 	%SP, %rd217;
	ld.param.f64 	%fd247, [gpu_calcDerivsSpatialU_param_2];
	ld.param.u64 	%rd18, [gpu_calcDerivsSpatialU_param_4];
	ld.param.u64 	%rd19, [gpu_calcDerivsSpatialU_param_5];
	cvta.to.global.u64 	%rd1, %rd19;
	mov.u32 	%r46, %ntid.x;
	mov.u32 	%r47, %ctaid.x;
	mov.u32 	%r48, %tid.x;
	mad.lo.s32 	%r1, %r46, %r47, %r48;
	mov.u32 	%r49, %ntid.y;
	mov.u32 	%r50, %ctaid.y;
	mov.u32 	%r51, %tid.y;
	mad.lo.s32 	%r2, %r49, %r50, %r51;
	setp.gt.s32	%p5, %r1, 1;
	ld.const.u32 	%r52, [dc_ny];
	add.s32 	%r53, %r52, -2;
	setp.lt.s32	%p6, %r1, %r53;
	and.pred  	%p7, %p5, %p6;
	setp.gt.s32	%p8, %r2, 1;
	and.pred  	%p9, %p7, %p8;
	ld.const.u32 	%r54, [dc_nx];
	add.s32 	%r55, %r54, -2;
	setp.lt.s32	%p10, %r2, %r55;
	and.pred  	%p11, %p9, %p10;
	@!%p11 bra 	BB21_153;
	bra.uni 	BB21_1;

BB21_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	sub.s32 	%r56, %r4, %r3;
	add.s32 	%r57, %r4, %r3;
	add.s32 	%r58, %r4, -1;
	add.s32 	%r59, %r4, 1;
	add.s32 	%r5, %r58, %r3;
	add.s32 	%r6, %r59, %r3;
	ld.const.u64 	%rd22, [dc_a];
	cvta.to.global.u64 	%rd2, %rd22;
	cvt.u64.u32	%rd3, %r58;
	mul.wide.u32 	%rd23, %r58, 4;
	add.s64 	%rd24, %rd2, %rd23;
	ld.global.u8 	%r7, [%rd24];
	cvt.u64.u32	%rd4, %r5;
	mul.wide.u32 	%rd25, %r5, 4;
	add.s64 	%rd26, %rd2, %rd25;
	ld.global.u8 	%r8, [%rd26];
	cvt.u64.u32	%rd5, %r4;
	mul.wide.u32 	%rd27, %r4, 4;
	add.s64 	%rd28, %rd2, %rd27;
	ld.global.u8 	%r9, [%rd28];
	cvt.u64.u32	%rd6, %r57;
	mul.wide.u32 	%rd29, %r57, 4;
	add.s64 	%rd30, %rd2, %rd29;
	ld.global.u8 	%r10, [%rd30];
	cvt.u64.u32	%rd7, %r59;
	mul.wide.u32 	%rd31, %r59, 4;
	add.s64 	%rd32, %rd2, %rd31;
	ld.global.u8 	%r11, [%rd32];
	cvt.u64.u32	%rd8, %r6;
	mul.wide.u32 	%rd33, %r6, 4;
	add.s64 	%rd34, %rd2, %rd33;
	ld.global.u8 	%r12, [%rd34];
	cvt.u64.u32	%rd9, %r56;
	setp.eq.s32	%p12, %r9, 0;
	setp.ne.s32	%p13, %r10, 255;
	and.pred  	%p14, %p12, %p13;
	setp.eq.s32	%p15, %r10, 0;
	setp.ne.s32	%p16, %r9, 255;
	and.pred  	%p17, %p15, %p16;
	or.pred  	%p18, %p14, %p17;
	@!%p18 bra 	BB21_153;
	bra.uni 	BB21_2;

BB21_2:
	cvta.to.global.u64 	%rd35, %rd18;
	add.s32 	%r60, %r4, -2;
	add.s32 	%r61, %r5, -1;
	mad.lo.s32 	%r62, %r3, 2, %r4;
	add.s32 	%r63, %r4, 2;
	add.s32 	%r64, %r6, 1;
	mul.wide.u32 	%rd36, %r60, 4;
	add.s64 	%rd37, %rd2, %rd36;
	ld.global.u32 	%r13, [%rd37];
	mul.wide.u32 	%rd38, %r61, 4;
	add.s64 	%rd39, %rd2, %rd38;
	ld.global.u32 	%r14, [%rd39];
	shl.b64 	%rd40, %rd9, 2;
	add.s64 	%rd41, %rd2, %rd40;
	ld.global.u32 	%r15, [%rd41];
	mul.wide.u32 	%rd42, %r62, 4;
	add.s64 	%rd43, %rd2, %rd42;
	ld.global.u32 	%r16, [%rd43];
	mul.wide.u32 	%rd44, %r63, 4;
	add.s64 	%rd45, %rd2, %rd44;
	ld.global.u32 	%r17, [%rd45];
	mul.wide.u32 	%rd46, %r64, 4;
	add.s64 	%rd47, %rd2, %rd46;
	ld.global.u32 	%r18, [%rd47];
	shl.b64 	%rd48, %rd3, 3;
	add.s64 	%rd49, %rd35, %rd48;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.global.f64 	%fd2, [%rd49];
	ld.const.f64 	%fd3, [dc_dryDepthThreshold];
	shl.b64 	%rd50, %rd4, 3;
	add.s64 	%rd51, %rd35, %rd50;
	ld.global.f64 	%fd4, [%rd51];
	shl.b64 	%rd52, %rd5, 3;
	add.s64 	%rd53, %rd35, %rd52;
	ld.global.f64 	%fd249, [%rd53];
	setp.gt.f64	%p19, %fd249, %fd1;
	selp.f64	%fd5, %fd249, %fd3, %p19;
	shl.b64 	%rd54, %rd6, 3;
	add.s64 	%rd55, %rd35, %rd54;
	ld.global.f64 	%fd250, [%rd55];
	setp.gt.f64	%p20, %fd250, %fd1;
	selp.f64	%fd6, %fd250, %fd3, %p20;
	shl.b64 	%rd56, %rd7, 3;
	add.s64 	%rd57, %rd35, %rd56;
	ld.global.f64 	%fd7, [%rd57];
	shl.b64 	%rd58, %rd8, 3;
	add.s64 	%rd59, %rd35, %rd58;
	ld.global.f64 	%fd8, [%rd59];
	add.s64 	%rd60, %rd1, %rd52;
	ld.global.f64 	%fd9, [%rd60];
	ld.const.u64 	%rd61, [dc_zc];
	cvta.to.global.u64 	%rd62, %rd61;
	add.s64 	%rd63, %rd62, %rd52;
	add.s64 	%rd64, %rd62, %rd54;
	ld.const.u64 	%rd65, [dc_zu];
	cvta.to.global.u64 	%rd66, %rd65;
	add.s64 	%rd67, %rd66, %rd52;
	ld.global.f64 	%fd10, [%rd63];
	add.f64 	%fd548, %fd5, %fd10;
	ld.global.f64 	%fd12, [%rd64];
	add.f64 	%fd549, %fd6, %fd12;
	setp.gt.f64	%p21, %fd5, %fd1;
	setp.gt.f64	%p22, %fd548, %fd12;
	and.pred  	%p23, %p21, %p22;
	ld.global.f64 	%fd14, [%rd67];
	setp.gt.f64	%p24, %fd548, %fd14;
	and.pred  	%p25, %p23, %p24;
	@%p25 bra 	BB21_5;

	setp.gt.f64	%p26, %fd6, %fd1;
	setp.gt.f64	%p27, %fd549, %fd10;
	and.pred  	%p28, %p26, %p27;
	setp.gt.f64	%p29, %fd549, %fd14;
	and.pred  	%p30, %p28, %p29;
	@%p30 bra 	BB21_5;
	bra.uni 	BB21_4;

BB21_5:
	setp.gt.f64	%p31, %fd2, %fd1;
	selp.f64	%fd15, %fd2, %fd3, %p31;
	setp.gt.f64	%p32, %fd4, %fd1;
	selp.f64	%fd16, %fd4, %fd3, %p32;
	setp.gt.f64	%p33, %fd7, %fd1;
	selp.f64	%fd17, %fd7, %fd3, %p33;
	setp.gt.f64	%p34, %fd8, %fd1;
	selp.f64	%fd18, %fd8, %fd3, %p34;
	setp.gt.f64	%p35, %fd548, %fd549;
	setp.gt.f64	%p36, %fd10, %fd12;
	selp.f64	%fd253, %fd10, %fd12, %p36;
	sub.f64 	%fd254, %fd14, %fd253;
	add.f64 	%fd19, %fd254, %fd254;
	@%p35 bra 	BB21_7;
	bra.uni 	BB21_6;

BB21_7:
	div.rn.f64 	%fd269, %fd19, %fd5;
	setp.gt.f64	%p42, %fd269, 0d0000000000000000;
	selp.f64	%fd270, %fd269, 0d0000000000000000, %p42;
	setp.lt.f64	%p43, %fd270, 0d3FF0000000000000;
	selp.f64	%fd271, %fd270, 0d3FF0000000000000, %p43;
	mov.f64 	%fd272, 0d3FF0000000000000;
	sub.f64 	%fd273, %fd272, %fd271;
	ld.const.u32 	%r144, [dc_spatialOrder];
	setp.eq.s32	%p44, %r144, 1;
	selp.f64	%fd274, 0d3FE199999999999A, 0d3FD3333333333333, %p44;
	mul.f64 	%fd275, %fd274, %fd273;
	fma.rn.f64 	%fd276, %fd271, 0d3FE8F5C28F5C28F6, %fd275;
	sub.f64 	%fd277, %fd272, %fd276;
	mul.f64 	%fd278, %fd14, %fd277;
	fma.rn.f64 	%fd279, %fd548, %fd276, %fd278;
	sub.f64 	%fd280, %fd10, %fd14;
	setp.gt.f64	%p45, %fd10, %fd14;
	selp.f64	%fd281, %fd280, 0d0000000000000000, %p45;
	sub.f64 	%fd282, %fd279, %fd281;
	setp.gt.f64	%p46, %fd549, %fd282;
	selp.f64	%fd549, %fd549, %fd282, %p46;
	bra.uni 	BB21_8;

BB21_6:
	div.rn.f64 	%fd255, %fd19, %fd6;
	setp.gt.f64	%p37, %fd255, 0d0000000000000000;
	selp.f64	%fd256, %fd255, 0d0000000000000000, %p37;
	setp.lt.f64	%p38, %fd256, 0d3FF0000000000000;
	selp.f64	%fd257, %fd256, 0d3FF0000000000000, %p38;
	mov.f64 	%fd258, 0d3FF0000000000000;
	sub.f64 	%fd259, %fd258, %fd257;
	ld.const.u32 	%r144, [dc_spatialOrder];
	setp.eq.s32	%p39, %r144, 1;
	selp.f64	%fd260, 0d3FE199999999999A, 0d3FD3333333333333, %p39;
	mul.f64 	%fd261, %fd260, %fd259;
	fma.rn.f64 	%fd262, %fd257, 0d3FE8F5C28F5C28F6, %fd261;
	sub.f64 	%fd263, %fd258, %fd262;
	mul.f64 	%fd264, %fd14, %fd263;
	fma.rn.f64 	%fd265, %fd549, %fd262, %fd264;
	sub.f64 	%fd266, %fd12, %fd14;
	setp.gt.f64	%p40, %fd12, %fd14;
	selp.f64	%fd267, %fd266, 0d0000000000000000, %p40;
	sub.f64 	%fd268, %fd265, %fd267;
	setp.gt.f64	%p41, %fd548, %fd268;
	selp.f64	%fd548, %fd548, %fd268, %p41;

BB21_8:
	ld.param.u64 	%rd214, [gpu_calcDerivsSpatialU_param_6];
	cvta.to.global.u64 	%rd71, %rd214;
	and.b32  	%r22, %r13, 255;
	and.b32  	%r23, %r14, 255;
	and.b32  	%r24, %r15, 255;
	and.b32  	%r25, %r16, 255;
	and.b32  	%r26, %r17, 255;
	and.b32  	%r27, %r18, 255;
	sub.f64 	%fd283, %fd548, %fd549;
	ld.const.f64 	%fd24, [dc_g];
	mul.f64 	%fd284, %fd24, %fd283;
	ld.const.f64 	%fd25, [dc_dx];
	div.rn.f64 	%fd26, %fd284, %fd25;
	ld.const.u64 	%rd72, [dc_nut];
	cvta.to.global.u64 	%rd73, %rd72;
	add.s64 	%rd75, %rd73, %rd48;
	ld.global.f64 	%fd27, [%rd75];
	add.s64 	%rd77, %rd73, %rd50;
	ld.global.f64 	%fd28, [%rd77];
	add.s64 	%rd79, %rd73, %rd52;
	ld.global.f64 	%fd29, [%rd79];
	add.s64 	%rd81, %rd73, %rd54;
	ld.global.f64 	%fd30, [%rd81];
	add.s64 	%rd83, %rd73, %rd56;
	ld.global.f64 	%fd31, [%rd83];
	add.s64 	%rd85, %rd73, %rd58;
	ld.global.f64 	%fd32, [%rd85];
	ld.const.u64 	%rd86, [dc_phi2];
	cvta.to.global.u64 	%rd87, %rd86;
	add.s64 	%rd88, %rd87, %rd52;
	shl.b64 	%rd89, %rd9, 3;
	add.s64 	%rd90, %rd87, %rd89;
	add.s64 	%rd91, %rd87, %rd54;
	ld.const.u64 	%rd92, [dc_phi4];
	cvta.to.global.u64 	%rd93, %rd92;
	add.s64 	%rd94, %rd93, %rd48;
	add.s64 	%rd95, %rd93, %rd50;
	add.s64 	%rd96, %rd93, %rd52;
	add.s64 	%rd97, %rd93, %rd54;
	setp.ne.s32	%p47, %r7, 0;
	setp.ne.s32	%p48, %r8, 0;
	and.pred  	%p1, %p48, %p47;
	add.s64 	%rd98, %rd1, %rd48;
	ld.global.f64 	%fd285, [%rd98];
	selp.f64	%fd33, %fd9, %fd285, %p1;
	add.s64 	%rd99, %rd1, %rd89;
	ld.global.f64 	%fd286, [%rd99];
	selp.f64	%fd34, %fd286, %fd9, %p12;
	add.s64 	%rd100, %rd71, %rd50;
	ld.global.f64 	%fd287, [%rd100];
	add.s64 	%rd101, %rd71, %rd48;
	ld.global.f64 	%fd288, [%rd101];
	selp.f64	%fd35, %fd288, %fd287, %p12;
	add.s64 	%rd102, %rd71, %rd54;
	ld.global.f64 	%fd289, [%rd102];
	add.s64 	%rd103, %rd71, %rd52;
	ld.global.f64 	%fd290, [%rd103];
	selp.f64	%fd36, %fd290, %fd289, %p12;
	ld.global.f64 	%fd291, [%rd90];
	ld.global.f64 	%fd292, [%rd88];
	selp.f64	%fd293, %fd291, %fd292, %p12;
	ld.global.f64 	%fd294, [%rd95];
	ld.global.f64 	%fd295, [%rd94];
	selp.f64	%fd37, %fd295, %fd294, %p12;
	ld.global.f64 	%fd296, [%rd97];
	ld.global.f64 	%fd297, [%rd96];
	selp.f64	%fd38, %fd297, %fd296, %p12;
	add.s64 	%rd104, %rd1, %rd54;
	ld.global.f64 	%fd298, [%rd104];
	selp.f64	%fd39, %fd298, %fd9, %p15;
	selp.f64	%fd40, %fd287, %fd35, %p15;
	selp.f64	%fd41, %fd289, %fd36, %p15;
	ld.global.f64 	%fd299, [%rd91];
	selp.f64	%fd300, %fd299, %fd292, %p15;
	selp.f64	%fd42, %fd294, %fd37, %p15;
	selp.f64	%fd43, %fd296, %fd38, %p15;
	setp.ne.s32	%p51, %r11, 0;
	setp.ne.s32	%p52, %r12, 0;
	and.pred  	%p2, %p52, %p51;
	add.s64 	%rd105, %rd1, %rd56;
	ld.global.f64 	%fd301, [%rd105];
	selp.f64	%fd44, %fd9, %fd301, %p2;
	add.f64 	%fd302, %fd292, %fd293;
	mul.f64 	%fd45, %fd302, 0d3FE0000000000000;
	add.f64 	%fd303, %fd292, %fd300;
	mul.f64 	%fd46, %fd303, 0d3FE0000000000000;
	setp.gt.s32	%p53, %r144, 1;
	@%p53 bra 	BB21_10;
	bra.uni 	BB21_9;

BB21_10:
	add.s32 	%r143, %r4, 2;
	add.s32 	%r142, %r4, -2;
	ld.const.u32 	%r141, [dc_nyPadded];
	shl.b32 	%r65, %r141, 1;
	sub.s32 	%r75, %r4, %r65;
	add.s32 	%r76, %r65, %r4;
	mul.wide.u32 	%rd107, %r75, 8;
	add.s64 	%rd108, %rd1, %rd107;
	mul.wide.u32 	%rd109, %r76, 8;
	add.s64 	%rd110, %rd1, %rd109;
	mul.wide.u32 	%rd111, %r142, 8;
	add.s64 	%rd112, %rd1, %rd111;
	mul.wide.u32 	%rd113, %r143, 8;
	add.s64 	%rd10, %rd1, %rd113;
	setp.ne.s32	%p58, %r22, 0;
	setp.ne.s32	%p59, %r23, 0;
	and.pred  	%p60, %p59, %p58;
	or.pred  	%p61, %p1, %p60;
	ld.global.f64 	%fd306, [%rd112];
	selp.f64	%fd51, %fd33, %fd306, %p61;
	setp.ne.s32	%p62, %r24, 0;
	setp.ne.s32	%p63, %r24, 255;
	and.pred  	%p64, %p63, %p62;
	setp.ne.s32	%p65, %r9, 0;
	or.pred  	%p66, %p64, %p65;
	ld.global.f64 	%fd307, [%rd108];
	selp.f64	%fd52, %fd34, %fd307, %p66;
	setp.ne.s32	%p67, %r25, 0;
	setp.ne.s32	%p68, %r25, 255;
	and.pred  	%p69, %p68, %p67;
	setp.ne.s32	%p70, %r10, 0;
	or.pred  	%p71, %p69, %p70;
	ld.global.f64 	%fd308, [%rd110];
	selp.f64	%fd53, %fd39, %fd308, %p71;
	mov.f64 	%fd658, %fd44;
	@%p2 bra 	BB21_12;

	ld.global.f64 	%fd309, [%rd10];
	setp.ne.s32	%p72, %r26, 0;
	setp.ne.s32	%p73, %r27, 0;
	and.pred  	%p74, %p73, %p72;
	selp.f64	%fd54, %fd44, %fd309, %p74;
	mov.f64 	%fd658, %fd54;

BB21_12:
	mov.f64 	%fd55, %fd658;
	setp.gt.f64	%p75, %fd45, 0d0000000000000000;
	@%p75 bra 	BB21_14;
	bra.uni 	BB21_13;

BB21_14:
	sub.f64 	%fd550, %fd34, %fd52;
	sub.f64 	%fd551, %fd9, %fd52;
	sub.f64 	%fd552, %fd9, %fd34;
	mov.f64 	%fd657, %fd34;
	bra.uni 	BB21_15;

BB21_9:
	setp.gt.f64	%p54, %fd45, 0d0000000000000000;
	selp.f64	%fd646, %fd34, %fd9, %p54;
	setp.gt.f64	%p55, %fd46, 0d0000000000000000;
	selp.f64	%fd645, %fd9, %fd39, %p55;
	add.f64 	%fd304, %fd37, %fd42;
	setp.gt.f64	%p56, %fd304, 0d0000000000000000;
	selp.f64	%fd644, %fd33, %fd9, %p56;
	add.f64 	%fd305, %fd38, %fd43;
	setp.gt.f64	%p57, %fd305, 0d0000000000000000;
	selp.f64	%fd643, %fd9, %fd44, %p57;
	bra.uni 	BB21_52;

BB21_4:
	ld.param.u64 	%rd213, [gpu_calcDerivsSpatialU_param_7];
	cvta.to.global.u64 	%rd68, %rd213;
	add.s64 	%rd70, %rd68, %rd52;
	mul.f64 	%fd251, %fd9, 0dBFD999999999999A;
	div.rn.f64 	%fd252, %fd251, %fd247;
	st.global.f64 	[%rd70], %fd252;
	bra.uni 	BB21_153;

BB21_13:
	sub.f64 	%fd550, %fd9, %fd39;
	sub.f64 	%fd551, %fd34, %fd39;
	sub.f64 	%fd552, %fd34, %fd9;
	mov.f64 	%fd617, %fd9;
	mov.f64 	%fd657, %fd617;

BB21_15:
	mov.f64 	%fd619, %fd657;
	mov.f64 	%fd62, %fd619;
	mul.f64 	%fd310, %fd550, %fd552;
	setp.leu.f64	%p76, %fd310, 0d0000000000000000;
	mov.f64 	%fd655, %fd62;
	@%p76 bra 	BB21_22;

	setp.eq.s32	%p77, %r144, 2;
	@%p77 bra 	BB21_19;
	bra.uni 	BB21_17;

BB21_19:
	add.f64 	%fd315, %fd9, %fd34;
	mul.f64 	%fd656, %fd315, 0d3FE0000000000000;
	bra.uni 	BB21_20;

BB21_17:
	setp.ne.s32	%p78, %r144, 4;
	mov.f64 	%fd656, %fd62;
	@%p78 bra 	BB21_20;

	add.f64 	%fd311, %fd9, %fd34;
	mul.f64 	%fd312, %fd311, 0d4022000000000000;
	add.f64 	%fd313, %fd39, %fd52;
	sub.f64 	%fd314, %fd312, %fd313;
	mul.f64 	%fd656, %fd314, 0d3FB0000000000000;

BB21_20:
	mov.f64 	%fd68, %fd656;
	div.rn.f64 	%fd316, %fd550, %fd551;
	setp.lt.f64	%p79, %fd316, 0d3FE0000000000000;
	mov.f64 	%fd317, 0d3FF0000000000000;
	sub.f64 	%fd318, %fd317, %fd316;
	selp.f64	%fd319, %fd316, %fd318, %p79;
	mul.f64 	%fd69, %fd319, 0d4024000000000000;
	setp.geu.f64	%p80, %fd69, 0d3FF0000000000000;
	mov.f64 	%fd655, %fd68;
	@%p80 bra 	BB21_22;

	sub.f64 	%fd321, %fd317, %fd69;
	mul.f64 	%fd322, %fd62, %fd321;
	fma.rn.f64 	%fd655, %fd68, %fd69, %fd322;

BB21_22:
	mov.f64 	%fd71, %fd655;
	setp.gt.f64	%p81, %fd46, 0d0000000000000000;
	@%p81 bra 	BB21_24;
	bra.uni 	BB21_23;

BB21_24:
	sub.f64 	%fd553, %fd9, %fd34;
	sub.f64 	%fd554, %fd39, %fd34;
	sub.f64 	%fd555, %fd39, %fd9;
	mov.f64 	%fd614, %fd9;
	mov.f64 	%fd654, %fd614;
	bra.uni 	BB21_25;

BB21_23:
	sub.f64 	%fd553, %fd39, %fd53;
	sub.f64 	%fd554, %fd9, %fd53;
	sub.f64 	%fd555, %fd9, %fd39;
	mov.f64 	%fd654, %fd39;

BB21_25:
	mov.f64 	%fd625, %fd654;
	mov.f64 	%fd78, %fd625;
	mul.f64 	%fd323, %fd553, %fd555;
	setp.leu.f64	%p82, %fd323, 0d0000000000000000;
	mov.f64 	%fd652, %fd78;
	@%p82 bra 	BB21_32;

	setp.eq.s32	%p83, %r144, 2;
	@%p83 bra 	BB21_29;
	bra.uni 	BB21_27;

BB21_29:
	add.f64 	%fd328, %fd9, %fd39;
	mul.f64 	%fd653, %fd328, 0d3FE0000000000000;
	bra.uni 	BB21_30;

BB21_27:
	setp.ne.s32	%p84, %r144, 4;
	mov.f64 	%fd653, %fd78;
	@%p84 bra 	BB21_30;

	add.f64 	%fd324, %fd9, %fd39;
	mul.f64 	%fd325, %fd324, 0d4022000000000000;
	add.f64 	%fd326, %fd34, %fd53;
	sub.f64 	%fd327, %fd325, %fd326;
	mul.f64 	%fd653, %fd327, 0d3FB0000000000000;

BB21_30:
	mov.f64 	%fd84, %fd653;
	div.rn.f64 	%fd329, %fd553, %fd554;
	setp.lt.f64	%p85, %fd329, 0d3FE0000000000000;
	mov.f64 	%fd330, 0d3FF0000000000000;
	sub.f64 	%fd331, %fd330, %fd329;
	selp.f64	%fd332, %fd329, %fd331, %p85;
	mul.f64 	%fd85, %fd332, 0d4024000000000000;
	setp.geu.f64	%p86, %fd85, 0d3FF0000000000000;
	mov.f64 	%fd652, %fd84;
	@%p86 bra 	BB21_32;

	sub.f64 	%fd334, %fd330, %fd85;
	mul.f64 	%fd335, %fd78, %fd334;
	fma.rn.f64 	%fd652, %fd84, %fd85, %fd335;

BB21_32:
	mov.f64 	%fd87, %fd652;
	add.f64 	%fd336, %fd37, %fd42;
	setp.gt.f64	%p87, %fd336, 0d0000000000000000;
	@%p87 bra 	BB21_34;
	bra.uni 	BB21_33;

BB21_34:
	sub.f64 	%fd556, %fd33, %fd51;
	sub.f64 	%fd557, %fd9, %fd51;
	sub.f64 	%fd558, %fd9, %fd33;
	mov.f64 	%fd651, %fd33;
	bra.uni 	BB21_35;

BB21_33:
	sub.f64 	%fd556, %fd9, %fd44;
	sub.f64 	%fd557, %fd33, %fd44;
	sub.f64 	%fd558, %fd33, %fd9;
	mov.f64 	%fd615, %fd9;
	mov.f64 	%fd651, %fd615;

BB21_35:
	mov.f64 	%fd631, %fd651;
	mov.f64 	%fd94, %fd631;
	mul.f64 	%fd337, %fd556, %fd558;
	setp.leu.f64	%p88, %fd337, 0d0000000000000000;
	mov.f64 	%fd649, %fd94;
	@%p88 bra 	BB21_42;

	setp.eq.s32	%p89, %r144, 2;
	@%p89 bra 	BB21_39;
	bra.uni 	BB21_37;

BB21_39:
	add.f64 	%fd342, %fd9, %fd33;
	mul.f64 	%fd650, %fd342, 0d3FE0000000000000;
	bra.uni 	BB21_40;

BB21_37:
	setp.ne.s32	%p90, %r144, 4;
	mov.f64 	%fd650, %fd94;
	@%p90 bra 	BB21_40;

	add.f64 	%fd338, %fd9, %fd33;
	mul.f64 	%fd339, %fd338, 0d4022000000000000;
	add.f64 	%fd340, %fd44, %fd51;
	sub.f64 	%fd341, %fd339, %fd340;
	mul.f64 	%fd650, %fd341, 0d3FB0000000000000;

BB21_40:
	mov.f64 	%fd100, %fd650;
	div.rn.f64 	%fd343, %fd556, %fd557;
	setp.lt.f64	%p91, %fd343, 0d3FE0000000000000;
	mov.f64 	%fd344, 0d3FF0000000000000;
	sub.f64 	%fd345, %fd344, %fd343;
	selp.f64	%fd346, %fd343, %fd345, %p91;
	mul.f64 	%fd101, %fd346, 0d4024000000000000;
	setp.geu.f64	%p92, %fd101, 0d3FF0000000000000;
	mov.f64 	%fd649, %fd100;
	@%p92 bra 	BB21_42;

	sub.f64 	%fd348, %fd344, %fd101;
	mul.f64 	%fd349, %fd94, %fd348;
	fma.rn.f64 	%fd649, %fd100, %fd101, %fd349;

BB21_42:
	mov.f64 	%fd103, %fd649;
	add.f64 	%fd350, %fd38, %fd43;
	setp.gt.f64	%p93, %fd350, 0d0000000000000000;
	@%p93 bra 	BB21_44;
	bra.uni 	BB21_43;

BB21_44:
	sub.f64 	%fd559, %fd9, %fd33;
	sub.f64 	%fd560, %fd44, %fd33;
	sub.f64 	%fd561, %fd44, %fd9;
	mov.f64 	%fd648, %fd9;
	bra.uni 	BB21_45;

BB21_43:
	sub.f64 	%fd559, %fd44, %fd55;
	sub.f64 	%fd560, %fd9, %fd55;
	sub.f64 	%fd561, %fd9, %fd44;
	mov.f64 	%fd648, %fd44;

BB21_45:
	mov.f64 	%fd110, %fd648;
	mul.f64 	%fd351, %fd559, %fd561;
	setp.leu.f64	%p94, %fd351, 0d0000000000000000;
	mov.f64 	%fd643, %fd110;
	mov.f64 	%fd644, %fd103;
	mov.f64 	%fd645, %fd87;
	mov.f64 	%fd646, %fd71;
	@%p94 bra 	BB21_52;

	setp.eq.s32	%p95, %r144, 2;
	@%p95 bra 	BB21_49;
	bra.uni 	BB21_47;

BB21_49:
	add.f64 	%fd356, %fd9, %fd44;
	mul.f64 	%fd647, %fd356, 0d3FE0000000000000;
	bra.uni 	BB21_50;

BB21_47:
	setp.ne.s32	%p96, %r144, 4;
	mov.f64 	%fd647, %fd110;
	@%p96 bra 	BB21_50;

	add.f64 	%fd352, %fd9, %fd44;
	mul.f64 	%fd353, %fd352, 0d4022000000000000;
	add.f64 	%fd354, %fd33, %fd55;
	sub.f64 	%fd355, %fd353, %fd354;
	mul.f64 	%fd647, %fd355, 0d3FB0000000000000;

BB21_50:
	mov.f64 	%fd116, %fd647;
	div.rn.f64 	%fd357, %fd559, %fd560;
	setp.lt.f64	%p97, %fd357, 0d3FE0000000000000;
	mov.f64 	%fd358, 0d3FF0000000000000;
	sub.f64 	%fd359, %fd358, %fd357;
	selp.f64	%fd360, %fd357, %fd359, %p97;
	mul.f64 	%fd117, %fd360, 0d4024000000000000;
	setp.geu.f64	%p98, %fd117, 0d3FF0000000000000;
	mov.f64 	%fd623, %fd71;
	mov.f64 	%fd629, %fd87;
	mov.f64 	%fd635, %fd103;
	mov.f64 	%fd643, %fd116;
	mov.f64 	%fd644, %fd635;
	mov.f64 	%fd645, %fd629;
	mov.f64 	%fd646, %fd623;
	@%p98 bra 	BB21_52;

	sub.f64 	%fd362, %fd358, %fd117;
	mul.f64 	%fd363, %fd110, %fd362;
	fma.rn.f64 	%fd643, %fd116, %fd117, %fd363;
	mov.f64 	%fd646, %fd71;
	mov.f64 	%fd645, %fd87;
	mov.f64 	%fd644, %fd103;

BB21_52:
	setp.eq.s32	%p99, %r7, 255;
	mov.f64 	%fd563, 0d0000000000000000;
	mov.f64 	%fd562, %fd563;
	@%p99 bra 	BB21_55;

	mul.f64 	%fd366, %fd37, 0d3FE0000000000000;
	add.f64 	%fd562, %fd366, 0d0000000000000000;
	fma.rn.f64 	%fd563, %fd366, %fd644, 0d0000000000000000;
	setp.gt.f64	%p100, %fd29, 0d0000000000000000;
	setp.gt.f64	%p101, %fd27, 0d0000000000000000;
	and.pred  	%p102, %p101, %p100;
	@!%p102 bra 	BB21_55;
	bra.uni 	BB21_54;

BB21_54:
	setp.lt.f64	%p103, %fd15, %fd5;
	selp.f64	%fd367, %fd15, %fd5, %p103;
	mul.f64 	%fd368, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd369, %fd367, %fd368;
	add.f64 	%fd370, %fd27, %fd29;
	mul.f64 	%fd371, %fd370, %fd369;
	sub.f64 	%fd372, %fd33, %fd9;
	mul.f64 	%fd373, %fd372, %fd371;
	ld.const.f64 	%fd374, [dc_dy];
	div.rn.f64 	%fd375, %fd373, %fd374;
	add.f64 	%fd563, %fd563, %fd375;

BB21_55:
	add.f64 	%fd564, %fd45, %fd562;
	fma.rn.f64 	%fd565, %fd45, %fd646, %fd563;
	setp.leu.f64	%p104, %fd29, 0d0000000000000000;
	@%p104 bra 	BB21_57;

	ld.const.f64 	%fd376, [dc_dy];
	mul.f64 	%fd377, %fd5, %fd376;
	mul.f64 	%fd378, %fd29, %fd377;
	sub.f64 	%fd379, %fd34, %fd9;
	mul.f64 	%fd380, %fd379, %fd378;
	div.rn.f64 	%fd381, %fd380, %fd25;
	add.f64 	%fd565, %fd565, %fd381;

BB21_57:
	setp.eq.s32	%p105, %r11, 255;
	@%p105 bra 	BB21_60;

	setp.gt.f64	%p106, %fd29, 0d0000000000000000;
	mul.f64 	%fd382, %fd38, 0d3FE0000000000000;
	sub.f64 	%fd564, %fd564, %fd382;
	mul.f64 	%fd383, %fd382, %fd643;
	sub.f64 	%fd565, %fd565, %fd383;
	setp.gt.f64	%p107, %fd31, 0d0000000000000000;
	and.pred  	%p108, %p107, %p106;
	@!%p108 bra 	BB21_60;
	bra.uni 	BB21_59;

BB21_59:
	setp.lt.f64	%p109, %fd17, %fd5;
	selp.f64	%fd384, %fd17, %fd5, %p109;
	mul.f64 	%fd385, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd386, %fd384, %fd385;
	add.f64 	%fd387, %fd29, %fd31;
	mul.f64 	%fd388, %fd387, %fd386;
	sub.f64 	%fd389, %fd44, %fd9;
	mul.f64 	%fd390, %fd389, %fd388;
	ld.const.f64 	%fd391, [dc_dy];
	div.rn.f64 	%fd392, %fd390, %fd391;
	add.f64 	%fd565, %fd565, %fd392;

BB21_60:
	setp.eq.s32	%p110, %r8, 255;
	@%p110 bra 	BB21_63;

	mul.f64 	%fd393, %fd42, 0d3FE0000000000000;
	add.f64 	%fd564, %fd393, %fd564;
	fma.rn.f64 	%fd565, %fd393, %fd644, %fd565;
	setp.gt.f64	%p111, %fd30, 0d0000000000000000;
	setp.gt.f64	%p112, %fd28, 0d0000000000000000;
	and.pred  	%p113, %p112, %p111;
	@!%p113 bra 	BB21_63;
	bra.uni 	BB21_62;

BB21_62:
	setp.lt.f64	%p114, %fd16, %fd6;
	selp.f64	%fd394, %fd16, %fd6, %p114;
	mul.f64 	%fd395, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd396, %fd394, %fd395;
	add.f64 	%fd397, %fd28, %fd30;
	mul.f64 	%fd398, %fd397, %fd396;
	sub.f64 	%fd399, %fd33, %fd9;
	mul.f64 	%fd400, %fd399, %fd398;
	ld.const.f64 	%fd401, [dc_dy];
	div.rn.f64 	%fd402, %fd400, %fd401;
	add.f64 	%fd565, %fd565, %fd402;

BB21_63:
	sub.f64 	%fd566, %fd564, %fd46;
	mul.f64 	%fd403, %fd46, %fd645;
	sub.f64 	%fd567, %fd565, %fd403;
	setp.leu.f64	%p115, %fd30, 0d0000000000000000;
	@%p115 bra 	BB21_65;

	ld.const.f64 	%fd404, [dc_dy];
	mul.f64 	%fd405, %fd6, %fd404;
	mul.f64 	%fd406, %fd30, %fd405;
	sub.f64 	%fd407, %fd39, %fd9;
	mul.f64 	%fd408, %fd407, %fd406;
	div.rn.f64 	%fd409, %fd408, %fd25;
	add.f64 	%fd567, %fd567, %fd409;

BB21_65:
	setp.eq.s32	%p116, %r12, 255;
	@%p116 bra 	BB21_68;

	setp.gt.f64	%p117, %fd30, 0d0000000000000000;
	mul.f64 	%fd410, %fd43, 0d3FE0000000000000;
	sub.f64 	%fd566, %fd566, %fd410;
	mul.f64 	%fd411, %fd410, %fd643;
	sub.f64 	%fd567, %fd567, %fd411;
	setp.gt.f64	%p118, %fd32, 0d0000000000000000;
	and.pred  	%p119, %p118, %p117;
	@!%p119 bra 	BB21_68;
	bra.uni 	BB21_67;

BB21_67:
	setp.lt.f64	%p120, %fd18, %fd6;
	selp.f64	%fd412, %fd18, %fd6, %p120;
	mul.f64 	%fd413, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd414, %fd412, %fd413;
	add.f64 	%fd415, %fd30, %fd32;
	mul.f64 	%fd416, %fd415, %fd414;
	sub.f64 	%fd417, %fd44, %fd9;
	mul.f64 	%fd418, %fd417, %fd416;
	ld.const.f64 	%fd419, [dc_dy];
	div.rn.f64 	%fd420, %fd418, %fd419;
	add.f64 	%fd567, %fd567, %fd420;

BB21_68:
	add.f64 	%fd421, %fd5, %fd6;
	mul.f64 	%fd151, %fd421, 0d3FE0000000000000;
	mul.f64 	%fd422, %fd6, %fd6;
	fma.rn.f64 	%fd423, %fd5, %fd5, %fd422;
	mul.f64 	%fd424, %fd423, 0d3FE0000000000000;
	div.rn.f64 	%fd152, %fd424, %fd151;
	add.f64 	%fd425, %fd35, %fd36;
	add.f64 	%fd426, %fd40, %fd41;
	mul.f64 	%fd427, %fd6, %fd426;
	fma.rn.f64 	%fd153, %fd5, %fd425, %fd427;
	ld.const.u32 	%r28, [dc_switches];
	and.b32  	%r79, %r28, 512;
	setp.eq.s32	%p121, %r79, 0;
	@%p121 bra 	BB21_70;

	ld.const.u64 	%rd114, [dc_mnu];
	cvta.to.global.u64 	%rd115, %rd114;
	mul.wide.u32 	%rd116, %r4, 8;
	add.s64 	%rd117, %rd115, %rd116;
	ld.global.f64 	%fd593, [%rd117];
	bra.uni 	BB21_125;

BB21_70:
	mul.wide.u32 	%rd212, %r4, 4;
	ld.const.u64 	%rd118, [dc_mat];
	cvta.to.global.u64 	%rd119, %rd118;
	add.s64 	%rd121, %rd119, %rd212;
	ld.global.u32 	%r80, [%rd121];
	bfe.u32 	%r29, %r80, 16, 8;
	setp.eq.s32	%p122, %r29, 0;
	mov.f64 	%fd594, 0d0000000000000000;
	@%p122 bra 	BB21_124;

	ld.const.u64 	%rd122, [dc_materialTypes];
	cvta.to.global.u64 	%rd123, %rd122;
	add.s32 	%r82, %r29, -1;
	mul.wide.u32 	%rd124, %r82, 176;
	add.s64 	%rd12, %rd123, %rd124;
	add.u64 	%rd125, %SP, 0;
	cvta.to.local.u64 	%rd11, %rd125;
	mov.u32 	%r145, 0;

BB21_72:
	mul.wide.s32 	%rd126, %r145, 8;
	add.s64 	%rd127, %rd12, %rd126;
	ld.global.u64 	%rd128, [%rd127];
	add.s64 	%rd129, %rd11, %rd126;
	st.local.u64 	[%rd129], %rd128;
	add.s32 	%r145, %r145, 1;
	setp.lt.u32	%p123, %r145, 22;
	@%p123 bra 	BB21_72;

	ld.local.f64 	%fd155, [%rd11+16];
	setp.gt.f64	%p124, %fd155, 0d0000000000000000;
	@%p124 bra 	BB21_99;
	bra.uni 	BB21_74;

BB21_99:
	fma.rn.f64 	%fd437, %fd26, %fd26, 0d0000000000000000;
	sqrt.rn.f64 	%fd438, %fd437;
	setp.gt.f64	%p141, %fd438, 0d3EB0C6F7A0B5ED8D;
	selp.f64	%fd439, %fd438, 0d3EB0C6F7A0B5ED8D, %p141;
	ld.const.u32 	%r83, [dc_unitsOption];
	setp.eq.s32	%p142, %r83, 1;
	selp.f64	%fd440, 0d3EB3DD5DA733223F, 0d3E7D87247702C0D0, %p142;
	mul.f64 	%fd441, %fd152, %fd439;
	sqrt.rn.f64 	%fd442, %fd441;
	div.rn.f64 	%fd443, %fd440, %fd442;
	div.rn.f64 	%fd444, %fd155, 0d403E000000000000;
	add.f64 	%fd182, %fd444, %fd443;
	ld.local.f64 	%fd183, [%rd11+24];
	mov.f64 	%fd445, 0d3FC5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd445;
	}
	bfe.u32 	%r84, %r32, 20, 11;
	add.s32 	%r85, %r84, -1012;
	mov.u64 	%rd187, 4595172819793696085;
	shl.b64 	%rd16, %rd187, %r85;
	setp.eq.s64	%p143, %rd16, -9223372036854775808;
	abs.f64 	%fd184, %fd152;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd184;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd445;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd582, [retval0+0];
	
	//{
	}// Callseq End 2
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd152;
	}
	setp.lt.s32	%p144, %r33, 0;
	and.pred  	%p3, %p144, %p143;
	@!%p3 bra 	BB21_101;
	bra.uni 	BB21_100;

BB21_100:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd582;
	}
	xor.b32  	%r87, %r86, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r88, %temp}, %fd582;
	}
	mov.b64 	%fd582, {%r88, %r87};

BB21_101:
	mov.f64 	%fd581, %fd582;
	setp.eq.f64	%p145, %fd152, 0d0000000000000000;
	@%p145 bra 	BB21_104;
	bra.uni 	BB21_102;

BB21_104:
	selp.b32	%r89, %r33, 0, %p143;
	or.b32  	%r90, %r89, 2146435072;
	setp.lt.s32	%p149, %r32, 0;
	selp.b32	%r91, %r90, %r89, %p149;
	mov.u32 	%r92, 0;
	mov.b64 	%fd581, {%r92, %r91};
	bra.uni 	BB21_105;

BB21_74:
	ld.local.f64 	%fd594, [%rd11+8];
	setp.geu.f64	%p125, %fd594, 0d0000000000000000;
	@%p125 bra 	BB21_124;

	ld.local.f64 	%fd574, [%rd11+48];
	setp.lt.f64	%p126, %fd152, %fd574;
	@%p126 bra 	BB21_98;
	bra.uni 	BB21_76;

BB21_98:
	ld.local.f64 	%fd594, [%rd11+112];
	bra.uni 	BB21_124;

BB21_102:
	setp.gt.s32	%p146, %r33, -1;
	@%p146 bra 	BB21_105;

	cvt.rzi.f64.f64	%fd447, %fd445;
	setp.neu.f64	%p147, %fd447, 0d3FC5555555555555;
	selp.f64	%fd581, 0dFFF8000000000000, %fd581, %p147;

BB21_105:
	mov.f64 	%fd190, %fd581;
	add.f64 	%fd191, %fd152, 0d3FC5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r93}, %fd191;
	}
	and.b32  	%r94, %r93, 2146435072;
	setp.ne.s32	%p150, %r94, 2146435072;
	mov.f64 	%fd580, %fd190;
	@%p150 bra 	BB21_112;

	setp.gtu.f64	%p151, %fd184, 0d7FF0000000000000;
	mov.f64 	%fd580, %fd191;
	@%p151 bra 	BB21_112;

	abs.f64 	%fd192, %fd445;
	setp.gtu.f64	%p152, %fd192, 0d7FF0000000000000;
	mov.f64 	%fd579, %fd191;
	mov.f64 	%fd580, %fd579;
	@%p152 bra 	BB21_112;

	setp.eq.f64	%p153, %fd192, 0d7FF0000000000000;
	@%p153 bra 	BB21_111;
	bra.uni 	BB21_109;

BB21_111:
	setp.gt.f64	%p155, %fd184, 0d3FF0000000000000;
	selp.b32	%r101, 2146435072, 0, %p155;
	xor.b32  	%r102, %r101, 2146435072;
	setp.lt.s32	%p156, %r32, 0;
	selp.b32	%r103, %r102, %r101, %p156;
	setp.eq.f64	%p157, %fd152, 0dBFF0000000000000;
	selp.b32	%r104, 1072693248, %r103, %p157;
	mov.u32 	%r105, 0;
	mov.b64 	%fd580, {%r105, %r104};
	bra.uni 	BB21_112;

BB21_76:
	ld.local.f64 	%fd158, [%rd11+56];
	setp.lt.f64	%p127, %fd152, %fd158;
	mov.u64 	%rd216, 1;
	mov.u64 	%rd215, 0;
	mov.f64 	%fd575, %fd158;
	@%p127 bra 	BB21_97;

	setp.leu.f64	%p128, %fd574, 0d0000000000000000;
	mov.f64 	%fd600, %fd594;
	@%p128 bra 	BB21_79;

	ld.local.f64 	%fd600, [%rd11+112];

BB21_79:
	mov.f64 	%fd599, %fd600;
	ld.local.f64 	%fd161, [%rd11+64];
	setp.lt.f64	%p129, %fd152, %fd161;
	mov.u64 	%rd216, 2;
	mov.u64 	%rd215, 1;
	mov.f64 	%fd574, %fd158;
	mov.f64 	%fd575, %fd161;
	@%p129 bra 	BB21_97;

	setp.leu.f64	%p130, %fd158, 0d0000000000000000;
	@%p130 bra 	BB21_82;

	ld.local.f64 	%fd599, [%rd11+120];

BB21_82:
	mov.f64 	%fd598, %fd599;
	ld.local.f64 	%fd164, [%rd11+72];
	setp.lt.f64	%p131, %fd152, %fd164;
	mov.u64 	%rd216, 3;
	mov.u64 	%rd215, 2;
	mov.f64 	%fd574, %fd161;
	mov.f64 	%fd575, %fd164;
	@%p131 bra 	BB21_97;

	setp.leu.f64	%p132, %fd161, 0d0000000000000000;
	@%p132 bra 	BB21_85;

	ld.local.f64 	%fd598, [%rd11+128];

BB21_85:
	mov.f64 	%fd597, %fd598;
	ld.local.f64 	%fd167, [%rd11+80];
	setp.lt.f64	%p133, %fd152, %fd167;
	mov.u64 	%rd216, 4;
	mov.u64 	%rd215, 3;
	mov.f64 	%fd574, %fd164;
	mov.f64 	%fd575, %fd167;
	@%p133 bra 	BB21_97;

	setp.leu.f64	%p134, %fd164, 0d0000000000000000;
	@%p134 bra 	BB21_88;

	ld.local.f64 	%fd597, [%rd11+136];

BB21_88:
	mov.f64 	%fd596, %fd597;
	ld.local.f64 	%fd170, [%rd11+88];
	setp.lt.f64	%p135, %fd152, %fd170;
	mov.u64 	%rd216, 5;
	mov.u64 	%rd215, 4;
	mov.f64 	%fd574, %fd167;
	mov.f64 	%fd575, %fd170;
	@%p135 bra 	BB21_97;

	setp.leu.f64	%p136, %fd167, 0d0000000000000000;
	@%p136 bra 	BB21_91;

	ld.local.f64 	%fd596, [%rd11+144];

BB21_91:
	mov.f64 	%fd595, %fd596;
	ld.local.f64 	%fd173, [%rd11+96];
	setp.lt.f64	%p137, %fd152, %fd173;
	mov.u64 	%rd216, 6;
	mov.u64 	%rd215, 5;
	mov.f64 	%fd574, %fd170;
	mov.f64 	%fd575, %fd173;
	@%p137 bra 	BB21_97;

	setp.leu.f64	%p138, %fd170, 0d0000000000000000;
	@%p138 bra 	BB21_94;

	ld.local.f64 	%fd595, [%rd11+152];

BB21_94:
	mov.f64 	%fd594, %fd595;
	ld.local.f64 	%fd176, [%rd11+104];
	setp.lt.f64	%p139, %fd152, %fd176;
	mov.u64 	%rd216, 7;
	mov.u64 	%rd215, 6;
	mov.f64 	%fd574, %fd173;
	mov.f64 	%fd575, %fd176;
	@%p139 bra 	BB21_97;
	bra.uni 	BB21_95;

BB21_97:
	sub.f64 	%fd429, %fd575, %fd574;
	sub.f64 	%fd430, %fd152, %fd574;
	div.rn.f64 	%fd431, %fd430, %fd429;
	mov.f64 	%fd432, 0d3FF0000000000000;
	sub.f64 	%fd433, %fd432, %fd431;
	shl.b64 	%rd178, %rd215, 3;
	add.s64 	%rd179, %rd11, 112;
	add.s64 	%rd180, %rd179, %rd178;
	ld.local.f64 	%fd434, [%rd180];
	shl.b64 	%rd181, %rd216, 3;
	add.s64 	%rd182, %rd179, %rd181;
	ld.local.f64 	%fd435, [%rd182];
	mul.f64 	%fd436, %fd431, %fd435;
	fma.rn.f64 	%fd594, %fd433, %fd434, %fd436;
	bra.uni 	BB21_124;

BB21_109:
	setp.neu.f64	%p154, %fd184, 0d7FF0000000000000;
	mov.f64 	%fd580, %fd190;
	@%p154 bra 	BB21_112;

	shr.s32 	%r95, %r32, 31;
	and.b32  	%r96, %r95, -2146435072;
	add.s32 	%r97, %r96, 2146435072;
	or.b32  	%r98, %r97, -2147483648;
	selp.b32	%r99, %r98, %r97, %p3;
	mov.u32 	%r100, 0;
	mov.b64 	%fd580, {%r100, %r99};

BB21_112:
	setp.eq.f64	%p158, %fd152, 0d3FF0000000000000;
	selp.f64	%fd449, 0d3FF0000000000000, %fd580, %p158;
	mul.f64 	%fd196, %fd183, %fd449;
	sqrt.rn.f64 	%fd197, %fd24;
	div.rn.f64 	%fd198, %fd152, %fd182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %fd198;
	}
	setp.gt.f64	%p159, %fd198, 0d0000000000000000;
	setp.lt.s32	%p160, %r146, 2146435072;
	and.pred  	%p161, %p159, %p160;
	@%p161 bra 	BB21_117;
	bra.uni 	BB21_113;

BB21_117:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r147, %temp}, %fd198;
	}
	mov.u32 	%r148, -1023;
	setp.gt.s32	%p165, %r146, 1048575;
	@%p165 bra 	BB21_119;

	mul.f64 	%fd452, %fd198, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %fd452;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r147, %temp}, %fd452;
	}
	mov.u32 	%r148, -1077;

BB21_119:
	shr.u32 	%r108, %r146, 20;
	add.s32 	%r149, %r148, %r108;
	and.b32  	%r109, %r146, -2146435073;
	or.b32  	%r110, %r109, 1072693248;
	mov.b64 	%fd583, {%r147, %r110};
	setp.lt.s32	%p166, %r110, 1073127583;
	@%p166 bra 	BB21_121;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r111, %temp}, %fd583;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd583;
	}
	add.s32 	%r113, %r112, -1048576;
	mov.b64 	%fd583, {%r111, %r113};
	add.s32 	%r149, %r149, 1;

BB21_121:
	add.f64 	%fd454, %fd583, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd453,%fd454;
	// inline asm
	neg.f64 	%fd455, %fd454;
	mov.f64 	%fd456, 0d3FF0000000000000;
	fma.rn.f64 	%fd457, %fd455, %fd453, %fd456;
	fma.rn.f64 	%fd458, %fd457, %fd457, %fd457;
	fma.rn.f64 	%fd459, %fd458, %fd453, %fd453;
	add.f64 	%fd460, %fd583, 0dBFF0000000000000;
	mul.f64 	%fd461, %fd460, %fd459;
	fma.rn.f64 	%fd462, %fd460, %fd459, %fd461;
	mul.f64 	%fd463, %fd462, %fd462;
	mov.f64 	%fd464, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd465, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd466, %fd465, %fd463, %fd464;
	mov.f64 	%fd467, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd468, %fd466, %fd463, %fd467;
	mov.f64 	%fd469, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd470, %fd468, %fd463, %fd469;
	mov.f64 	%fd471, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd472, %fd470, %fd463, %fd471;
	mov.f64 	%fd473, 0d3F624924923BE72D;
	fma.rn.f64 	%fd474, %fd472, %fd463, %fd473;
	mov.f64 	%fd475, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd476, %fd474, %fd463, %fd475;
	mov.f64 	%fd477, 0d3FB5555555555554;
	fma.rn.f64 	%fd478, %fd476, %fd463, %fd477;
	sub.f64 	%fd479, %fd460, %fd462;
	add.f64 	%fd480, %fd479, %fd479;
	neg.f64 	%fd481, %fd462;
	fma.rn.f64 	%fd482, %fd481, %fd460, %fd480;
	mul.f64 	%fd483, %fd459, %fd482;
	mul.f64 	%fd484, %fd463, %fd478;
	fma.rn.f64 	%fd485, %fd484, %fd462, %fd483;
	xor.b32  	%r114, %r149, -2147483648;
	mov.u32 	%r115, 1127219200;
	mov.b64 	%fd486, {%r114, %r115};
	mov.u32 	%r116, -2147483648;
	mov.b64 	%fd487, {%r116, %r115};
	sub.f64 	%fd488, %fd486, %fd487;
	mov.f64 	%fd489, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd490, %fd488, %fd489, %fd462;
	neg.f64 	%fd491, %fd488;
	fma.rn.f64 	%fd492, %fd491, %fd489, %fd490;
	sub.f64 	%fd493, %fd492, %fd462;
	sub.f64 	%fd494, %fd485, %fd493;
	mov.f64 	%fd495, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd496, %fd488, %fd495, %fd494;
	add.f64 	%fd584, %fd490, %fd496;
	bra.uni 	BB21_122;

BB21_113:
	abs.f64 	%fd450, %fd198;
	setp.gtu.f64	%p162, %fd450, 0d7FF0000000000000;
	@%p162 bra 	BB21_116;
	bra.uni 	BB21_114;

BB21_116:
	add.f64 	%fd584, %fd198, %fd198;
	bra.uni 	BB21_122;

BB21_114:
	setp.eq.f64	%p163, %fd198, 0d0000000000000000;
	mov.f64 	%fd584, 0dFFF0000000000000;
	@%p163 bra 	BB21_122;

	setp.eq.f64	%p164, %fd198, 0d7FF0000000000000;
	selp.f64	%fd584, %fd198, 0dFFF8000000000000, %p164;

BB21_122:
	add.f64 	%fd497, %fd584, 0dBFF0000000000000;
	mul.f64 	%fd498, %fd197, %fd497;
	div.rn.f64 	%fd206, %fd196, %fd498;
	ld.local.f64 	%fd207, [%rd11+8];
	setp.gt.f64	%p167, %fd206, %fd207;
	mov.f64 	%fd594, %fd206;
	@%p167 bra 	BB21_124;

	mov.f64 	%fd594, %fd207;

BB21_124:
	mov.f64 	%fd593, %fd594;
	ld.const.u64 	%rd190, [dc_mnu];
	cvta.to.global.u64 	%rd191, %rd190;
	mul.wide.u32 	%rd192, %r4, 8;
	add.s64 	%rd193, %rd191, %rd192;
	st.global.f64 	[%rd193], %fd593;

BB21_125:
	ld.const.f64 	%fd500, [dc_nUnitsFactor];
	mul.f64 	%fd210, %fd593, %fd500;
	and.b32  	%r117, %r28, 1024;
	setp.eq.s32	%p168, %r117, 0;
	mov.f64 	%fd601, 0d0000000000000000;
	@%p168 bra 	BB21_127;

	ld.const.u64 	%rd194, [dc_uFormLoss];
	cvta.to.global.u64 	%rd195, %rd194;
	mul.wide.u32 	%rd196, %r4, 8;
	add.s64 	%rd197, %rd195, %rd196;
	ld.global.f64 	%fd601, [%rd197];

BB21_127:
	mul.f64 	%fd501, %fd153, 0d3FD0000000000000;
	div.rn.f64 	%fd213, %fd501, %fd151;
	mul.f64 	%fd502, %fd9, %fd566;
	sub.f64 	%fd503, %fd567, %fd502;
	ld.const.f64 	%fd504, [dc_dy];
	mul.f64 	%fd505, %fd25, %fd504;
	mul.f64 	%fd506, %fd151, %fd505;
	div.rn.f64 	%fd507, %fd503, %fd506;
	add.f64 	%fd603, %fd26, %fd507;
	ld.const.f64 	%fd215, [dc_shearStressH0];
	setp.leu.f64	%p169, %fd152, %fd215;
	@%p169 bra 	BB21_133;

	ld.const.u64 	%rd198, [dc_uniformShearStress];
	cvta.to.global.u64 	%rd199, %rd198;
	ld.global.f64 	%fd602, [%rd199];
	and.b32  	%r118, %r28, 64;
	setp.eq.s32	%p170, %r118, 0;
	@%p170 bra 	BB21_130;

	ld.param.f64 	%fd547, [gpu_calcDerivsSpatialU_param_3];
	mov.f64 	%fd508, 0d3FF0000000000000;
	sub.f64 	%fd509, %fd508, %fd547;
	ld.const.u64 	%rd200, [dc_tauU0];
	cvta.to.global.u64 	%rd201, %rd200;
	mul.wide.u32 	%rd202, %r4, 8;
	add.s64 	%rd203, %rd201, %rd202;
	ld.global.f64 	%fd510, [%rd203];
	ld.const.u64 	%rd204, [dc_tauU1];
	cvta.to.global.u64 	%rd205, %rd204;
	add.s64 	%rd206, %rd205, %rd202;
	ld.global.f64 	%fd511, [%rd206];
	mul.f64 	%fd512, %fd511, %fd547;
	fma.rn.f64 	%fd513, %fd509, %fd510, %fd512;
	add.f64 	%fd602, %fd602, %fd513;

BB21_130:
	ld.const.f64 	%fd219, [dc_shearStressH1];
	setp.geu.f64	%p171, %fd152, %fd219;
	@%p171 bra 	BB21_132;

	sub.f64 	%fd514, %fd152, %fd215;
	sub.f64 	%fd515, %fd219, %fd215;
	div.rn.f64 	%fd516, %fd514, %fd515;
	mul.f64 	%fd602, %fd602, %fd516;

BB21_132:
	ld.const.f64 	%fd517, [dc_rho];
	mul.f64 	%fd518, %fd152, %fd517;
	div.rn.f64 	%fd519, %fd602, %fd518;
	add.f64 	%fd603, %fd603, %fd519;

BB21_133:
	setp.gt.f64	%p172, %fd210, 0d0000000000000000;
	@%p172 bra 	BB21_135;
	bra.uni 	BB21_134;

BB21_135:
	mul.f64 	%fd522, %fd210, %fd24;
	mul.f64 	%fd225, %fd210, %fd522;
	mov.f64 	%fd523, 0d3FF5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd523;
	}
	bfe.u32 	%r119, %r44, 20, 11;
	add.s32 	%r120, %r119, -1012;
	mov.u64 	%rd207, 4608683618675807573;
	shl.b64 	%rd17, %rd207, %r120;
	setp.eq.s64	%p173, %rd17, -9223372036854775808;
	abs.f64 	%fd226, %fd152;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd226;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd523;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd610, [retval0+0];
	
	//{
	}// Callseq End 3
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd152;
	}
	setp.lt.s32	%p174, %r45, 0;
	and.pred  	%p4, %p174, %p173;
	@!%p4 bra 	BB21_137;
	bra.uni 	BB21_136;

BB21_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd610;
	}
	xor.b32  	%r122, %r121, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd610;
	}
	mov.b64 	%fd610, {%r123, %r122};

BB21_137:
	mov.f64 	%fd609, %fd610;
	setp.eq.f64	%p175, %fd152, 0d0000000000000000;
	@%p175 bra 	BB21_140;
	bra.uni 	BB21_138;

BB21_140:
	selp.b32	%r124, %r45, 0, %p173;
	or.b32  	%r125, %r124, 2146435072;
	setp.lt.s32	%p179, %r44, 0;
	selp.b32	%r126, %r125, %r124, %p179;
	mov.u32 	%r127, 0;
	mov.b64 	%fd609, {%r127, %r126};
	bra.uni 	BB21_141;

BB21_134:
	mul.f64 	%fd520, %fd601, %fd247;
	add.f64 	%fd521, %fd25, %fd25;
	div.rn.f64 	%fd611, %fd520, %fd521;
	bra.uni 	BB21_149;

BB21_138:
	setp.gt.s32	%p176, %r45, -1;
	@%p176 bra 	BB21_141;

	cvt.rzi.f64.f64	%fd525, %fd523;
	setp.neu.f64	%p177, %fd525, 0d3FF5555555555555;
	selp.f64	%fd609, 0dFFF8000000000000, %fd609, %p177;

BB21_141:
	mov.f64 	%fd232, %fd609;
	add.f64 	%fd233, %fd152, 0d3FF5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd233;
	}
	and.b32  	%r129, %r128, 2146435072;
	setp.ne.s32	%p180, %r129, 2146435072;
	mov.f64 	%fd608, %fd232;
	@%p180 bra 	BB21_148;

	setp.gtu.f64	%p181, %fd226, 0d7FF0000000000000;
	mov.f64 	%fd608, %fd233;
	@%p181 bra 	BB21_148;

	abs.f64 	%fd234, %fd523;
	setp.gtu.f64	%p182, %fd234, 0d7FF0000000000000;
	mov.f64 	%fd607, %fd233;
	mov.f64 	%fd608, %fd607;
	@%p182 bra 	BB21_148;

	setp.eq.f64	%p183, %fd234, 0d7FF0000000000000;
	@%p183 bra 	BB21_147;
	bra.uni 	BB21_145;

BB21_147:
	setp.gt.f64	%p185, %fd226, 0d3FF0000000000000;
	selp.b32	%r136, 2146435072, 0, %p185;
	xor.b32  	%r137, %r136, 2146435072;
	setp.lt.s32	%p186, %r44, 0;
	selp.b32	%r138, %r137, %r136, %p186;
	setp.eq.f64	%p187, %fd152, 0dBFF0000000000000;
	selp.b32	%r139, 1072693248, %r138, %p187;
	mov.u32 	%r140, 0;
	mov.b64 	%fd608, {%r140, %r139};
	bra.uni 	BB21_148;

BB21_145:
	setp.neu.f64	%p184, %fd226, 0d7FF0000000000000;
	mov.f64 	%fd608, %fd232;
	@%p184 bra 	BB21_148;

	shr.s32 	%r130, %r44, 31;
	and.b32  	%r131, %r130, -2146435072;
	add.s32 	%r132, %r131, 2146435072;
	or.b32  	%r133, %r132, -2147483648;
	selp.b32	%r134, %r133, %r132, %p4;
	mov.u32 	%r135, 0;
	mov.b64 	%fd608, {%r135, %r134};

BB21_148:
	setp.eq.f64	%p188, %fd152, 0d3FF0000000000000;
	selp.f64	%fd527, 0d3FF0000000000000, %fd608, %p188;
	div.rn.f64 	%fd528, %fd225, %fd527;
	add.f64 	%fd529, %fd25, %fd25;
	div.rn.f64 	%fd530, %fd601, %fd529;
	add.f64 	%fd531, %fd528, %fd530;
	mul.f64 	%fd611, %fd531, %fd247;

BB21_149:
	mov.f64 	%fd532, 0d412E848000000000;
	sub.f64 	%fd533, %fd532, %fd9;
	abs.f64 	%fd534, %fd533;
	setp.leu.f64	%p189, %fd534, 0d3EB0C6F7A0B5ED8D;
	mov.f64 	%fd641, %fd9;
	@%p189 bra 	BB21_152;

	fma.rn.f64 	%fd240, %fd603, %fd247, %fd9;
	mul.f64 	%fd241, %fd213, %fd213;
	mov.f64 	%fd535, 0d3FF0000000000000;
	mov.f64 	%fd612, %fd535;
	mov.f64 	%fd642, %fd9;

BB21_151:
	mov.f64 	%fd243, %fd642;
	mov.f64 	%fd242, %fd612;
	fma.rn.f64 	%fd536, %fd243, %fd243, %fd241;
	sqrt.rn.f64 	%fd537, %fd536;
	fma.rn.f64 	%fd538, %fd611, %fd537, 0d3FF0000000000000;
	div.rn.f64 	%fd539, %fd240, %fd538;
	sub.f64 	%fd541, %fd535, %fd242;
	mul.f64 	%fd542, %fd242, %fd539;
	fma.rn.f64 	%fd642, %fd243, %fd541, %fd542;
	add.f64 	%fd245, %fd242, 0dBFA999999999999A;
	sub.f64 	%fd543, %fd243, %fd642;
	abs.f64 	%fd544, %fd543;
	setp.gt.f64	%p190, %fd544, 0d3EB0C6F7A0B5ED8D;
	mov.f64 	%fd612, %fd245;
	mov.f64 	%fd640, %fd642;
	mov.f64 	%fd641, %fd640;
	@%p190 bra 	BB21_151;

BB21_152:
	mov.f64 	%fd246, %fd641;
	ld.param.u64 	%rd211, [gpu_calcDerivsSpatialU_param_7];
	sub.f64 	%fd545, %fd246, %fd9;
	div.rn.f64 	%fd546, %fd545, %fd247;
	cvta.to.global.u64 	%rd208, %rd211;
	mul.wide.u32 	%rd209, %r4, 8;
	add.s64 	%rd210, %rd208, %rd209;
	st.global.f64 	[%rd210], %fd546;

BB21_153:
	ret;

BB21_95:
	setp.leu.f64	%p140, %fd173, 0d0000000000000000;
	@%p140 bra 	BB21_124;

	ld.local.f64 	%fd594, [%rd11+160];
	bra.uni 	BB21_124;
}

	// .globl	gpu_calcDerivsSpatialV
.visible .entry gpu_calcDerivsSpatialV(
	.param .u32 gpu_calcDerivsSpatialV_param_0,
	.param .f64 gpu_calcDerivsSpatialV_param_1,
	.param .f64 gpu_calcDerivsSpatialV_param_2,
	.param .f64 gpu_calcDerivsSpatialV_param_3,
	.param .u64 gpu_calcDerivsSpatialV_param_4,
	.param .u64 gpu_calcDerivsSpatialV_param_5,
	.param .u64 gpu_calcDerivsSpatialV_param_6,
	.param .u64 gpu_calcDerivsSpatialV_param_7
)
{
	.local .align 8 .b8 	__local_depot22[176];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<191>;
	.reg .b32 	%r<153>;
	.reg .f64 	%fd<659>;
	.reg .b64 	%rd<222>;


	mov.u64 	%rd221, __local_depot22;
	cvta.local.u64 	%SP, %rd221;
	ld.param.f64 	%fd247, [gpu_calcDerivsSpatialV_param_2];
	ld.param.u64 	%rd19, [gpu_calcDerivsSpatialV_param_4];
	ld.param.u64 	%rd21, [gpu_calcDerivsSpatialV_param_6];
	cvta.to.global.u64 	%rd1, %rd21;
	mov.u32 	%r47, %ntid.x;
	mov.u32 	%r48, %ctaid.x;
	mov.u32 	%r49, %tid.x;
	mad.lo.s32 	%r1, %r47, %r48, %r49;
	mov.u32 	%r50, %ntid.y;
	mov.u32 	%r51, %ctaid.y;
	mov.u32 	%r52, %tid.y;
	mad.lo.s32 	%r2, %r50, %r51, %r52;
	setp.gt.s32	%p5, %r1, 1;
	ld.const.u32 	%r53, [dc_ny];
	add.s32 	%r54, %r53, -2;
	setp.lt.s32	%p6, %r1, %r54;
	and.pred  	%p7, %p5, %p6;
	setp.gt.s32	%p8, %r2, 1;
	and.pred  	%p9, %p7, %p8;
	ld.const.u32 	%r55, [dc_nx];
	add.s32 	%r56, %r55, -2;
	setp.lt.s32	%p10, %r2, %r56;
	and.pred  	%p11, %p9, %p10;
	@!%p11 bra 	BB22_153;
	bra.uni 	BB22_1;

BB22_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	sub.s32 	%r5, %r4, %r3;
	add.s32 	%r57, %r4, %r3;
	add.s32 	%r58, %r4, -1;
	add.s32 	%r6, %r5, 1;
	add.s32 	%r7, %r57, 1;
	ld.const.u64 	%rd23, [dc_a];
	cvta.to.global.u64 	%rd2, %rd23;
	cvt.u64.u32	%rd3, %r5;
	mul.wide.u32 	%rd24, %r5, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.global.u8 	%r8, [%rd25];
	cvt.u64.u32	%rd4, %r6;
	mul.wide.u32 	%rd26, %r6, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.global.u8 	%r9, [%rd27];
	cvt.u64.u32	%rd5, %r4;
	mul.wide.u32 	%rd28, %r4, 4;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.u8 	%r10, [%rd29];
	add.s32 	%r59, %r4, 1;
	cvt.u64.u32	%rd6, %r59;
	mul.wide.u32 	%rd30, %r59, 4;
	add.s64 	%rd31, %rd2, %rd30;
	ld.global.u8 	%r11, [%rd31];
	cvt.u64.u32	%rd7, %r57;
	mul.wide.u32 	%rd32, %r57, 4;
	add.s64 	%rd33, %rd2, %rd32;
	ld.global.u8 	%r12, [%rd33];
	cvt.u64.u32	%rd8, %r7;
	mul.wide.u32 	%rd34, %r7, 4;
	add.s64 	%rd35, %rd2, %rd34;
	ld.global.u8 	%r13, [%rd35];
	cvt.u64.u32	%rd9, %r58;
	setp.eq.s32	%p12, %r10, 0;
	setp.ne.s32	%p13, %r11, 255;
	and.pred  	%p14, %p12, %p13;
	setp.eq.s32	%p15, %r11, 0;
	setp.ne.s32	%p16, %r10, 255;
	and.pred  	%p17, %p15, %p16;
	or.pred  	%p18, %p14, %p17;
	@!%p18 bra 	BB22_153;
	bra.uni 	BB22_2;

BB22_2:
	cvta.to.global.u64 	%rd37, %rd19;
	sub.s32 	%r60, %r5, %r3;
	sub.s32 	%r61, %r6, %r3;
	add.s32 	%r62, %r4, 2;
	mad.lo.s32 	%r63, %r3, 2, %r4;
	add.s32 	%r64, %r7, %r3;
	mul.wide.u32 	%rd38, %r60, 4;
	add.s64 	%rd39, %rd2, %rd38;
	ld.global.u32 	%r14, [%rd39];
	mul.wide.u32 	%rd40, %r61, 4;
	add.s64 	%rd41, %rd2, %rd40;
	ld.global.u32 	%r15, [%rd41];
	shl.b64 	%rd42, %rd9, 2;
	add.s64 	%rd43, %rd2, %rd42;
	ld.global.u32 	%r16, [%rd43];
	mul.wide.u32 	%rd44, %r62, 4;
	add.s64 	%rd45, %rd2, %rd44;
	ld.global.u32 	%r17, [%rd45];
	mul.wide.u32 	%rd46, %r63, 4;
	add.s64 	%rd47, %rd2, %rd46;
	ld.global.u32 	%r18, [%rd47];
	mul.wide.u32 	%rd48, %r64, 4;
	add.s64 	%rd49, %rd2, %rd48;
	ld.global.u32 	%r19, [%rd49];
	shl.b64 	%rd50, %rd3, 3;
	add.s64 	%rd51, %rd37, %rd50;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.global.f64 	%fd2, [%rd51];
	ld.const.f64 	%fd3, [dc_dryDepthThreshold];
	shl.b64 	%rd52, %rd4, 3;
	add.s64 	%rd53, %rd37, %rd52;
	ld.global.f64 	%fd4, [%rd53];
	shl.b64 	%rd54, %rd5, 3;
	add.s64 	%rd55, %rd37, %rd54;
	ld.global.f64 	%fd249, [%rd55];
	setp.gt.f64	%p19, %fd249, %fd1;
	selp.f64	%fd5, %fd249, %fd3, %p19;
	shl.b64 	%rd56, %rd6, 3;
	add.s64 	%rd57, %rd37, %rd56;
	ld.global.f64 	%fd250, [%rd57];
	setp.gt.f64	%p20, %fd250, %fd1;
	selp.f64	%fd6, %fd250, %fd3, %p20;
	shl.b64 	%rd58, %rd7, 3;
	add.s64 	%rd59, %rd37, %rd58;
	ld.global.f64 	%fd7, [%rd59];
	shl.b64 	%rd60, %rd8, 3;
	add.s64 	%rd61, %rd37, %rd60;
	ld.global.f64 	%fd8, [%rd61];
	add.s64 	%rd62, %rd1, %rd54;
	ld.global.f64 	%fd9, [%rd62];
	ld.const.u64 	%rd63, [dc_zc];
	cvta.to.global.u64 	%rd64, %rd63;
	add.s64 	%rd65, %rd64, %rd54;
	add.s64 	%rd66, %rd64, %rd56;
	ld.const.u64 	%rd67, [dc_zv];
	cvta.to.global.u64 	%rd68, %rd67;
	add.s64 	%rd69, %rd68, %rd54;
	ld.global.f64 	%fd10, [%rd65];
	add.f64 	%fd548, %fd5, %fd10;
	ld.global.f64 	%fd12, [%rd66];
	add.f64 	%fd549, %fd6, %fd12;
	setp.gt.f64	%p21, %fd5, %fd1;
	setp.gt.f64	%p22, %fd548, %fd12;
	and.pred  	%p23, %p21, %p22;
	ld.global.f64 	%fd14, [%rd69];
	setp.gt.f64	%p24, %fd548, %fd14;
	and.pred  	%p25, %p23, %p24;
	@%p25 bra 	BB22_5;

	setp.gt.f64	%p26, %fd6, %fd1;
	setp.gt.f64	%p27, %fd549, %fd10;
	and.pred  	%p28, %p26, %p27;
	setp.gt.f64	%p29, %fd549, %fd14;
	and.pred  	%p30, %p28, %p29;
	@%p30 bra 	BB22_5;
	bra.uni 	BB22_4;

BB22_5:
	setp.gt.f64	%p31, %fd2, %fd1;
	selp.f64	%fd15, %fd2, %fd3, %p31;
	setp.gt.f64	%p32, %fd4, %fd1;
	selp.f64	%fd16, %fd4, %fd3, %p32;
	setp.gt.f64	%p33, %fd7, %fd1;
	selp.f64	%fd17, %fd7, %fd3, %p33;
	setp.gt.f64	%p34, %fd8, %fd1;
	selp.f64	%fd18, %fd8, %fd3, %p34;
	setp.gt.f64	%p35, %fd548, %fd549;
	setp.gt.f64	%p36, %fd10, %fd12;
	selp.f64	%fd253, %fd10, %fd12, %p36;
	sub.f64 	%fd254, %fd14, %fd253;
	add.f64 	%fd19, %fd254, %fd254;
	@%p35 bra 	BB22_7;
	bra.uni 	BB22_6;

BB22_7:
	div.rn.f64 	%fd269, %fd19, %fd5;
	setp.gt.f64	%p42, %fd269, 0d0000000000000000;
	selp.f64	%fd270, %fd269, 0d0000000000000000, %p42;
	setp.lt.f64	%p43, %fd270, 0d3FF0000000000000;
	selp.f64	%fd271, %fd270, 0d3FF0000000000000, %p43;
	mov.f64 	%fd272, 0d3FF0000000000000;
	sub.f64 	%fd273, %fd272, %fd271;
	ld.const.u32 	%r147, [dc_spatialOrder];
	setp.eq.s32	%p44, %r147, 1;
	selp.f64	%fd274, 0d3FE199999999999A, 0d3FD3333333333333, %p44;
	mul.f64 	%fd275, %fd274, %fd273;
	fma.rn.f64 	%fd276, %fd271, 0d3FE8F5C28F5C28F6, %fd275;
	sub.f64 	%fd277, %fd272, %fd276;
	mul.f64 	%fd278, %fd14, %fd277;
	fma.rn.f64 	%fd279, %fd548, %fd276, %fd278;
	sub.f64 	%fd280, %fd10, %fd14;
	setp.gt.f64	%p45, %fd10, %fd14;
	selp.f64	%fd281, %fd280, 0d0000000000000000, %p45;
	sub.f64 	%fd282, %fd279, %fd281;
	setp.gt.f64	%p46, %fd549, %fd282;
	selp.f64	%fd549, %fd549, %fd282, %p46;
	bra.uni 	BB22_8;

BB22_6:
	div.rn.f64 	%fd255, %fd19, %fd6;
	setp.gt.f64	%p37, %fd255, 0d0000000000000000;
	selp.f64	%fd256, %fd255, 0d0000000000000000, %p37;
	setp.lt.f64	%p38, %fd256, 0d3FF0000000000000;
	selp.f64	%fd257, %fd256, 0d3FF0000000000000, %p38;
	mov.f64 	%fd258, 0d3FF0000000000000;
	sub.f64 	%fd259, %fd258, %fd257;
	ld.const.u32 	%r147, [dc_spatialOrder];
	setp.eq.s32	%p39, %r147, 1;
	selp.f64	%fd260, 0d3FE199999999999A, 0d3FD3333333333333, %p39;
	mul.f64 	%fd261, %fd260, %fd259;
	fma.rn.f64 	%fd262, %fd257, 0d3FE8F5C28F5C28F6, %fd261;
	sub.f64 	%fd263, %fd258, %fd262;
	mul.f64 	%fd264, %fd14, %fd263;
	fma.rn.f64 	%fd265, %fd549, %fd262, %fd264;
	sub.f64 	%fd266, %fd12, %fd14;
	setp.gt.f64	%p40, %fd12, %fd14;
	selp.f64	%fd267, %fd266, 0d0000000000000000, %p40;
	sub.f64 	%fd268, %fd265, %fd267;
	setp.gt.f64	%p41, %fd548, %fd268;
	selp.f64	%fd548, %fd548, %fd268, %p41;

BB22_8:
	add.s32 	%r146, %r4, 1;
	ld.param.u64 	%rd218, [gpu_calcDerivsSpatialV_param_5];
	ld.const.u32 	%r145, [dc_nyPadded];
	cvta.to.global.u64 	%rd70, %rd218;
	and.b32  	%r23, %r14, 255;
	and.b32  	%r24, %r15, 255;
	and.b32  	%r25, %r16, 255;
	and.b32  	%r26, %r17, 255;
	and.b32  	%r27, %r18, 255;
	and.b32  	%r28, %r19, 255;
	sub.f64 	%fd283, %fd548, %fd549;
	ld.const.f64 	%fd24, [dc_g];
	mul.f64 	%fd284, %fd24, %fd283;
	ld.const.f64 	%fd25, [dc_dy];
	div.rn.f64 	%fd26, %fd284, %fd25;
	ld.const.u64 	%rd71, [dc_nut];
	cvta.to.global.u64 	%rd72, %rd71;
	add.s64 	%rd74, %rd72, %rd50;
	ld.global.f64 	%fd27, [%rd74];
	add.s64 	%rd76, %rd72, %rd52;
	ld.global.f64 	%fd28, [%rd76];
	add.s64 	%rd78, %rd72, %rd54;
	ld.global.f64 	%fd29, [%rd78];
	add.s64 	%rd80, %rd72, %rd56;
	ld.global.f64 	%fd30, [%rd80];
	add.s64 	%rd82, %rd72, %rd58;
	ld.global.f64 	%fd31, [%rd82];
	add.s64 	%rd84, %rd72, %rd60;
	ld.global.f64 	%fd32, [%rd84];
	sub.s32 	%r66, %r146, %r145;
	mul.wide.u32 	%rd85, %r66, 8;
	add.s64 	%rd86, %rd70, %rd85;
	ld.const.u64 	%rd87, [dc_phi4];
	cvta.to.global.u64 	%rd88, %rd87;
	add.s64 	%rd89, %rd88, %rd54;
	shl.b64 	%rd90, %rd9, 3;
	add.s64 	%rd91, %rd88, %rd90;
	add.s64 	%rd92, %rd88, %rd56;
	ld.const.u64 	%rd93, [dc_phi2];
	cvta.to.global.u64 	%rd94, %rd93;
	add.s64 	%rd95, %rd94, %rd50;
	add.s64 	%rd96, %rd94, %rd54;
	add.s64 	%rd97, %rd94, %rd85;
	add.s64 	%rd98, %rd94, %rd56;
	setp.ne.s32	%p47, %r8, 0;
	setp.ne.s32	%p48, %r9, 0;
	and.pred  	%p1, %p48, %p47;
	add.s64 	%rd99, %rd1, %rd50;
	ld.global.f64 	%fd285, [%rd99];
	selp.f64	%fd33, %fd9, %fd285, %p1;
	add.s64 	%rd100, %rd1, %rd90;
	ld.global.f64 	%fd286, [%rd100];
	selp.f64	%fd34, %fd286, %fd9, %p12;
	ld.global.f64 	%fd287, [%rd86];
	add.s64 	%rd101, %rd70, %rd50;
	ld.global.f64 	%fd288, [%rd101];
	selp.f64	%fd35, %fd288, %fd287, %p12;
	add.s64 	%rd102, %rd70, %rd56;
	ld.global.f64 	%fd289, [%rd102];
	add.s64 	%rd103, %rd70, %rd54;
	ld.global.f64 	%fd290, [%rd103];
	selp.f64	%fd36, %fd290, %fd289, %p12;
	ld.global.f64 	%fd291, [%rd91];
	ld.global.f64 	%fd292, [%rd89];
	selp.f64	%fd293, %fd291, %fd292, %p12;
	ld.global.f64 	%fd294, [%rd97];
	ld.global.f64 	%fd295, [%rd95];
	selp.f64	%fd37, %fd295, %fd294, %p12;
	ld.global.f64 	%fd296, [%rd98];
	ld.global.f64 	%fd297, [%rd96];
	selp.f64	%fd38, %fd297, %fd296, %p12;
	add.s64 	%rd104, %rd1, %rd56;
	ld.global.f64 	%fd298, [%rd104];
	selp.f64	%fd39, %fd298, %fd9, %p15;
	selp.f64	%fd40, %fd287, %fd35, %p15;
	selp.f64	%fd41, %fd289, %fd36, %p15;
	ld.global.f64 	%fd299, [%rd92];
	selp.f64	%fd300, %fd299, %fd292, %p15;
	selp.f64	%fd42, %fd294, %fd37, %p15;
	selp.f64	%fd43, %fd296, %fd38, %p15;
	setp.ne.s32	%p51, %r12, 0;
	setp.ne.s32	%p52, %r13, 0;
	and.pred  	%p2, %p52, %p51;
	add.s64 	%rd105, %rd1, %rd58;
	ld.global.f64 	%fd301, [%rd105];
	selp.f64	%fd44, %fd9, %fd301, %p2;
	add.f64 	%fd302, %fd292, %fd293;
	mul.f64 	%fd45, %fd302, 0d3FE0000000000000;
	add.f64 	%fd303, %fd292, %fd300;
	mul.f64 	%fd46, %fd303, 0d3FE0000000000000;
	setp.gt.s32	%p53, %r147, 1;
	@%p53 bra 	BB22_10;
	bra.uni 	BB22_9;

BB22_10:
	add.s32 	%r144, %r4, 2;
	ld.const.u32 	%r143, [dc_nyPadded];
	shl.b32 	%r67, %r143, 1;
	sub.s32 	%r77, %r4, %r67;
	add.s32 	%r78, %r67, %r4;
	add.s32 	%r79, %r4, -2;
	mul.wide.u32 	%rd107, %r77, 8;
	add.s64 	%rd108, %rd1, %rd107;
	mul.wide.u32 	%rd109, %r78, 8;
	add.s64 	%rd11, %rd1, %rd109;
	mul.wide.u32 	%rd110, %r79, 8;
	add.s64 	%rd111, %rd1, %rd110;
	mul.wide.u32 	%rd112, %r144, 8;
	add.s64 	%rd113, %rd1, %rd112;
	setp.ne.s32	%p58, %r23, 0;
	setp.ne.s32	%p59, %r24, 0;
	and.pred  	%p60, %p59, %p58;
	or.pred  	%p61, %p1, %p60;
	ld.global.f64 	%fd306, [%rd108];
	selp.f64	%fd51, %fd33, %fd306, %p61;
	setp.ne.s32	%p62, %r25, 0;
	setp.ne.s32	%p63, %r25, 255;
	and.pred  	%p64, %p63, %p62;
	setp.ne.s32	%p65, %r10, 0;
	or.pred  	%p66, %p64, %p65;
	ld.global.f64 	%fd307, [%rd111];
	selp.f64	%fd52, %fd34, %fd307, %p66;
	setp.ne.s32	%p67, %r26, 0;
	setp.ne.s32	%p68, %r26, 255;
	and.pred  	%p69, %p68, %p67;
	setp.ne.s32	%p70, %r11, 0;
	or.pred  	%p71, %p69, %p70;
	ld.global.f64 	%fd308, [%rd113];
	selp.f64	%fd53, %fd39, %fd308, %p71;
	mov.f64 	%fd658, %fd44;
	@%p2 bra 	BB22_12;

	ld.global.f64 	%fd309, [%rd11];
	setp.ne.s32	%p72, %r27, 0;
	setp.ne.s32	%p73, %r28, 0;
	and.pred  	%p74, %p73, %p72;
	selp.f64	%fd54, %fd44, %fd309, %p74;
	mov.f64 	%fd658, %fd54;

BB22_12:
	mov.f64 	%fd55, %fd658;
	add.f64 	%fd310, %fd37, %fd42;
	setp.gt.f64	%p75, %fd310, 0d0000000000000000;
	@%p75 bra 	BB22_14;
	bra.uni 	BB22_13;

BB22_14:
	sub.f64 	%fd550, %fd33, %fd51;
	sub.f64 	%fd551, %fd9, %fd51;
	sub.f64 	%fd552, %fd9, %fd33;
	mov.f64 	%fd657, %fd33;
	bra.uni 	BB22_15;

BB22_9:
	add.f64 	%fd304, %fd37, %fd42;
	setp.gt.f64	%p54, %fd304, 0d0000000000000000;
	selp.f64	%fd646, %fd33, %fd9, %p54;
	add.f64 	%fd305, %fd38, %fd43;
	setp.gt.f64	%p55, %fd305, 0d0000000000000000;
	selp.f64	%fd645, %fd9, %fd44, %p55;
	setp.gt.f64	%p56, %fd45, 0d0000000000000000;
	selp.f64	%fd644, %fd34, %fd9, %p56;
	setp.gt.f64	%p57, %fd46, 0d0000000000000000;
	selp.f64	%fd643, %fd9, %fd39, %p57;
	bra.uni 	BB22_52;

BB22_4:
	ld.param.u64 	%rd217, [gpu_calcDerivsSpatialV_param_7];
	cvt.u64.u32	%rd216, %r4;
	shl.b64 	%rd215, %rd216, 3;
	cvta.to.global.u64 	%rd214, %rd217;
	add.s64 	%rd213, %rd214, %rd215;
	mul.f64 	%fd251, %fd9, 0dBFD999999999999A;
	div.rn.f64 	%fd252, %fd251, %fd247;
	st.global.f64 	[%rd213], %fd252;
	bra.uni 	BB22_153;

BB22_13:
	sub.f64 	%fd550, %fd9, %fd44;
	sub.f64 	%fd551, %fd33, %fd44;
	sub.f64 	%fd552, %fd33, %fd9;
	mov.f64 	%fd617, %fd9;
	mov.f64 	%fd657, %fd617;

BB22_15:
	mov.f64 	%fd619, %fd657;
	mov.f64 	%fd62, %fd619;
	mul.f64 	%fd311, %fd550, %fd552;
	setp.leu.f64	%p76, %fd311, 0d0000000000000000;
	mov.f64 	%fd655, %fd62;
	@%p76 bra 	BB22_22;

	setp.eq.s32	%p77, %r147, 2;
	@%p77 bra 	BB22_19;
	bra.uni 	BB22_17;

BB22_19:
	add.f64 	%fd316, %fd9, %fd33;
	mul.f64 	%fd656, %fd316, 0d3FE0000000000000;
	bra.uni 	BB22_20;

BB22_17:
	setp.ne.s32	%p78, %r147, 4;
	mov.f64 	%fd656, %fd62;
	@%p78 bra 	BB22_20;

	add.f64 	%fd312, %fd9, %fd33;
	mul.f64 	%fd313, %fd312, 0d4022000000000000;
	add.f64 	%fd314, %fd44, %fd51;
	sub.f64 	%fd315, %fd313, %fd314;
	mul.f64 	%fd656, %fd315, 0d3FB0000000000000;

BB22_20:
	mov.f64 	%fd68, %fd656;
	div.rn.f64 	%fd317, %fd550, %fd551;
	setp.lt.f64	%p79, %fd317, 0d3FE0000000000000;
	mov.f64 	%fd318, 0d3FF0000000000000;
	sub.f64 	%fd319, %fd318, %fd317;
	selp.f64	%fd320, %fd317, %fd319, %p79;
	mul.f64 	%fd69, %fd320, 0d4024000000000000;
	setp.geu.f64	%p80, %fd69, 0d3FF0000000000000;
	mov.f64 	%fd655, %fd68;
	@%p80 bra 	BB22_22;

	sub.f64 	%fd322, %fd318, %fd69;
	mul.f64 	%fd323, %fd62, %fd322;
	fma.rn.f64 	%fd655, %fd68, %fd69, %fd323;

BB22_22:
	mov.f64 	%fd71, %fd655;
	add.f64 	%fd324, %fd38, %fd43;
	setp.gt.f64	%p81, %fd324, 0d0000000000000000;
	@%p81 bra 	BB22_24;
	bra.uni 	BB22_23;

BB22_24:
	sub.f64 	%fd553, %fd9, %fd33;
	sub.f64 	%fd554, %fd44, %fd33;
	sub.f64 	%fd555, %fd44, %fd9;
	mov.f64 	%fd654, %fd9;
	bra.uni 	BB22_25;

BB22_23:
	sub.f64 	%fd553, %fd44, %fd55;
	sub.f64 	%fd554, %fd9, %fd55;
	sub.f64 	%fd555, %fd9, %fd44;
	mov.f64 	%fd654, %fd44;

BB22_25:
	mov.f64 	%fd78, %fd654;
	mul.f64 	%fd325, %fd553, %fd555;
	setp.leu.f64	%p82, %fd325, 0d0000000000000000;
	mov.f64 	%fd652, %fd78;
	@%p82 bra 	BB22_32;

	setp.eq.s32	%p83, %r147, 2;
	@%p83 bra 	BB22_29;
	bra.uni 	BB22_27;

BB22_29:
	add.f64 	%fd330, %fd9, %fd44;
	mul.f64 	%fd653, %fd330, 0d3FE0000000000000;
	bra.uni 	BB22_30;

BB22_27:
	setp.ne.s32	%p84, %r147, 4;
	mov.f64 	%fd653, %fd78;
	@%p84 bra 	BB22_30;

	add.f64 	%fd326, %fd9, %fd44;
	mul.f64 	%fd327, %fd326, 0d4022000000000000;
	add.f64 	%fd328, %fd33, %fd55;
	sub.f64 	%fd329, %fd327, %fd328;
	mul.f64 	%fd653, %fd329, 0d3FB0000000000000;

BB22_30:
	mov.f64 	%fd84, %fd653;
	div.rn.f64 	%fd331, %fd553, %fd554;
	setp.lt.f64	%p85, %fd331, 0d3FE0000000000000;
	mov.f64 	%fd332, 0d3FF0000000000000;
	sub.f64 	%fd333, %fd332, %fd331;
	selp.f64	%fd334, %fd331, %fd333, %p85;
	mul.f64 	%fd85, %fd334, 0d4024000000000000;
	setp.geu.f64	%p86, %fd85, 0d3FF0000000000000;
	mov.f64 	%fd652, %fd84;
	@%p86 bra 	BB22_32;

	sub.f64 	%fd336, %fd332, %fd85;
	mul.f64 	%fd337, %fd78, %fd336;
	fma.rn.f64 	%fd652, %fd84, %fd85, %fd337;

BB22_32:
	mov.f64 	%fd87, %fd652;
	setp.gt.f64	%p87, %fd45, 0d0000000000000000;
	@%p87 bra 	BB22_34;
	bra.uni 	BB22_33;

BB22_34:
	sub.f64 	%fd556, %fd34, %fd52;
	sub.f64 	%fd557, %fd9, %fd52;
	sub.f64 	%fd558, %fd9, %fd34;
	mov.f64 	%fd651, %fd34;
	bra.uni 	BB22_35;

BB22_33:
	sub.f64 	%fd556, %fd9, %fd39;
	sub.f64 	%fd557, %fd34, %fd39;
	sub.f64 	%fd558, %fd34, %fd9;
	mov.f64 	%fd615, %fd9;
	mov.f64 	%fd651, %fd615;

BB22_35:
	mov.f64 	%fd631, %fd651;
	mov.f64 	%fd94, %fd631;
	mul.f64 	%fd338, %fd556, %fd558;
	setp.leu.f64	%p88, %fd338, 0d0000000000000000;
	mov.f64 	%fd649, %fd94;
	@%p88 bra 	BB22_42;

	setp.eq.s32	%p89, %r147, 2;
	@%p89 bra 	BB22_39;
	bra.uni 	BB22_37;

BB22_39:
	add.f64 	%fd343, %fd9, %fd34;
	mul.f64 	%fd650, %fd343, 0d3FE0000000000000;
	bra.uni 	BB22_40;

BB22_37:
	setp.ne.s32	%p90, %r147, 4;
	mov.f64 	%fd650, %fd94;
	@%p90 bra 	BB22_40;

	add.f64 	%fd339, %fd9, %fd34;
	mul.f64 	%fd340, %fd339, 0d4022000000000000;
	add.f64 	%fd341, %fd39, %fd52;
	sub.f64 	%fd342, %fd340, %fd341;
	mul.f64 	%fd650, %fd342, 0d3FB0000000000000;

BB22_40:
	mov.f64 	%fd100, %fd650;
	div.rn.f64 	%fd344, %fd556, %fd557;
	setp.lt.f64	%p91, %fd344, 0d3FE0000000000000;
	mov.f64 	%fd345, 0d3FF0000000000000;
	sub.f64 	%fd346, %fd345, %fd344;
	selp.f64	%fd347, %fd344, %fd346, %p91;
	mul.f64 	%fd101, %fd347, 0d4024000000000000;
	setp.geu.f64	%p92, %fd101, 0d3FF0000000000000;
	mov.f64 	%fd649, %fd100;
	@%p92 bra 	BB22_42;

	sub.f64 	%fd349, %fd345, %fd101;
	mul.f64 	%fd350, %fd94, %fd349;
	fma.rn.f64 	%fd649, %fd100, %fd101, %fd350;

BB22_42:
	mov.f64 	%fd103, %fd649;
	setp.gt.f64	%p93, %fd46, 0d0000000000000000;
	@%p93 bra 	BB22_44;
	bra.uni 	BB22_43;

BB22_44:
	sub.f64 	%fd559, %fd9, %fd34;
	sub.f64 	%fd560, %fd39, %fd34;
	sub.f64 	%fd561, %fd39, %fd9;
	mov.f64 	%fd616, %fd9;
	mov.f64 	%fd648, %fd616;
	bra.uni 	BB22_45;

BB22_43:
	sub.f64 	%fd559, %fd39, %fd53;
	sub.f64 	%fd560, %fd9, %fd53;
	sub.f64 	%fd561, %fd9, %fd39;
	mov.f64 	%fd648, %fd39;

BB22_45:
	mov.f64 	%fd637, %fd648;
	mov.f64 	%fd110, %fd637;
	mul.f64 	%fd351, %fd559, %fd561;
	setp.leu.f64	%p94, %fd351, 0d0000000000000000;
	mov.f64 	%fd643, %fd110;
	mov.f64 	%fd644, %fd103;
	mov.f64 	%fd645, %fd87;
	mov.f64 	%fd646, %fd71;
	@%p94 bra 	BB22_52;

	setp.eq.s32	%p95, %r147, 2;
	@%p95 bra 	BB22_49;
	bra.uni 	BB22_47;

BB22_49:
	add.f64 	%fd356, %fd9, %fd39;
	mul.f64 	%fd647, %fd356, 0d3FE0000000000000;
	bra.uni 	BB22_50;

BB22_47:
	setp.ne.s32	%p96, %r147, 4;
	mov.f64 	%fd647, %fd110;
	@%p96 bra 	BB22_50;

	add.f64 	%fd352, %fd9, %fd39;
	mul.f64 	%fd353, %fd352, 0d4022000000000000;
	add.f64 	%fd354, %fd34, %fd53;
	sub.f64 	%fd355, %fd353, %fd354;
	mul.f64 	%fd647, %fd355, 0d3FB0000000000000;

BB22_50:
	mov.f64 	%fd116, %fd647;
	div.rn.f64 	%fd357, %fd559, %fd560;
	setp.lt.f64	%p97, %fd357, 0d3FE0000000000000;
	mov.f64 	%fd358, 0d3FF0000000000000;
	sub.f64 	%fd359, %fd358, %fd357;
	selp.f64	%fd360, %fd357, %fd359, %p97;
	mul.f64 	%fd117, %fd360, 0d4024000000000000;
	setp.geu.f64	%p98, %fd117, 0d3FF0000000000000;
	mov.f64 	%fd623, %fd71;
	mov.f64 	%fd629, %fd87;
	mov.f64 	%fd635, %fd103;
	mov.f64 	%fd643, %fd116;
	mov.f64 	%fd644, %fd635;
	mov.f64 	%fd645, %fd629;
	mov.f64 	%fd646, %fd623;
	@%p98 bra 	BB22_52;

	sub.f64 	%fd362, %fd358, %fd117;
	mul.f64 	%fd363, %fd110, %fd362;
	fma.rn.f64 	%fd643, %fd116, %fd117, %fd363;
	mov.f64 	%fd646, %fd71;
	mov.f64 	%fd645, %fd87;
	mov.f64 	%fd644, %fd103;

BB22_52:
	setp.eq.s32	%p99, %r8, 255;
	mov.f64 	%fd563, 0d0000000000000000;
	mov.f64 	%fd562, %fd563;
	@%p99 bra 	BB22_55;

	mul.f64 	%fd366, %fd37, 0d3FE0000000000000;
	add.f64 	%fd562, %fd366, 0d0000000000000000;
	fma.rn.f64 	%fd563, %fd366, %fd646, 0d0000000000000000;
	setp.gt.f64	%p100, %fd29, 0d0000000000000000;
	setp.gt.f64	%p101, %fd27, 0d0000000000000000;
	and.pred  	%p102, %p101, %p100;
	@!%p102 bra 	BB22_55;
	bra.uni 	BB22_54;

BB22_54:
	setp.lt.f64	%p103, %fd15, %fd5;
	selp.f64	%fd367, %fd15, %fd5, %p103;
	mul.f64 	%fd368, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd369, %fd367, %fd368;
	add.f64 	%fd370, %fd27, %fd29;
	mul.f64 	%fd371, %fd370, %fd369;
	sub.f64 	%fd372, %fd33, %fd9;
	mul.f64 	%fd373, %fd372, %fd371;
	ld.const.f64 	%fd374, [dc_dx];
	div.rn.f64 	%fd375, %fd373, %fd374;
	add.f64 	%fd563, %fd563, %fd375;

BB22_55:
	add.f64 	%fd564, %fd45, %fd562;
	fma.rn.f64 	%fd565, %fd45, %fd644, %fd563;
	setp.leu.f64	%p104, %fd29, 0d0000000000000000;
	@%p104 bra 	BB22_57;

	ld.const.f64 	%fd376, [dc_dx];
	mul.f64 	%fd377, %fd5, %fd376;
	mul.f64 	%fd378, %fd29, %fd377;
	sub.f64 	%fd379, %fd34, %fd9;
	mul.f64 	%fd380, %fd379, %fd378;
	div.rn.f64 	%fd381, %fd380, %fd25;
	add.f64 	%fd565, %fd565, %fd381;

BB22_57:
	setp.eq.s32	%p105, %r12, 255;
	@%p105 bra 	BB22_60;

	setp.gt.f64	%p106, %fd29, 0d0000000000000000;
	mul.f64 	%fd382, %fd38, 0d3FE0000000000000;
	sub.f64 	%fd564, %fd564, %fd382;
	mul.f64 	%fd383, %fd382, %fd645;
	sub.f64 	%fd565, %fd565, %fd383;
	setp.gt.f64	%p107, %fd31, 0d0000000000000000;
	and.pred  	%p108, %p107, %p106;
	@!%p108 bra 	BB22_60;
	bra.uni 	BB22_59;

BB22_59:
	setp.lt.f64	%p109, %fd17, %fd5;
	selp.f64	%fd384, %fd17, %fd5, %p109;
	mul.f64 	%fd385, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd386, %fd384, %fd385;
	add.f64 	%fd387, %fd29, %fd31;
	mul.f64 	%fd388, %fd387, %fd386;
	sub.f64 	%fd389, %fd44, %fd9;
	mul.f64 	%fd390, %fd389, %fd388;
	ld.const.f64 	%fd391, [dc_dx];
	div.rn.f64 	%fd392, %fd390, %fd391;
	add.f64 	%fd565, %fd565, %fd392;

BB22_60:
	setp.eq.s32	%p110, %r9, 255;
	@%p110 bra 	BB22_63;

	mul.f64 	%fd393, %fd42, 0d3FE0000000000000;
	add.f64 	%fd564, %fd393, %fd564;
	fma.rn.f64 	%fd565, %fd393, %fd646, %fd565;
	setp.gt.f64	%p111, %fd30, 0d0000000000000000;
	setp.gt.f64	%p112, %fd28, 0d0000000000000000;
	and.pred  	%p113, %p112, %p111;
	@!%p113 bra 	BB22_63;
	bra.uni 	BB22_62;

BB22_62:
	setp.lt.f64	%p114, %fd16, %fd6;
	selp.f64	%fd394, %fd16, %fd6, %p114;
	mul.f64 	%fd395, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd396, %fd394, %fd395;
	add.f64 	%fd397, %fd28, %fd30;
	mul.f64 	%fd398, %fd397, %fd396;
	sub.f64 	%fd399, %fd33, %fd9;
	mul.f64 	%fd400, %fd399, %fd398;
	ld.const.f64 	%fd401, [dc_dx];
	div.rn.f64 	%fd402, %fd400, %fd401;
	add.f64 	%fd565, %fd565, %fd402;

BB22_63:
	sub.f64 	%fd566, %fd564, %fd46;
	mul.f64 	%fd403, %fd46, %fd643;
	sub.f64 	%fd567, %fd565, %fd403;
	setp.leu.f64	%p115, %fd30, 0d0000000000000000;
	@%p115 bra 	BB22_65;

	ld.const.f64 	%fd404, [dc_dx];
	mul.f64 	%fd405, %fd6, %fd404;
	mul.f64 	%fd406, %fd30, %fd405;
	sub.f64 	%fd407, %fd39, %fd9;
	mul.f64 	%fd408, %fd407, %fd406;
	div.rn.f64 	%fd409, %fd408, %fd25;
	add.f64 	%fd567, %fd567, %fd409;

BB22_65:
	setp.eq.s32	%p116, %r13, 255;
	@%p116 bra 	BB22_68;

	setp.gt.f64	%p117, %fd30, 0d0000000000000000;
	mul.f64 	%fd410, %fd43, 0d3FE0000000000000;
	sub.f64 	%fd566, %fd566, %fd410;
	mul.f64 	%fd411, %fd410, %fd645;
	sub.f64 	%fd567, %fd567, %fd411;
	setp.gt.f64	%p118, %fd32, 0d0000000000000000;
	and.pred  	%p119, %p118, %p117;
	@!%p119 bra 	BB22_68;
	bra.uni 	BB22_67;

BB22_67:
	setp.lt.f64	%p120, %fd18, %fd6;
	selp.f64	%fd412, %fd18, %fd6, %p120;
	mul.f64 	%fd413, %fd25, 0d3FD0000000000000;
	mul.f64 	%fd414, %fd412, %fd413;
	add.f64 	%fd415, %fd30, %fd32;
	mul.f64 	%fd416, %fd415, %fd414;
	sub.f64 	%fd417, %fd44, %fd9;
	mul.f64 	%fd418, %fd417, %fd416;
	ld.const.f64 	%fd419, [dc_dx];
	div.rn.f64 	%fd420, %fd418, %fd419;
	add.f64 	%fd567, %fd567, %fd420;

BB22_68:
	add.f64 	%fd421, %fd5, %fd6;
	mul.f64 	%fd151, %fd421, 0d3FE0000000000000;
	mul.f64 	%fd422, %fd6, %fd6;
	fma.rn.f64 	%fd423, %fd5, %fd5, %fd422;
	mul.f64 	%fd424, %fd423, 0d3FE0000000000000;
	div.rn.f64 	%fd152, %fd424, %fd151;
	add.f64 	%fd425, %fd35, %fd36;
	add.f64 	%fd426, %fd40, %fd41;
	mul.f64 	%fd427, %fd6, %fd426;
	fma.rn.f64 	%fd153, %fd5, %fd425, %fd427;
	ld.const.u32 	%r29, [dc_switches];
	and.b32  	%r81, %r29, 512;
	setp.eq.s32	%p121, %r81, 0;
	@%p121 bra 	BB22_70;

	ld.const.u64 	%rd114, [dc_mnv];
	cvta.to.global.u64 	%rd115, %rd114;
	add.s64 	%rd117, %rd115, %rd54;
	ld.global.f64 	%fd593, [%rd117];
	bra.uni 	BB22_125;

BB22_70:
	ld.const.u64 	%rd118, [dc_mat];
	cvta.to.global.u64 	%rd119, %rd118;
	shl.b64 	%rd120, %rd5, 2;
	add.s64 	%rd121, %rd119, %rd120;
	ld.global.u32 	%r82, [%rd121];
	bfe.u32 	%r30, %r82, 8, 8;
	setp.eq.s32	%p122, %r30, 0;
	mov.f64 	%fd594, 0d0000000000000000;
	@%p122 bra 	BB22_124;

	ld.const.u64 	%rd122, [dc_materialTypes];
	cvta.to.global.u64 	%rd123, %rd122;
	add.s32 	%r84, %r30, -1;
	mul.wide.u32 	%rd124, %r84, 176;
	add.s64 	%rd13, %rd123, %rd124;
	add.u64 	%rd125, %SP, 0;
	cvta.to.local.u64 	%rd12, %rd125;
	mov.u32 	%r148, 0;

BB22_72:
	mul.wide.s32 	%rd126, %r148, 8;
	add.s64 	%rd127, %rd13, %rd126;
	ld.global.u64 	%rd128, [%rd127];
	add.s64 	%rd129, %rd12, %rd126;
	st.local.u64 	[%rd129], %rd128;
	add.s32 	%r148, %r148, 1;
	setp.lt.u32	%p123, %r148, 22;
	@%p123 bra 	BB22_72;

	ld.local.f64 	%fd155, [%rd12+16];
	setp.gt.f64	%p124, %fd155, 0d0000000000000000;
	@%p124 bra 	BB22_99;
	bra.uni 	BB22_74;

BB22_99:
	fma.rn.f64 	%fd437, %fd26, %fd26, 0d0000000000000000;
	sqrt.rn.f64 	%fd438, %fd437;
	setp.gt.f64	%p141, %fd438, 0d3EB0C6F7A0B5ED8D;
	selp.f64	%fd439, %fd438, 0d3EB0C6F7A0B5ED8D, %p141;
	ld.const.u32 	%r85, [dc_unitsOption];
	setp.eq.s32	%p142, %r85, 1;
	selp.f64	%fd440, 0d3EB3DD5DA733223F, 0d3E7D87247702C0D0, %p142;
	mul.f64 	%fd441, %fd152, %fd439;
	sqrt.rn.f64 	%fd442, %fd441;
	div.rn.f64 	%fd443, %fd440, %fd442;
	div.rn.f64 	%fd444, %fd155, 0d403E000000000000;
	add.f64 	%fd182, %fd444, %fd443;
	ld.local.f64 	%fd183, [%rd12+24];
	mov.f64 	%fd445, 0d3FC5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd445;
	}
	bfe.u32 	%r86, %r33, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd187, 4595172819793696085;
	shl.b64 	%rd17, %rd187, %r87;
	setp.eq.s64	%p143, %rd17, -9223372036854775808;
	abs.f64 	%fd184, %fd152;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd184;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd445;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd582, [retval0+0];
	
	//{
	}// Callseq End 4
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd152;
	}
	setp.lt.s32	%p144, %r34, 0;
	and.pred  	%p3, %p144, %p143;
	@!%p3 bra 	BB22_101;
	bra.uni 	BB22_100;

BB22_100:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd582;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd582;
	}
	mov.b64 	%fd582, {%r90, %r89};

BB22_101:
	mov.f64 	%fd581, %fd582;
	setp.eq.f64	%p145, %fd152, 0d0000000000000000;
	@%p145 bra 	BB22_104;
	bra.uni 	BB22_102;

BB22_104:
	selp.b32	%r91, %r34, 0, %p143;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p149, %r33, 0;
	selp.b32	%r93, %r92, %r91, %p149;
	mov.u32 	%r94, 0;
	mov.b64 	%fd581, {%r94, %r93};
	bra.uni 	BB22_105;

BB22_74:
	ld.local.f64 	%fd594, [%rd12+8];
	setp.geu.f64	%p125, %fd594, 0d0000000000000000;
	@%p125 bra 	BB22_124;

	ld.local.f64 	%fd574, [%rd12+48];
	setp.lt.f64	%p126, %fd152, %fd574;
	@%p126 bra 	BB22_98;
	bra.uni 	BB22_76;

BB22_98:
	ld.local.f64 	%fd594, [%rd12+112];
	bra.uni 	BB22_124;

BB22_102:
	setp.gt.s32	%p146, %r34, -1;
	@%p146 bra 	BB22_105;

	cvt.rzi.f64.f64	%fd447, %fd445;
	setp.neu.f64	%p147, %fd447, 0d3FC5555555555555;
	selp.f64	%fd581, 0dFFF8000000000000, %fd581, %p147;

BB22_105:
	mov.f64 	%fd190, %fd581;
	add.f64 	%fd191, %fd152, 0d3FC5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd191;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p150, %r96, 2146435072;
	mov.f64 	%fd580, %fd190;
	@%p150 bra 	BB22_112;

	setp.gtu.f64	%p151, %fd184, 0d7FF0000000000000;
	mov.f64 	%fd580, %fd191;
	@%p151 bra 	BB22_112;

	abs.f64 	%fd192, %fd445;
	setp.gtu.f64	%p152, %fd192, 0d7FF0000000000000;
	mov.f64 	%fd579, %fd191;
	mov.f64 	%fd580, %fd579;
	@%p152 bra 	BB22_112;

	setp.eq.f64	%p153, %fd192, 0d7FF0000000000000;
	@%p153 bra 	BB22_111;
	bra.uni 	BB22_109;

BB22_111:
	setp.gt.f64	%p155, %fd184, 0d3FF0000000000000;
	selp.b32	%r103, 2146435072, 0, %p155;
	xor.b32  	%r104, %r103, 2146435072;
	setp.lt.s32	%p156, %r33, 0;
	selp.b32	%r105, %r104, %r103, %p156;
	setp.eq.f64	%p157, %fd152, 0dBFF0000000000000;
	selp.b32	%r106, 1072693248, %r105, %p157;
	mov.u32 	%r107, 0;
	mov.b64 	%fd580, {%r107, %r106};
	bra.uni 	BB22_112;

BB22_76:
	ld.local.f64 	%fd158, [%rd12+56];
	setp.lt.f64	%p127, %fd152, %fd158;
	mov.u64 	%rd220, 1;
	mov.u64 	%rd219, 0;
	mov.f64 	%fd575, %fd158;
	@%p127 bra 	BB22_97;

	setp.leu.f64	%p128, %fd574, 0d0000000000000000;
	mov.f64 	%fd600, %fd594;
	@%p128 bra 	BB22_79;

	ld.local.f64 	%fd600, [%rd12+112];

BB22_79:
	mov.f64 	%fd599, %fd600;
	ld.local.f64 	%fd161, [%rd12+64];
	setp.lt.f64	%p129, %fd152, %fd161;
	mov.u64 	%rd220, 2;
	mov.u64 	%rd219, 1;
	mov.f64 	%fd574, %fd158;
	mov.f64 	%fd575, %fd161;
	@%p129 bra 	BB22_97;

	setp.leu.f64	%p130, %fd158, 0d0000000000000000;
	@%p130 bra 	BB22_82;

	ld.local.f64 	%fd599, [%rd12+120];

BB22_82:
	mov.f64 	%fd598, %fd599;
	ld.local.f64 	%fd164, [%rd12+72];
	setp.lt.f64	%p131, %fd152, %fd164;
	mov.u64 	%rd220, 3;
	mov.u64 	%rd219, 2;
	mov.f64 	%fd574, %fd161;
	mov.f64 	%fd575, %fd164;
	@%p131 bra 	BB22_97;

	setp.leu.f64	%p132, %fd161, 0d0000000000000000;
	@%p132 bra 	BB22_85;

	ld.local.f64 	%fd598, [%rd12+128];

BB22_85:
	mov.f64 	%fd597, %fd598;
	ld.local.f64 	%fd167, [%rd12+80];
	setp.lt.f64	%p133, %fd152, %fd167;
	mov.u64 	%rd220, 4;
	mov.u64 	%rd219, 3;
	mov.f64 	%fd574, %fd164;
	mov.f64 	%fd575, %fd167;
	@%p133 bra 	BB22_97;

	setp.leu.f64	%p134, %fd164, 0d0000000000000000;
	@%p134 bra 	BB22_88;

	ld.local.f64 	%fd597, [%rd12+136];

BB22_88:
	mov.f64 	%fd596, %fd597;
	ld.local.f64 	%fd170, [%rd12+88];
	setp.lt.f64	%p135, %fd152, %fd170;
	mov.u64 	%rd220, 5;
	mov.u64 	%rd219, 4;
	mov.f64 	%fd574, %fd167;
	mov.f64 	%fd575, %fd170;
	@%p135 bra 	BB22_97;

	setp.leu.f64	%p136, %fd167, 0d0000000000000000;
	@%p136 bra 	BB22_91;

	ld.local.f64 	%fd596, [%rd12+144];

BB22_91:
	mov.f64 	%fd595, %fd596;
	ld.local.f64 	%fd173, [%rd12+96];
	setp.lt.f64	%p137, %fd152, %fd173;
	mov.u64 	%rd220, 6;
	mov.u64 	%rd219, 5;
	mov.f64 	%fd574, %fd170;
	mov.f64 	%fd575, %fd173;
	@%p137 bra 	BB22_97;

	setp.leu.f64	%p138, %fd170, 0d0000000000000000;
	@%p138 bra 	BB22_94;

	ld.local.f64 	%fd595, [%rd12+152];

BB22_94:
	mov.f64 	%fd594, %fd595;
	ld.local.f64 	%fd176, [%rd12+104];
	setp.lt.f64	%p139, %fd152, %fd176;
	mov.u64 	%rd220, 7;
	mov.u64 	%rd219, 6;
	mov.f64 	%fd574, %fd173;
	mov.f64 	%fd575, %fd176;
	@%p139 bra 	BB22_97;
	bra.uni 	BB22_95;

BB22_97:
	sub.f64 	%fd429, %fd575, %fd574;
	sub.f64 	%fd430, %fd152, %fd574;
	div.rn.f64 	%fd431, %fd430, %fd429;
	mov.f64 	%fd432, 0d3FF0000000000000;
	sub.f64 	%fd433, %fd432, %fd431;
	shl.b64 	%rd178, %rd219, 3;
	add.s64 	%rd179, %rd12, 112;
	add.s64 	%rd180, %rd179, %rd178;
	ld.local.f64 	%fd434, [%rd180];
	shl.b64 	%rd181, %rd220, 3;
	add.s64 	%rd182, %rd179, %rd181;
	ld.local.f64 	%fd435, [%rd182];
	mul.f64 	%fd436, %fd431, %fd435;
	fma.rn.f64 	%fd594, %fd433, %fd434, %fd436;
	bra.uni 	BB22_124;

BB22_109:
	setp.neu.f64	%p154, %fd184, 0d7FF0000000000000;
	mov.f64 	%fd580, %fd190;
	@%p154 bra 	BB22_112;

	shr.s32 	%r97, %r33, 31;
	and.b32  	%r98, %r97, -2146435072;
	add.s32 	%r99, %r98, 2146435072;
	or.b32  	%r100, %r99, -2147483648;
	selp.b32	%r101, %r100, %r99, %p3;
	mov.u32 	%r102, 0;
	mov.b64 	%fd580, {%r102, %r101};

BB22_112:
	setp.eq.f64	%p158, %fd152, 0d3FF0000000000000;
	selp.f64	%fd449, 0d3FF0000000000000, %fd580, %p158;
	mul.f64 	%fd196, %fd183, %fd449;
	sqrt.rn.f64 	%fd197, %fd24;
	div.rn.f64 	%fd198, %fd152, %fd182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd198;
	}
	setp.gt.f64	%p159, %fd198, 0d0000000000000000;
	setp.lt.s32	%p160, %r149, 2146435072;
	and.pred  	%p161, %p159, %p160;
	@%p161 bra 	BB22_117;
	bra.uni 	BB22_113;

BB22_117:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd198;
	}
	mov.u32 	%r151, -1023;
	setp.gt.s32	%p165, %r149, 1048575;
	@%p165 bra 	BB22_119;

	mul.f64 	%fd452, %fd198, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd452;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd452;
	}
	mov.u32 	%r151, -1077;

BB22_119:
	shr.u32 	%r110, %r149, 20;
	add.s32 	%r152, %r151, %r110;
	and.b32  	%r111, %r149, -2146435073;
	or.b32  	%r112, %r111, 1072693248;
	mov.b64 	%fd583, {%r150, %r112};
	setp.lt.s32	%p166, %r112, 1073127583;
	@%p166 bra 	BB22_121;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd583;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd583;
	}
	add.s32 	%r115, %r114, -1048576;
	mov.b64 	%fd583, {%r113, %r115};
	add.s32 	%r152, %r152, 1;

BB22_121:
	add.f64 	%fd454, %fd583, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd453,%fd454;
	// inline asm
	neg.f64 	%fd455, %fd454;
	mov.f64 	%fd456, 0d3FF0000000000000;
	fma.rn.f64 	%fd457, %fd455, %fd453, %fd456;
	fma.rn.f64 	%fd458, %fd457, %fd457, %fd457;
	fma.rn.f64 	%fd459, %fd458, %fd453, %fd453;
	add.f64 	%fd460, %fd583, 0dBFF0000000000000;
	mul.f64 	%fd461, %fd460, %fd459;
	fma.rn.f64 	%fd462, %fd460, %fd459, %fd461;
	mul.f64 	%fd463, %fd462, %fd462;
	mov.f64 	%fd464, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd465, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd466, %fd465, %fd463, %fd464;
	mov.f64 	%fd467, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd468, %fd466, %fd463, %fd467;
	mov.f64 	%fd469, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd470, %fd468, %fd463, %fd469;
	mov.f64 	%fd471, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd472, %fd470, %fd463, %fd471;
	mov.f64 	%fd473, 0d3F624924923BE72D;
	fma.rn.f64 	%fd474, %fd472, %fd463, %fd473;
	mov.f64 	%fd475, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd476, %fd474, %fd463, %fd475;
	mov.f64 	%fd477, 0d3FB5555555555554;
	fma.rn.f64 	%fd478, %fd476, %fd463, %fd477;
	sub.f64 	%fd479, %fd460, %fd462;
	add.f64 	%fd480, %fd479, %fd479;
	neg.f64 	%fd481, %fd462;
	fma.rn.f64 	%fd482, %fd481, %fd460, %fd480;
	mul.f64 	%fd483, %fd459, %fd482;
	mul.f64 	%fd484, %fd463, %fd478;
	fma.rn.f64 	%fd485, %fd484, %fd462, %fd483;
	xor.b32  	%r116, %r152, -2147483648;
	mov.u32 	%r117, 1127219200;
	mov.b64 	%fd486, {%r116, %r117};
	mov.u32 	%r118, -2147483648;
	mov.b64 	%fd487, {%r118, %r117};
	sub.f64 	%fd488, %fd486, %fd487;
	mov.f64 	%fd489, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd490, %fd488, %fd489, %fd462;
	neg.f64 	%fd491, %fd488;
	fma.rn.f64 	%fd492, %fd491, %fd489, %fd490;
	sub.f64 	%fd493, %fd492, %fd462;
	sub.f64 	%fd494, %fd485, %fd493;
	mov.f64 	%fd495, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd496, %fd488, %fd495, %fd494;
	add.f64 	%fd584, %fd490, %fd496;
	bra.uni 	BB22_122;

BB22_113:
	abs.f64 	%fd450, %fd198;
	setp.gtu.f64	%p162, %fd450, 0d7FF0000000000000;
	@%p162 bra 	BB22_116;
	bra.uni 	BB22_114;

BB22_116:
	add.f64 	%fd584, %fd198, %fd198;
	bra.uni 	BB22_122;

BB22_114:
	setp.eq.f64	%p163, %fd198, 0d0000000000000000;
	mov.f64 	%fd584, 0dFFF0000000000000;
	@%p163 bra 	BB22_122;

	setp.eq.f64	%p164, %fd198, 0d7FF0000000000000;
	selp.f64	%fd584, %fd198, 0dFFF8000000000000, %p164;

BB22_122:
	add.f64 	%fd497, %fd584, 0dBFF0000000000000;
	mul.f64 	%fd498, %fd197, %fd497;
	div.rn.f64 	%fd206, %fd196, %fd498;
	ld.local.f64 	%fd207, [%rd12+8];
	setp.gt.f64	%p167, %fd206, %fd207;
	mov.f64 	%fd594, %fd206;
	@%p167 bra 	BB22_124;

	mov.f64 	%fd594, %fd207;

BB22_124:
	mov.f64 	%fd593, %fd594;
	ld.const.u64 	%rd190, [dc_mnv];
	cvta.to.global.u64 	%rd191, %rd190;
	add.s64 	%rd193, %rd191, %rd54;
	st.global.f64 	[%rd193], %fd593;

BB22_125:
	ld.const.f64 	%fd500, [dc_nUnitsFactor];
	mul.f64 	%fd210, %fd593, %fd500;
	and.b32  	%r119, %r29, 1024;
	setp.eq.s32	%p168, %r119, 0;
	mov.f64 	%fd601, 0d0000000000000000;
	@%p168 bra 	BB22_127;

	ld.const.u64 	%rd194, [dc_vFormLoss];
	cvta.to.global.u64 	%rd195, %rd194;
	add.s64 	%rd197, %rd195, %rd54;
	ld.global.f64 	%fd601, [%rd197];

BB22_127:
	mul.f64 	%fd501, %fd153, 0d3FD0000000000000;
	div.rn.f64 	%fd213, %fd501, %fd151;
	mul.f64 	%fd502, %fd9, %fd566;
	sub.f64 	%fd503, %fd567, %fd502;
	ld.const.f64 	%fd504, [dc_dx];
	mul.f64 	%fd505, %fd504, %fd25;
	mul.f64 	%fd506, %fd151, %fd505;
	div.rn.f64 	%fd507, %fd503, %fd506;
	add.f64 	%fd603, %fd26, %fd507;
	ld.const.f64 	%fd215, [dc_shearStressH0];
	setp.leu.f64	%p169, %fd152, %fd215;
	@%p169 bra 	BB22_133;

	ld.const.u64 	%rd198, [dc_uniformShearStress];
	cvta.to.global.u64 	%rd199, %rd198;
	ld.global.f64 	%fd602, [%rd199+8];
	and.b32  	%r120, %r29, 64;
	setp.eq.s32	%p170, %r120, 0;
	@%p170 bra 	BB22_130;

	ld.param.f64 	%fd547, [gpu_calcDerivsSpatialV_param_3];
	mov.f64 	%fd508, 0d3FF0000000000000;
	sub.f64 	%fd509, %fd508, %fd547;
	ld.const.u64 	%rd200, [dc_tauV0];
	cvta.to.global.u64 	%rd201, %rd200;
	add.s64 	%rd203, %rd201, %rd54;
	ld.global.f64 	%fd510, [%rd203];
	ld.const.u64 	%rd204, [dc_tauV1];
	cvta.to.global.u64 	%rd205, %rd204;
	add.s64 	%rd206, %rd205, %rd54;
	ld.global.f64 	%fd511, [%rd206];
	mul.f64 	%fd512, %fd511, %fd547;
	fma.rn.f64 	%fd513, %fd509, %fd510, %fd512;
	add.f64 	%fd602, %fd602, %fd513;

BB22_130:
	ld.const.f64 	%fd219, [dc_shearStressH1];
	setp.geu.f64	%p171, %fd152, %fd219;
	@%p171 bra 	BB22_132;

	sub.f64 	%fd514, %fd152, %fd215;
	sub.f64 	%fd515, %fd219, %fd215;
	div.rn.f64 	%fd516, %fd514, %fd515;
	mul.f64 	%fd602, %fd602, %fd516;

BB22_132:
	ld.const.f64 	%fd517, [dc_rho];
	mul.f64 	%fd518, %fd152, %fd517;
	div.rn.f64 	%fd519, %fd602, %fd518;
	add.f64 	%fd603, %fd603, %fd519;

BB22_133:
	setp.gt.f64	%p172, %fd210, 0d0000000000000000;
	@%p172 bra 	BB22_135;
	bra.uni 	BB22_134;

BB22_135:
	mul.f64 	%fd522, %fd210, %fd24;
	mul.f64 	%fd225, %fd210, %fd522;
	mov.f64 	%fd523, 0d3FF5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd523;
	}
	bfe.u32 	%r121, %r45, 20, 11;
	add.s32 	%r122, %r121, -1012;
	mov.u64 	%rd207, 4608683618675807573;
	shl.b64 	%rd18, %rd207, %r122;
	setp.eq.s64	%p173, %rd18, -9223372036854775808;
	abs.f64 	%fd226, %fd152;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd226;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd523;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd610, [retval0+0];
	
	//{
	}// Callseq End 5
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd152;
	}
	setp.lt.s32	%p174, %r46, 0;
	and.pred  	%p4, %p174, %p173;
	@!%p4 bra 	BB22_137;
	bra.uni 	BB22_136;

BB22_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd610;
	}
	xor.b32  	%r124, %r123, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd610;
	}
	mov.b64 	%fd610, {%r125, %r124};

BB22_137:
	mov.f64 	%fd609, %fd610;
	setp.eq.f64	%p175, %fd152, 0d0000000000000000;
	@%p175 bra 	BB22_140;
	bra.uni 	BB22_138;

BB22_140:
	selp.b32	%r126, %r46, 0, %p173;
	or.b32  	%r127, %r126, 2146435072;
	setp.lt.s32	%p179, %r45, 0;
	selp.b32	%r128, %r127, %r126, %p179;
	mov.u32 	%r129, 0;
	mov.b64 	%fd609, {%r129, %r128};
	bra.uni 	BB22_141;

BB22_134:
	mul.f64 	%fd520, %fd601, %fd247;
	add.f64 	%fd521, %fd25, %fd25;
	div.rn.f64 	%fd611, %fd520, %fd521;
	bra.uni 	BB22_149;

BB22_138:
	setp.gt.s32	%p176, %r46, -1;
	@%p176 bra 	BB22_141;

	cvt.rzi.f64.f64	%fd525, %fd523;
	setp.neu.f64	%p177, %fd525, 0d3FF5555555555555;
	selp.f64	%fd609, 0dFFF8000000000000, %fd609, %p177;

BB22_141:
	mov.f64 	%fd232, %fd609;
	add.f64 	%fd233, %fd152, 0d3FF5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd233;
	}
	and.b32  	%r131, %r130, 2146435072;
	setp.ne.s32	%p180, %r131, 2146435072;
	mov.f64 	%fd608, %fd232;
	@%p180 bra 	BB22_148;

	setp.gtu.f64	%p181, %fd226, 0d7FF0000000000000;
	mov.f64 	%fd608, %fd233;
	@%p181 bra 	BB22_148;

	abs.f64 	%fd234, %fd523;
	setp.gtu.f64	%p182, %fd234, 0d7FF0000000000000;
	mov.f64 	%fd607, %fd233;
	mov.f64 	%fd608, %fd607;
	@%p182 bra 	BB22_148;

	setp.eq.f64	%p183, %fd234, 0d7FF0000000000000;
	@%p183 bra 	BB22_147;
	bra.uni 	BB22_145;

BB22_147:
	setp.gt.f64	%p185, %fd226, 0d3FF0000000000000;
	selp.b32	%r138, 2146435072, 0, %p185;
	xor.b32  	%r139, %r138, 2146435072;
	setp.lt.s32	%p186, %r45, 0;
	selp.b32	%r140, %r139, %r138, %p186;
	setp.eq.f64	%p187, %fd152, 0dBFF0000000000000;
	selp.b32	%r141, 1072693248, %r140, %p187;
	mov.u32 	%r142, 0;
	mov.b64 	%fd608, {%r142, %r141};
	bra.uni 	BB22_148;

BB22_145:
	setp.neu.f64	%p184, %fd226, 0d7FF0000000000000;
	mov.f64 	%fd608, %fd232;
	@%p184 bra 	BB22_148;

	shr.s32 	%r132, %r45, 31;
	and.b32  	%r133, %r132, -2146435072;
	add.s32 	%r134, %r133, 2146435072;
	or.b32  	%r135, %r134, -2147483648;
	selp.b32	%r136, %r135, %r134, %p4;
	mov.u32 	%r137, 0;
	mov.b64 	%fd608, {%r137, %r136};

BB22_148:
	setp.eq.f64	%p188, %fd152, 0d3FF0000000000000;
	selp.f64	%fd527, 0d3FF0000000000000, %fd608, %p188;
	div.rn.f64 	%fd528, %fd225, %fd527;
	add.f64 	%fd529, %fd25, %fd25;
	div.rn.f64 	%fd530, %fd601, %fd529;
	add.f64 	%fd531, %fd528, %fd530;
	mul.f64 	%fd611, %fd531, %fd247;

BB22_149:
	mov.f64 	%fd532, 0d412E848000000000;
	sub.f64 	%fd533, %fd532, %fd9;
	abs.f64 	%fd534, %fd533;
	setp.leu.f64	%p189, %fd534, 0d3EB0C6F7A0B5ED8D;
	mov.f64 	%fd641, %fd9;
	@%p189 bra 	BB22_152;

	fma.rn.f64 	%fd240, %fd603, %fd247, %fd9;
	mul.f64 	%fd241, %fd213, %fd213;
	mov.f64 	%fd535, 0d3FF0000000000000;
	mov.f64 	%fd612, %fd535;
	mov.f64 	%fd642, %fd9;

BB22_151:
	mov.f64 	%fd243, %fd642;
	mov.f64 	%fd242, %fd612;
	fma.rn.f64 	%fd536, %fd243, %fd243, %fd241;
	sqrt.rn.f64 	%fd537, %fd536;
	fma.rn.f64 	%fd538, %fd611, %fd537, 0d3FF0000000000000;
	div.rn.f64 	%fd539, %fd240, %fd538;
	sub.f64 	%fd541, %fd535, %fd242;
	mul.f64 	%fd542, %fd242, %fd539;
	fma.rn.f64 	%fd642, %fd243, %fd541, %fd542;
	add.f64 	%fd245, %fd242, 0dBFA999999999999A;
	sub.f64 	%fd543, %fd243, %fd642;
	abs.f64 	%fd544, %fd543;
	setp.gt.f64	%p190, %fd544, 0d3EB0C6F7A0B5ED8D;
	mov.f64 	%fd612, %fd245;
	mov.f64 	%fd640, %fd642;
	mov.f64 	%fd641, %fd640;
	@%p190 bra 	BB22_151;

BB22_152:
	mov.f64 	%fd246, %fd641;
	ld.param.u64 	%rd212, [gpu_calcDerivsSpatialV_param_7];
	cvt.u64.u32	%rd211, %r4;
	shl.b64 	%rd210, %rd211, 3;
	cvta.to.global.u64 	%rd209, %rd212;
	add.s64 	%rd208, %rd209, %rd210;
	sub.f64 	%fd545, %fd246, %fd9;
	div.rn.f64 	%fd546, %fd545, %fd247;
	st.global.f64 	[%rd208], %fd546;

BB22_153:
	ret;

BB22_95:
	setp.leu.f64	%p140, %fd173, 0d0000000000000000;
	@%p140 bra 	BB22_124;

	ld.local.f64 	%fd594, [%rd12+160];
	bra.uni 	BB22_124;
}

	// .globl	gpu_extractHxSources
.visible .entry gpu_extractHxSources(
	.param .u32 gpu_extractHxSources_param_0,
	.param .u32 gpu_extractHxSources_param_1,
	.param .u32 gpu_extractHxSources_param_2,
	.param .u64 gpu_extractHxSources_param_3,
	.param .u64 gpu_extractHxSources_param_4,
	.param .u64 gpu_extractHxSources_param_5,
	.param .u64 gpu_extractHxSources_param_6,
	.param .u64 gpu_extractHxSources_param_7,
	.param .u64 gpu_extractHxSources_param_8
)
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<24>;
	.reg .f64 	%fd<11>;
	.reg .b64 	%rd<29>;


	ld.param.u32 	%r10, [gpu_extractHxSources_param_1];
	ld.param.u32 	%r11, [gpu_extractHxSources_param_2];
	ld.param.u64 	%rd6, [gpu_extractHxSources_param_6];
	ld.param.u64 	%rd7, [gpu_extractHxSources_param_7];
	ld.param.u64 	%rd8, [gpu_extractHxSources_param_8];
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ntid.y;
	mov.u32 	%r14, %tid.y;
	mad.lo.s32 	%r23, %r13, %r12, %r14;
	setp.ge.s32	%p1, %r23, %r11;
	@%p1 bra 	BB23_7;

	ld.const.u32 	%r15, [dc_ny];
	add.s32 	%r2, %r15, -2;
	ld.const.u32 	%r16, [dc_nx];
	add.s32 	%r3, %r16, -2;
	ld.const.u32 	%r4, [dc_nyPadded];
	ld.const.u64 	%rd9, [dc_a];
	cvta.to.global.u64 	%rd1, %rd9;
	ld.const.u64 	%rd10, [dc_phi2];
	cvta.to.global.u64 	%rd2, %rd10;
	ld.const.u64 	%rd11, [dc_phi4];
	cvta.to.global.u64 	%rd3, %rd11;
	cvta.to.global.u64 	%rd12, %rd6;
	cvta.to.global.u64 	%rd15, %rd7;
	cvta.to.global.u64 	%rd17, %rd8;

BB23_2:
	mul.wide.s32 	%rd13, %r23, 4;
	add.s64 	%rd14, %rd12, %rd13;
	add.s64 	%rd16, %rd15, %rd13;
	ld.global.u32 	%r17, [%rd16];
	sub.s32 	%r6, %r17, %r10;
	ld.global.u32 	%r7, [%rd14];
	setp.gt.s32	%p2, %r7, 1;
	setp.lt.s32	%p3, %r7, %r2;
	and.pred  	%p4, %p2, %p3;
	setp.gt.s32	%p5, %r6, 1;
	and.pred  	%p6, %p4, %p5;
	setp.lt.s32	%p7, %r6, %r3;
	and.pred  	%p8, %p6, %p7;
	mul.wide.s32 	%rd18, %r23, 8;
	add.s64 	%rd4, %rd17, %rd18;
	mov.f64 	%fd10, 0d0000000000000000;
	@!%p8 bra 	BB23_5;
	bra.uni 	BB23_3;

BB23_3:
	mad.lo.s32 	%r8, %r4, %r6, %r7;
	cvt.u64.u32	%rd5, %r8;
	mul.wide.u32 	%rd19, %r8, 4;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.u8 	%r18, [%rd20];
	setp.eq.s32	%p9, %r18, 255;
	@%p9 bra 	BB23_6;

	sub.s32 	%r19, %r8, %r4;
	mul.wide.u32 	%rd21, %r19, 8;
	add.s64 	%rd22, %rd2, %rd21;
	add.s32 	%r20, %r8, -1;
	mul.wide.u32 	%rd23, %r20, 8;
	add.s64 	%rd24, %rd3, %rd23;
	shl.b64 	%rd25, %rd5, 3;
	add.s64 	%rd26, %rd2, %rd25;
	ld.global.f64 	%fd4, [%rd26];
	ld.global.f64 	%fd5, [%rd22];
	sub.f64 	%fd6, %fd5, %fd4;
	ld.global.f64 	%fd7, [%rd24];
	add.f64 	%fd8, %fd6, %fd7;
	add.s64 	%rd27, %rd3, %rd25;
	ld.global.f64 	%fd9, [%rd27];
	sub.f64 	%fd10, %fd8, %fd9;

BB23_5:
	st.global.f64 	[%rd4], %fd10;
	mov.u32 	%r22, %ntid.x;
	mad.lo.s32 	%r23, %r22, %r13, %r23;
	setp.lt.s32	%p10, %r23, %r11;
	@%p10 bra 	BB23_2;
	bra.uni 	BB23_7;

BB23_6:
	mov.u64 	%rd28, 0;
	st.global.u64 	[%rd4], %rd28;

BB23_7:
	ret;
}

	// .globl	gpu_setHxLevels
.visible .entry gpu_setHxLevels(
	.param .u32 gpu_setHxLevels_param_0,
	.param .u32 gpu_setHxLevels_param_1,
	.param .u32 gpu_setHxLevels_param_2,
	.param .u64 gpu_setHxLevels_param_3,
	.param .u64 gpu_setHxLevels_param_4,
	.param .u64 gpu_setHxLevels_param_5,
	.param .u64 gpu_setHxLevels_param_6
)
{
	.reg .pred 	%p<28>;
	.reg .b32 	%r<39>;
	.reg .f64 	%fd<71>;
	.reg .b64 	%rd<53>;


	ld.param.u32 	%r14, [gpu_setHxLevels_param_2];
	ld.param.u64 	%rd8, [gpu_setHxLevels_param_3];
	ld.param.u64 	%rd9, [gpu_setHxLevels_param_4];
	ld.param.u64 	%rd10, [gpu_setHxLevels_param_5];
	mov.u32 	%r15, %tid.x;
	mov.u32 	%r16, %ntid.y;
	mov.u32 	%r17, %tid.y;
	mad.lo.s32 	%r38, %r16, %r15, %r17;
	setp.ge.s32	%p1, %r38, %r14;
	@%p1 bra 	BB24_20;

	ld.const.u32 	%r4, [dc_nyPadded];
	ld.const.u64 	%rd12, [dc_zc];
	cvta.to.global.u64 	%rd1, %rd12;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.const.u64 	%rd13, [dc_fxHx];
	cvta.to.global.u64 	%rd2, %rd13;
	ld.const.u64 	%rd14, [dc_fyHx];
	cvta.to.global.u64 	%rd3, %rd14;
	ld.const.u64 	%rd15, [dc_a];
	cvta.to.global.u64 	%rd4, %rd15;
	cvta.to.global.u64 	%rd16, %rd8;
	cvta.to.global.u64 	%rd19, %rd9;
	cvta.to.global.u64 	%rd23, %rd10;
	bra.uni 	BB24_2;

BB24_17:
	sub.f64 	%fd65, %fd4, %fd3;
	st.global.f64 	[%rd6], %fd65;
	bra.uni 	BB24_19;

BB24_2:
	ld.const.u32 	%r37, [dc_nx];
	add.s32 	%r36, %r37, -2;
	ld.const.u32 	%r35, [dc_ny];
	add.s32 	%r34, %r35, -2;
	ld.param.u32 	%r33, [gpu_setHxLevels_param_1];
	cvt.s64.s32	%rd5, %r38;
	mul.wide.s32 	%rd17, %r38, 4;
	add.s64 	%rd18, %rd16, %rd17;
	add.s64 	%rd20, %rd19, %rd17;
	ld.global.u32 	%r20, [%rd20];
	sub.s32 	%r6, %r20, %r33;
	ld.global.u32 	%r7, [%rd18];
	setp.gt.s32	%p2, %r7, 1;
	setp.lt.s32	%p3, %r7, %r34;
	and.pred  	%p4, %p2, %p3;
	setp.gt.s32	%p5, %r6, 1;
	and.pred  	%p6, %p4, %p5;
	setp.lt.s32	%p7, %r6, %r36;
	and.pred  	%p8, %p6, %p7;
	@!%p8 bra 	BB24_19;
	bra.uni 	BB24_3;

BB24_3:
	ld.param.u64 	%rd52, [gpu_setHxLevels_param_6];
	mad.lo.s32 	%r8, %r4, %r6, %r7;
	mul.wide.s32 	%rd21, %r8, 8;
	add.s64 	%rd22, %rd1, %rd21;
	shl.b64 	%rd24, %rd5, 3;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.f64 	%fd3, [%rd22];
	add.f64 	%fd34, %fd3, %fd1;
	ld.global.f64 	%fd4, [%rd25];
	setp.gt.f64	%p9, %fd4, %fd34;
	cvta.to.global.u64 	%rd26, %rd52;
	add.s64 	%rd6, %rd26, %rd21;
	@%p9 bra 	BB24_5;
	bra.uni 	BB24_4;

BB24_5:
	add.s64 	%rd28, %rd2, %rd24;
	add.s64 	%rd29, %rd3, %rd24;
	ld.global.f64 	%fd5, [%rd29];
	ld.global.f64 	%fd6, [%rd28];
	abs.f64 	%fd7, %fd6;
	setp.leu.f64	%p10, %fd7, 0d3EB0C6F7A0B5ED8D;
	@%p10 bra 	BB24_7;

	abs.f64 	%fd8, %fd5;
	setp.gt.f64	%p11, %fd8, 0d3EB0C6F7A0B5ED8D;
	@%p11 bra 	BB24_8;
	bra.uni 	BB24_7;

BB24_8:
	sub.s32 	%r21, %r8, %r4;
	cvt.u64.u32	%rd7, %r21;
	mul.wide.u32 	%rd30, %r21, 4;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u8 	%r22, [%rd31];
	add.s32 	%r23, %r4, %r8;
	mul.wide.u32 	%rd32, %r23, 4;
	add.s64 	%rd33, %rd4, %rd32;
	ld.global.u32 	%r9, [%rd33];
	add.s32 	%r24, %r8, -1;
	mul.wide.u32 	%rd34, %r24, 4;
	add.s64 	%rd35, %rd4, %rd34;
	ld.global.u32 	%r10, [%rd35];
	add.s32 	%r25, %r8, 1;
	mul.wide.u32 	%rd36, %r25, 4;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u32 	%r11, [%rd37];
	mul.wide.u32 	%rd38, %r23, 8;
	add.s64 	%rd39, %rd1, %rd38;
	ld.global.f64 	%fd9, [%rd39];
	mul.wide.u32 	%rd40, %r24, 8;
	add.s64 	%rd41, %rd1, %rd40;
	ld.global.f64 	%fd10, [%rd41];
	mul.wide.u32 	%rd42, %r25, 8;
	add.s64 	%rd43, %rd1, %rd42;
	ld.global.f64 	%fd11, [%rd43];
	mul.wide.u32 	%rd45, %r21, 8;
	add.s64 	%rd46, %rd26, %rd45;
	add.s64 	%rd47, %rd26, %rd38;
	ld.global.f64 	%fd12, [%rd47];
	add.s64 	%rd48, %rd26, %rd40;
	ld.global.f64 	%fd13, [%rd48];
	add.s64 	%rd49, %rd26, %rd42;
	ld.global.f64 	%fd14, [%rd49];
	rcp.rn.f64 	%fd38, %fd7;
	setp.gt.f64	%p12, %fd7, 0d3F50624DD2F1A9FC;
	selp.f64	%fd15, %fd38, 0d408F400000000000, %p12;
	rcp.rn.f64 	%fd39, %fd8;
	setp.gt.f64	%p13, %fd8, 0d3F50624DD2F1A9FC;
	selp.f64	%fd16, %fd39, 0d408F400000000000, %p13;
	setp.ne.s32	%p14, %r22, 255;
	ld.global.f64 	%fd17, [%rd46];
	setp.gt.f64	%p15, %fd17, %fd1;
	and.pred  	%p16, %p14, %p15;
	mov.f64 	%fd70, 0d0000000000000000;
	mov.f64 	%fd69, %fd70;
	@!%p16 bra 	BB24_10;
	bra.uni 	BB24_9;

BB24_9:
	shl.b64 	%rd50, %rd7, 3;
	add.s64 	%rd51, %rd1, %rd50;
	ld.global.f64 	%fd40, [%rd51];
	add.f64 	%fd41, %fd17, %fd40;
	fma.rn.f64 	%fd42, %fd6, %fd41, %fd4;
	mul.f64 	%fd43, %fd15, %fd42;
	add.f64 	%fd44, %fd6, 0d3FF0000000000000;
	div.rn.f64 	%fd45, %fd43, %fd44;
	add.f64 	%fd69, %fd45, 0d0000000000000000;
	add.f64 	%fd70, %fd15, 0d0000000000000000;

BB24_10:
	and.b32  	%r26, %r9, 255;
	setp.gt.f64	%p17, %fd12, %fd1;
	setp.ne.s32	%p18, %r26, 255;
	and.pred  	%p19, %p18, %p17;
	@!%p19 bra 	BB24_12;
	bra.uni 	BB24_11;

BB24_11:
	add.f64 	%fd46, %fd9, %fd12;
	mul.f64 	%fd47, %fd6, %fd46;
	sub.f64 	%fd48, %fd4, %fd47;
	mul.f64 	%fd49, %fd48, %fd15;
	mov.f64 	%fd50, 0d3FF0000000000000;
	sub.f64 	%fd51, %fd50, %fd6;
	div.rn.f64 	%fd52, %fd49, %fd51;
	add.f64 	%fd69, %fd69, %fd52;
	add.f64 	%fd70, %fd15, %fd70;

BB24_12:
	and.b32  	%r27, %r10, 255;
	setp.gt.f64	%p20, %fd13, %fd1;
	setp.ne.s32	%p21, %r27, 255;
	and.pred  	%p22, %p21, %p20;
	@!%p22 bra 	BB24_14;
	bra.uni 	BB24_13;

BB24_13:
	add.f64 	%fd53, %fd10, %fd13;
	fma.rn.f64 	%fd54, %fd5, %fd53, %fd4;
	mul.f64 	%fd55, %fd54, %fd16;
	add.f64 	%fd56, %fd5, 0d3FF0000000000000;
	div.rn.f64 	%fd57, %fd55, %fd56;
	add.f64 	%fd69, %fd69, %fd57;
	add.f64 	%fd70, %fd16, %fd70;

BB24_14:
	and.b32  	%r28, %r11, 255;
	setp.gt.f64	%p23, %fd14, %fd1;
	setp.ne.s32	%p24, %r28, 255;
	and.pred  	%p25, %p24, %p23;
	@!%p25 bra 	BB24_16;
	bra.uni 	BB24_15;

BB24_15:
	add.f64 	%fd58, %fd11, %fd14;
	mul.f64 	%fd59, %fd5, %fd58;
	sub.f64 	%fd60, %fd4, %fd59;
	mul.f64 	%fd61, %fd16, %fd60;
	mov.f64 	%fd62, 0d3FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd5;
	div.rn.f64 	%fd64, %fd61, %fd63;
	add.f64 	%fd69, %fd69, %fd64;
	add.f64 	%fd70, %fd16, %fd70;

BB24_16:
	setp.gt.f64	%p26, %fd70, 0d0000000000000000;
	@%p26 bra 	BB24_18;
	bra.uni 	BB24_17;

BB24_18:
	div.rn.f64 	%fd66, %fd69, %fd70;
	sub.f64 	%fd67, %fd66, %fd3;
	st.global.f64 	[%rd6], %fd67;
	bra.uni 	BB24_19;

BB24_4:
	ld.const.f64 	%fd68, [dc_dryDepthThreshold];
	st.global.f64 	[%rd6], %fd68;
	bra.uni 	BB24_19;

BB24_7:
	sub.f64 	%fd35, %fd4, %fd3;
	st.global.f64 	[%rd6], %fd35;

BB24_19:
	ld.param.u32 	%r32, [gpu_setHxLevels_param_2];
	mov.u32 	%r31, %ntid.y;
	mov.u32 	%r29, %ntid.x;
	mad.lo.s32 	%r38, %r29, %r31, %r38;
	setp.lt.s32	%p27, %r38, %r32;
	@%p27 bra 	BB24_2;

BB24_20:
	ret;
}

	// .globl	gpu_calcVarFC
.visible .entry gpu_calcVarFC(
	.param .u32 gpu_calcVarFC_param_0,
	.param .u32 gpu_calcVarFC_param_1,
	.param .u32 gpu_calcVarFC_param_2,
	.param .u64 gpu_calcVarFC_param_3,
	.param .u64 gpu_calcVarFC_param_4,
	.param .u64 gpu_calcVarFC_param_5
)
{
	.reg .pred 	%p<22>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<57>;
	.reg .b64 	%rd<46>;


	ld.param.u32 	%r11, [gpu_calcVarFC_param_2];
	ld.param.u64 	%rd13, [gpu_calcVarFC_param_3];
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ntid.y;
	mov.u32 	%r14, %tid.y;
	mad.lo.s32 	%r31, %r13, %r12, %r14;
	setp.ge.s32	%p1, %r31, %r11;
	@%p1 bra 	BB25_15;

	ld.const.u64 	%rd14, [dc_varFC_n];
	cvta.to.global.u64 	%rd1, %rd14;
	ld.const.u64 	%rd15, [dc_varFC_m];
	cvta.to.global.u64 	%rd2, %rd15;
	ld.const.u64 	%rd16, [dc_varFC_type];
	cvta.to.global.u64 	%rd3, %rd16;
	ld.const.u64 	%rd17, [dc_varFC_h];
	cvta.to.global.u64 	%rd4, %rd17;
	ld.const.u64 	%rd18, [dc_varFC_ad];
	cvta.to.global.u64 	%rd5, %rd18;
	ld.const.u64 	%rd19, [dc_varFC_fl];
	cvta.to.global.u64 	%rd6, %rd19;
	ld.const.u64 	%rd20, [dc_vFlowWidth];
	cvta.to.global.u64 	%rd7, %rd20;
	ld.const.u64 	%rd21, [dc_vFormLoss];
	cvta.to.global.u64 	%rd8, %rd21;
	ld.const.u64 	%rd22, [dc_uFormLoss];
	cvta.to.global.u64 	%rd9, %rd22;
	ld.const.u64 	%rd10, [dc_uFlowWidth];
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd39, %rd10;

BB25_2:
	ld.const.u32 	%r29, [dc_ny];
	add.s32 	%r28, %r29, -2;
	ld.const.u32 	%r27, [dc_nx];
	add.s32 	%r26, %r27, -2;
	ld.param.u32 	%r25, [gpu_calcVarFC_param_1];
	cvt.s64.s32	%rd11, %r31;
	mul.wide.s32 	%rd23, %r31, 4;
	add.s64 	%rd24, %rd1, %rd23;
	add.s64 	%rd25, %rd2, %rd23;
	ld.global.u32 	%r17, [%rd25];
	sub.s32 	%r6, %r17, %r25;
	setp.lt.s32	%p2, %r6, 1;
	setp.gt.s32	%p3, %r6, %r26;
	or.pred  	%p4, %p2, %p3;
	ld.global.u32 	%r7, [%rd24];
	setp.lt.s32	%p5, %r7, 1;
	or.pred  	%p6, %p4, %p5;
	setp.gt.s32	%p7, %r7, %r28;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	BB25_14;

	ld.const.f64 	%fd50, [dc_dryDepthThreshold];
	ld.const.f64 	%fd49, [dc_wetDepthThreshold];
	ld.const.u32 	%r30, [dc_nyPadded];
	shl.b64 	%rd26, %rd11, 2;
	add.s64 	%rd27, %rd3, %rd26;
	ld.global.u32 	%r8, [%rd27];
	mad.lo.s32 	%r18, %r30, %r6, %r7;
	cvt.s64.s32	%rd12, %r18;
	mul.wide.s32 	%rd29, %r18, 8;
	add.s64 	%rd30, %rd28, %rd29;
	ld.global.f64 	%fd30, [%rd30];
	setp.gt.f64	%p9, %fd30, %fd49;
	selp.f64	%fd3, %fd30, %fd50, %p9;
	mul.lo.s32 	%r19, %r31, 3;
	mul.wide.s32 	%rd31, %r19, 8;
	add.s64 	%rd32, %rd4, %rd31;
	add.s32 	%r20, %r19, 1;
	mul.wide.s32 	%rd33, %r20, 8;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.f64 	%fd4, [%rd34];
	ld.global.f64 	%fd5, [%rd32];
	sub.f64 	%fd31, %fd4, %fd5;
	ld.global.f64 	%fd6, [%rd34+8];
	sub.f64 	%fd32, %fd6, %fd4;
	setp.gt.f64	%p10, %fd31, 0d3F50624DD2F1A9FC;
	selp.f64	%fd7, %fd31, 0d3F50624DD2F1A9FC, %p10;
	setp.gt.f64	%p11, %fd32, 0d3F50624DD2F1A9FC;
	selp.f64	%fd8, %fd32, 0d3F50624DD2F1A9FC, %p11;
	add.s64 	%rd35, %rd5, %rd31;
	ld.global.f64 	%fd9, [%rd35];
	add.s64 	%rd36, %rd5, %rd33;
	ld.global.f64 	%fd10, [%rd36];
	ld.global.f64 	%fd11, [%rd36+8];
	add.s64 	%rd37, %rd6, %rd31;
	ld.global.f64 	%fd12, [%rd37];
	add.s64 	%rd38, %rd6, %rd33;
	ld.global.f64 	%fd13, [%rd38];
	ld.global.f64 	%fd14, [%rd38+8];
	setp.lt.f64	%p12, %fd3, %fd5;
	mov.f64 	%fd55, 0d0000000000000000;
	mov.f64 	%fd54, %fd55;
	mov.f64 	%fd27, %fd55;
	mov.f64 	%fd52, %fd3;
	mov.f64 	%fd53, %fd27;
	@%p12 bra 	BB25_7;

	setp.lt.f64	%p13, %fd3, %fd4;
	@%p13 bra 	BB25_6;
	bra.uni 	BB25_5;

BB25_6:
	sub.f64 	%fd17, %fd3, %fd5;
	mov.f64 	%fd55, 0d0000000000000000;
	mov.f64 	%fd54, %fd55;
	mov.f64 	%fd51, %fd5;
	mov.f64 	%fd52, %fd51;
	mov.f64 	%fd53, %fd17;
	bra.uni 	BB25_7;

BB25_5:
	setp.lt.f64	%p14, %fd3, %fd6;
	sub.f64 	%fd33, %fd3, %fd4;
	selp.f64	%fd54, %fd33, %fd8, %p14;
	sub.f64 	%fd34, %fd3, %fd6;
	selp.f64	%fd55, 0d0000000000000000, %fd34, %p14;
	mov.f64 	%fd52, %fd5;
	mov.f64 	%fd53, %fd7;

BB25_7:
	mov.f64 	%fd19, %fd53;
	mov.f64 	%fd18, %fd52;
	mul.f64 	%fd37, %fd10, %fd19;
	fma.rn.f64 	%fd38, %fd9, %fd18, %fd37;
	fma.rn.f64 	%fd39, %fd11, %fd54, %fd38;
	add.f64 	%fd40, %fd55, %fd39;
	div.rn.f64 	%fd41, %fd40, %fd3;
	setp.gt.f64	%p15, %fd41, 0d3FB999999999999A;
	selp.f64	%fd42, %fd41, 0d3FB999999999999A, %p15;
	setp.lt.f64	%p16, %fd42, 0d3FF0000000000000;
	selp.f64	%fd22, %fd42, 0d3FF0000000000000, %p16;
	setp.lt.s32	%p17, %r8, 10;
	@%p17 bra 	BB25_9;
	bra.uni 	BB25_8;

BB25_9:
	div.rn.f64 	%fd46, %fd19, %fd7;
	fma.rn.f64 	%fd47, %fd13, %fd46, %fd12;
	div.rn.f64 	%fd48, %fd54, %fd8;
	fma.rn.f64 	%fd56, %fd14, %fd48, %fd47;
	bra.uni 	BB25_10;

BB25_8:
	mul.f64 	%fd43, %fd13, %fd19;
	fma.rn.f64 	%fd44, %fd12, %fd18, %fd43;
	fma.rn.f64 	%fd45, %fd14, %fd54, %fd44;
	div.rn.f64 	%fd56, %fd45, %fd3;

BB25_10:
	setp.gt.f64	%p18, %fd56, 0d0000000000000000;
	selp.f64	%fd26, %fd56, 0d0000000000000000, %p18;
	setp.eq.s32	%p19, %r8, 3;
	@%p19 bra 	BB25_12;

	setp.ne.s32	%p20, %r8, 13;
	@%p20 bra 	BB25_13;

BB25_12:
	shl.b64 	%rd40, %rd12, 3;
	add.s64 	%rd41, %rd39, %rd40;
	st.global.f64 	[%rd41], %fd22;
	add.s64 	%rd42, %rd9, %rd40;
	st.global.f64 	[%rd42], %fd26;
	bra.uni 	BB25_14;

BB25_13:
	shl.b64 	%rd43, %rd12, 3;
	add.s64 	%rd44, %rd7, %rd43;
	st.global.f64 	[%rd44], %fd22;
	add.s64 	%rd45, %rd8, %rd43;
	st.global.f64 	[%rd45], %fd26;

BB25_14:
	ld.param.u32 	%r24, [gpu_calcVarFC_param_2];
	mov.u32 	%r23, %ntid.y;
	mov.u32 	%r21, %ntid.x;
	mad.lo.s32 	%r31, %r21, %r23, %r31;
	setp.lt.s32	%p21, %r31, %r24;
	@%p21 bra 	BB25_2;

BB25_15:
	ret;
}

	// .globl	gpu_calcVarZ
.visible .entry gpu_calcVarZ(
	.param .u32 gpu_calcVarZ_param_0,
	.param .u32 gpu_calcVarZ_param_1,
	.param .u32 gpu_calcVarZ_param_2,
	.param .u64 gpu_calcVarZ_param_3,
	.param .f64 gpu_calcVarZ_param_4
)
{
	.local .align 8 .b8 	__local_depot26[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<71>;
	.reg .b16 	%rs<11>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<61>;
	.reg .b64 	%rd<118>;


	mov.u64 	%rd117, __local_depot26;
	cvta.local.u64 	%SP, %rd117;
	ld.param.u32 	%r20, [gpu_calcVarZ_param_2];
	ld.param.u64 	%rd17, [gpu_calcVarZ_param_3];
	ld.param.f64 	%fd22, [gpu_calcVarZ_param_4];
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.x;
	mov.u32 	%r23, %tid.y;
	mad.lo.s32 	%r52, %r21, %r22, %r23;
	setp.ge.s32	%p4, %r52, %r20;
	@%p4 bra 	BB26_70;

	ld.const.u32 	%r51, [dc_nx];
	ld.const.u64 	%rd18, [dc_varZ_m];
	cvta.to.global.u64 	%rd1, %rd18;
	ld.const.u64 	%rd19, [dc_varZ_n];
	cvta.to.global.u64 	%rd2, %rd19;
	ld.const.u64 	%rd20, [dc_varZ_type];
	cvta.to.global.u64 	%rd3, %rd20;
	ld.const.u64 	%rd21, [dc_varZ_tv];
	cvta.to.global.u64 	%rd4, %rd21;
	ld.const.u64 	%rd22, [dc_varZ_z];
	cvta.to.global.u64 	%rd5, %rd22;
	ld.const.u64 	%rd23, [dc_varZ_t];
	cvta.to.global.u64 	%rd6, %rd23;
	ld.const.u64 	%rd7, [dc_zc];
	bra.uni 	BB26_2;

BB26_71:
	ld.const.u32 	%r51, [dc_nx];

BB26_2:
	mov.u32 	%r4, %r51;
	ld.param.u32 	%r49, [gpu_calcVarZ_param_1];
	mul.lo.s32 	%r24, %r52, 3;
	mul.wide.s32 	%rd24, %r24, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.u32 	%r25, [%rd25];
	sub.s32 	%r6, %r25, %r49;
	add.s32 	%r26, %r24, 1;
	mul.wide.s32 	%rd26, %r26, 4;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.u32 	%r27, [%rd27];
	sub.s32 	%r7, %r27, %r49;
	ld.global.u32 	%r28, [%rd27+4];
	sub.s32 	%r8, %r28, %r49;
	add.s64 	%rd28, %rd2, %rd24;
	add.s64 	%rd29, %rd2, %rd26;
	ld.global.u32 	%r9, [%rd29];
	ld.global.u32 	%r10, [%rd29+4];
	shl.b32 	%r29, %r52, 1;
	mul.wide.s32 	%rd30, %r29, 4;
	add.s64 	%rd31, %rd3, %rd30;
	ld.global.u32 	%r11, [%rd31];
	add.s32 	%r30, %r29, 1;
	mul.wide.s32 	%rd32, %r30, 4;
	add.s64 	%rd8, %rd3, %rd32;
	ld.global.u32 	%r12, [%rd8];
	shl.b32 	%r31, %r52, 2;
	mul.wide.s32 	%rd33, %r31, 8;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.f64 	%fd1, [%rd34];
	add.s32 	%r32, %r31, 1;
	mul.wide.s32 	%rd35, %r32, 8;
	add.s64 	%rd9, %rd4, %rd35;
	ld.global.f64 	%fd2, [%rd9];
	ld.global.f64 	%fd3, [%rd9+16];
	mul.wide.s32 	%rd36, %r29, 8;
	add.s64 	%rd10, %rd5, %rd36;
	ld.global.f64 	%fd4, [%rd10];
	ld.global.f64 	%fd5, [%rd10+8];
	add.s64 	%rd11, %rd6, %rd36;
	setp.lt.s32	%p5, %r6, 2;
	add.s32 	%r13, %r4, -2;
	setp.gt.s32	%p6, %r6, %r13;
	or.pred  	%p7, %p5, %p6;
	ld.global.u32 	%r14, [%rd28];
	setp.lt.s32	%p8, %r14, 2;
	or.pred  	%p9, %p7, %p8;
	ld.const.u32 	%r33, [dc_ny];
	add.s32 	%r34, %r33, -2;
	setp.gt.s32	%p10, %r14, %r34;
	or.pred  	%p11, %p9, %p10;
	ld.global.f64 	%fd6, [%rd11];
	setp.gt.f64	%p12, %fd6, 0d476812F9CF7920E3;
	or.pred  	%p13, %p11, %p12;
	@%p13 bra 	BB26_69;

	ld.global.f64 	%fd7, [%rd9+8];
	ld.global.f64 	%fd8, [%rd11+8];
	ld.const.u32 	%r15, [dc_nyPadded];
	mad.lo.s32 	%r16, %r15, %r6, %r14;
	setp.geu.f64	%p14, %fd6, 0dC76812F9CF7920E3;
	mov.f64 	%fd55, %fd6;
	mov.f64 	%fd58, %fd8;
	@%p14 bra 	BB26_24;

	setp.eq.s32	%p15, %r9, 0;
	@%p15 bra 	BB26_23;
	bra.uni 	BB26_5;

BB26_23:
	st.global.f64 	[%rd11], %fd1;
	st.global.f64 	[%rd11+8], %fd2;
	mov.f64 	%fd55, %fd1;
	mov.f64 	%fd58, %fd2;
	bra.uni 	BB26_24;

BB26_5:
	setp.lt.s32	%p16, %r12, 1;
	mov.f64 	%fd53, %fd6;
	mov.f64 	%fd55, %fd53;
	mov.f64 	%fd56, %fd8;
	mov.f64 	%fd58, %fd56;
	@%p16 bra 	BB26_24;

	setp.gt.u32	%p17, %r9, -3;
	@%p17 bra 	BB26_13;
	bra.uni 	BB26_7;

BB26_13:
	cvta.to.global.u64 	%rd50, %rd7;
	mul.wide.s32 	%rd51, %r16, 8;
	add.s64 	%rd14, %rd50, %rd51;
	cvta.to.global.u64 	%rd52, %rd17;
	add.s64 	%rd15, %rd52, %rd51;
	ld.global.f64 	%fd34, [%rd15];
	ld.global.f64 	%fd35, [%rd14];
	add.f64 	%fd9, %fd35, %fd34;
	setp.eq.s32	%p32, %r11, 13;
	@%p32 bra 	BB26_16;
	bra.uni 	BB26_14;

BB26_16:
	add.s32 	%r38, %r15, %r16;
	mul.wide.s32 	%rd54, %r38, 8;
	add.s64 	%rd55, %rd50, %rd54;
	add.s64 	%rd57, %rd52, %rd54;
	ld.global.f64 	%fd38, [%rd57];
	ld.global.f64 	%fd39, [%rd55];
	add.f64 	%fd11, %fd39, %fd38;
	mov.f64 	%fd52, %fd11;
	bra.uni 	BB26_17;

BB26_7:
	setp.eq.s32	%p18, %r9, -11;
	mov.u16 	%rs10, 0;
	@%p18 bra 	BB26_21;

	setp.eq.s32	%p19, %r10, 0;
	mad.lo.s32 	%r35, %r15, %r7, %r9;
	cvt.s64.s32	%rd12, %r35;
	cvta.to.global.u64 	%rd37, %rd17;
	mul.wide.s32 	%rd38, %r35, 8;
	add.s64 	%rd13, %rd37, %rd38;
	mov.u16 	%rs10, 0;
	@%p19 bra 	BB26_11;
	bra.uni 	BB26_9;

BB26_11:
	setp.gt.s32	%p28, %r7, 2;
	setp.lt.s32	%p29, %r7, %r13;
	and.pred  	%p30, %p28, %p29;
	@!%p30 bra 	BB26_21;
	bra.uni 	BB26_12;

BB26_12:
	ld.const.u64 	%rd46, [dc_zc];
	cvta.to.global.u64 	%rd47, %rd46;
	shl.b64 	%rd48, %rd12, 3;
	add.s64 	%rd49, %rd47, %rd48;
	ld.global.f64 	%fd31, [%rd13];
	ld.global.f64 	%fd32, [%rd49];
	add.f64 	%fd33, %fd32, %fd31;
	setp.gt.f64	%p31, %fd33, %fd1;
	selp.u16	%rs10, 1, 0, %p31;
	bra.uni 	BB26_21;

BB26_14:
	setp.ne.s32	%p33, %r11, 14;
	mov.f64 	%fd52, %fd9;
	@%p33 bra 	BB26_17;

	ld.global.f64 	%fd36, [%rd15+8];
	ld.global.f64 	%fd37, [%rd14+8];
	add.f64 	%fd10, %fd37, %fd36;
	mov.f64 	%fd52, %fd10;

BB26_17:
	mov.f64 	%fd12, %fd52;
	setp.eq.s32	%p34, %r9, -1;
	@%p34 bra 	BB26_19;
	bra.uni 	BB26_18;

BB26_19:
	setp.gt.f64	%p35, %fd9, %fd1;
	setp.gt.f64	%p36, %fd12, %fd1;
	or.pred  	%p70, %p35, %p36;
	bra.uni 	BB26_20;

BB26_18:
	sub.f64 	%fd40, %fd12, %fd9;
	abs.f64 	%fd41, %fd40;
	setp.gt.f64	%p70, %fd41, %fd1;

BB26_20:
	selp.u16	%rs10, 1, 0, %p70;

BB26_21:
	setp.eq.s16	%p37, %rs10, 0;
	mov.f64 	%fd54, %fd6;
	mov.f64 	%fd55, %fd54;
	mov.f64 	%fd57, %fd8;
	mov.f64 	%fd58, %fd57;
	@%p37 bra 	BB26_24;

	add.f64 	%fd58, %fd2, %fd22;
	st.global.f64 	[%rd11], %fd22;
	st.global.f64 	[%rd11+8], %fd58;
	add.s32 	%r39, %r12, -1;
	st.global.u32 	[%rd8], %r39;
	mov.f64 	%fd55, %fd22;

BB26_24:
	mov.f64 	%fd14, %fd55;
	setp.leu.f64	%p38, %fd14, 0dC76812F9CF7920E3;
	@%p38 bra 	BB26_69;

	setp.lt.f64	%p39, %fd14, %fd22;
	@%p39 bra 	BB26_49;
	bra.uni 	BB26_26;

BB26_49:
	sub.f64 	%fd44, %fd22, %fd14;
	sub.f64 	%fd45, %fd58, %fd14;
	div.rn.f64 	%fd46, %fd44, %fd45;
	setp.lt.f64	%p55, %fd46, 0d3FF0000000000000;
	selp.f64	%fd47, %fd46, 0d3FF0000000000000, %p55;
	fma.rn.f64 	%fd21, %fd5, %fd47, %fd4;
	ld.const.u64 	%rd94, [dc_varZ_q];
	cvta.to.global.u64 	%rd95, %rd94;
	mul.wide.s32 	%rd96, %r52, 4;
	add.s64 	%rd16, %rd95, %rd96;
	ld.global.u32 	%r41, [%rd16];
	add.s32 	%r42, %r41, 1;
	st.global.u32 	[%rd16], %r42;
	setp.gt.s32	%p56, %r11, 3;
	@%p56 bra 	BB26_54;

	setp.eq.s32	%p60, %r11, 1;
	@%p60 bra 	BB26_59;

	setp.eq.s32	%p61, %r11, 2;
	@%p61 bra 	BB26_58;
	bra.uni 	BB26_52;

BB26_58:
	ld.const.u64 	%rd105, [dc_zc];
	cvta.to.global.u64 	%rd106, %rd105;
	mul.wide.s32 	%rd107, %r16, 8;
	add.s64 	%rd108, %rd106, %rd107;
	st.global.f64 	[%rd108], %fd21;
	bra.uni 	BB26_60;

BB26_26:
	setp.gt.s32	%p40, %r11, 3;
	@%p40 bra 	BB26_31;

	setp.eq.s32	%p44, %r11, 1;
	@%p44 bra 	BB26_36;

	setp.eq.s32	%p45, %r11, 2;
	@%p45 bra 	BB26_35;
	bra.uni 	BB26_29;

BB26_35:
	ld.const.u64 	%rd66, [dc_zc];
	cvta.to.global.u64 	%rd67, %rd66;
	mul.wide.s32 	%rd68, %r16, 8;
	add.s64 	%rd69, %rd67, %rd68;
	ld.global.f64 	%fd18, [%rd69];
	mov.f64 	%fd60, %fd18;
	bra.uni 	BB26_37;

BB26_54:
	setp.eq.s32	%p57, %r11, 4;
	@%p57 bra 	BB26_57;

	setp.eq.s32	%p58, %r11, 13;
	@%p58 bra 	BB26_53;

	setp.ne.s32	%p59, %r11, 14;
	@%p59 bra 	BB26_60;

BB26_57:
	ld.const.u64 	%rd97, [dc_zv];
	cvta.to.global.u64 	%rd98, %rd97;
	mul.wide.s32 	%rd99, %r16, 8;
	add.s64 	%rd100, %rd98, %rd99;
	st.global.f64 	[%rd100], %fd21;
	bra.uni 	BB26_60;

BB26_31:
	setp.eq.s32	%p41, %r11, 4;
	@%p41 bra 	BB26_34;

	setp.eq.s32	%p42, %r11, 13;
	@%p42 bra 	BB26_30;

	setp.ne.s32	%p43, %r11, 14;
	mov.f64 	%fd60, %fd4;
	@%p43 bra 	BB26_37;

BB26_34:
	ld.const.u64 	%rd58, [dc_zv];
	cvta.to.global.u64 	%rd59, %rd58;
	mul.wide.s32 	%rd60, %r16, 8;
	add.s64 	%rd61, %rd59, %rd60;
	ld.global.f64 	%fd16, [%rd61];
	mov.f64 	%fd60, %fd16;
	bra.uni 	BB26_37;

BB26_59:
	ld.const.u64 	%rd109, [dc_zh];
	cvta.to.global.u64 	%rd110, %rd109;
	mul.wide.s32 	%rd111, %r16, 8;
	add.s64 	%rd112, %rd110, %rd111;
	st.global.f64 	[%rd112], %fd21;
	bra.uni 	BB26_60;

BB26_52:
	setp.eq.s32	%p62, %r11, 3;
	@%p62 bra 	BB26_53;
	bra.uni 	BB26_60;

BB26_53:
	ld.const.u64 	%rd101, [dc_zu];
	cvta.to.global.u64 	%rd102, %rd101;
	mul.wide.s32 	%rd103, %r16, 8;
	add.s64 	%rd104, %rd102, %rd103;
	st.global.f64 	[%rd104], %fd21;

BB26_60:
	setp.gtu.f64	%p63, %fd58, %fd22;
	@%p63 bra 	BB26_69;

	setp.lt.f64	%p64, %fd5, 0d0000000000000000;
	@%p64 bra 	BB26_65;
	bra.uni 	BB26_62;

BB26_65:
	setp.gt.f64	%p68, %fd3, 0d0000000000000000;
	@%p68 bra 	BB26_67;
	bra.uni 	BB26_66;

BB26_67:
	st.global.f64 	[%rd10], %fd21;
	neg.f64 	%fd49, %fd5;
	st.global.f64 	[%rd10+8], %fd49;
	add.f64 	%fd50, %fd7, %fd58;
	st.global.f64 	[%rd11], %fd50;
	add.f64 	%fd51, %fd3, %fd50;
	st.global.f64 	[%rd11+8], %fd51;
	bra.uni 	BB26_68;

BB26_62:
	setp.gt.s32	%p65, %r12, 0;
	setp.ne.s32	%p66, %r9, 0;
	and.pred  	%p67, %p65, %p66;
	@%p67 bra 	BB26_64;
	bra.uni 	BB26_63;

BB26_64:
	st.global.f64 	[%rd10], %fd21;
	neg.f64 	%fd48, %fd5;
	st.global.f64 	[%rd10+8], %fd48;
	mov.u64 	%rd114, -4616189618054758400;
	st.global.u64 	[%rd11], %rd114;
	st.global.u64 	[%rd11+8], %rd114;
	bra.uni 	BB26_68;

BB26_36:
	ld.const.u64 	%rd70, [dc_zh];
	cvta.to.global.u64 	%rd71, %rd70;
	mul.wide.s32 	%rd72, %r16, 8;
	add.s64 	%rd73, %rd71, %rd72;
	ld.global.f64 	%fd19, [%rd73];
	mov.f64 	%fd60, %fd19;
	bra.uni 	BB26_37;

BB26_29:
	setp.eq.s32	%p46, %r11, 3;
	mov.f64 	%fd59, %fd4;
	mov.f64 	%fd60, %fd59;
	@%p46 bra 	BB26_30;
	bra.uni 	BB26_37;

BB26_30:
	ld.const.u64 	%rd62, [dc_zu];
	cvta.to.global.u64 	%rd63, %rd62;
	mul.wide.s32 	%rd64, %r16, 8;
	add.s64 	%rd65, %rd63, %rd64;
	ld.global.f64 	%fd17, [%rd65];
	mov.f64 	%fd60, %fd17;

BB26_37:
	mov.f64 	%fd20, %fd60;
	sub.f64 	%fd42, %fd20, %fd4;
	abs.f64 	%fd43, %fd42;
	setp.leu.f64	%p47, %fd43, 0d3F50624DD2F1A9FC;
	@%p47 bra 	BB26_69;

	add.u64 	%rd74, %SP, 0;
	cvta.to.local.u64 	%rd75, %rd74;
	st.local.u32 	[%rd75], %r14;
	st.local.u32 	[%rd75+4], %r6;
	st.local.u32 	[%rd75+8], %r11;
	st.local.f64 	[%rd75+16], %fd20;
	st.local.f64 	[%rd75+24], %fd4;
	mov.u64 	%rd76, $str;
	cvta.global.u64 	%rd77, %rd76;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd77;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd74;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r40, [retval0+0];
	
	//{
	}// Callseq End 6
	@%p40 bra 	BB26_43;

	setp.eq.s32	%p52, %r11, 1;
	@%p52 bra 	BB26_48;

	setp.eq.s32	%p53, %r11, 2;
	@%p53 bra 	BB26_47;
	bra.uni 	BB26_41;

BB26_47:
	ld.const.u64 	%rd86, [dc_zc];
	cvta.to.global.u64 	%rd87, %rd86;
	mul.wide.s32 	%rd88, %r16, 8;
	add.s64 	%rd89, %rd87, %rd88;
	st.global.f64 	[%rd89], %fd4;
	bra.uni 	BB26_69;

BB26_43:
	setp.eq.s32	%p49, %r11, 4;
	@%p49 bra 	BB26_46;

	setp.eq.s32	%p50, %r11, 13;
	@%p50 bra 	BB26_42;

	setp.ne.s32	%p51, %r11, 14;
	@%p51 bra 	BB26_69;

BB26_46:
	ld.const.u64 	%rd78, [dc_zv];
	cvta.to.global.u64 	%rd79, %rd78;
	mul.wide.s32 	%rd80, %r16, 8;
	add.s64 	%rd81, %rd79, %rd80;
	st.global.f64 	[%rd81], %fd4;
	bra.uni 	BB26_69;

BB26_66:
	mov.u64 	%rd115, 5160588303184390427;
	st.global.u64 	[%rd11], %rd115;
	st.global.u64 	[%rd11+8], %rd115;
	bra.uni 	BB26_68;

BB26_63:
	mov.u64 	%rd113, 5160588303184390427;
	st.global.u64 	[%rd11], %rd113;
	st.global.u64 	[%rd11+8], %rd113;

BB26_68:
	mov.u32 	%r43, 0;
	st.global.u32 	[%rd16], %r43;
	bra.uni 	BB26_69;

BB26_48:
	ld.const.u64 	%rd90, [dc_zh];
	cvta.to.global.u64 	%rd91, %rd90;
	mul.wide.s32 	%rd92, %r16, 8;
	add.s64 	%rd93, %rd91, %rd92;
	st.global.f64 	[%rd93], %fd4;
	bra.uni 	BB26_69;

BB26_41:
	setp.eq.s32	%p54, %r11, 3;
	@%p54 bra 	BB26_42;
	bra.uni 	BB26_69;

BB26_42:
	ld.const.u64 	%rd82, [dc_zu];
	cvta.to.global.u64 	%rd83, %rd82;
	mul.wide.s32 	%rd84, %r16, 8;
	add.s64 	%rd85, %rd83, %rd84;
	st.global.f64 	[%rd85], %fd4;

BB26_69:
	ld.param.u32 	%r50, [gpu_calcVarZ_param_2];
	mov.u32 	%r48, %ntid.y;
	mov.u32 	%r44, %ntid.x;
	mad.lo.s32 	%r52, %r44, %r48, %r52;
	setp.lt.s32	%p69, %r52, %r50;
	@%p69 bra 	BB26_71;
	bra.uni 	BB26_70;

BB26_9:
	ld.const.u32 	%r47, [dc_nx];
	add.s32 	%r46, %r47, -2;
	setp.gt.s32	%p20, %r7, 2;
	setp.gt.s32	%p21, %r8, 2;
	and.pred  	%p22, %p20, %p21;
	setp.lt.s32	%p23, %r7, %r46;
	and.pred  	%p24, %p22, %p23;
	setp.lt.s32	%p25, %r8, %r46;
	and.pred  	%p26, %p24, %p25;
	@!%p26 bra 	BB26_21;
	bra.uni 	BB26_10;

BB26_10:
	cvta.to.global.u64 	%rd116, %rd17;
	mad.lo.s32 	%r37, %r15, %r8, %r10;
	cvta.to.global.u64 	%rd39, %rd7;
	add.s64 	%rd41, %rd39, %rd38;
	ld.global.f64 	%fd23, [%rd13];
	ld.global.f64 	%fd24, [%rd41];
	add.f64 	%fd25, %fd24, %fd23;
	mul.wide.s32 	%rd42, %r37, 8;
	add.s64 	%rd43, %rd39, %rd42;
	add.s64 	%rd45, %rd116, %rd42;
	ld.global.f64 	%fd26, [%rd45];
	ld.global.f64 	%fd27, [%rd43];
	add.f64 	%fd28, %fd27, %fd26;
	sub.f64 	%fd29, %fd28, %fd25;
	abs.f64 	%fd30, %fd29;
	setp.gt.f64	%p27, %fd30, %fd1;
	selp.u16	%rs10, 1, 0, %p27;
	bra.uni 	BB26_21;

BB26_70:
	ret;
}

	// .globl	gpu_incrementCumulativeWetTime
.visible .entry gpu_incrementCumulativeWetTime(
	.param .u32 gpu_incrementCumulativeWetTime_param_0,
	.param .f64 gpu_incrementCumulativeWetTime_param_1,
	.param .u64 gpu_incrementCumulativeWetTime_param_2,
	.param .u64 gpu_incrementCumulativeWetTime_param_3
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd1, [gpu_incrementCumulativeWetTime_param_1];
	ld.param.u64 	%rd1, [gpu_incrementCumulativeWetTime_param_2];
	ld.param.u64 	%rd2, [gpu_incrementCumulativeWetTime_param_3];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r7, %r8, %r9;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r10, [dc_ny];
	add.s32 	%r11, %r10, -2;
	setp.lt.s32	%p2, %r1, %r11;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r12, [dc_nx];
	add.s32 	%r13, %r12, -2;
	setp.lt.s32	%p6, %r2, %r13;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB27_4;
	bra.uni 	BB27_1;

BB27_1:
	ld.const.u32 	%r14, [dc_nyPadded];
	mad.lo.s32 	%r3, %r14, %r2, %r1;
	ld.const.u64 	%rd3, [dc_a];
	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.s32 	%rd5, %r3, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.u8 	%r15, [%rd6];
	setp.ne.s32	%p8, %r15, 0;
	@%p8 bra 	BB27_4;

	cvta.to.global.u64 	%rd7, %rd1;
	mul.wide.s32 	%rd8, %r3, 8;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.f64 	%fd2, [%rd9];
	setp.leu.f64	%p9, %fd2, 0d0000000000000000;
	@%p9 bra 	BB27_4;

	cvta.to.global.u64 	%rd10, %rd2;
	add.s64 	%rd12, %rd10, %rd8;
	ld.global.f64 	%fd3, [%rd12];
	add.f64 	%fd4, %fd3, %fd1;
	st.global.f64 	[%rd12], %fd4;

BB27_4:
	ret;
}

	// .globl	gpu_evaluateModel
.visible .entry gpu_evaluateModel(
	.param .u32 gpu_evaluateModel_param_0,
	.param .f64 gpu_evaluateModel_param_1,
	.param .u64 gpu_evaluateModel_param_2,
	.param .u64 gpu_evaluateModel_param_3,
	.param .u64 gpu_evaluateModel_param_4,
	.param .u64 gpu_evaluateModel_param_5,
	.param .u64 gpu_evaluateModel_param_6,
	.param .u64 gpu_evaluateModel_param_7
)
{
	.reg .pred 	%p<26>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<52>;
	.reg .b64 	%rd<45>;


	ld.param.f64 	%fd13, [gpu_evaluateModel_param_1];
	ld.param.u64 	%rd2, [gpu_evaluateModel_param_2];
	ld.param.u64 	%rd3, [gpu_evaluateModel_param_3];
	ld.param.u64 	%rd4, [gpu_evaluateModel_param_4];
	ld.param.u64 	%rd5, [gpu_evaluateModel_param_5];
	ld.param.u64 	%rd6, [gpu_evaluateModel_param_6];
	ld.param.u64 	%rd7, [gpu_evaluateModel_param_7];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r7, %r8, %r9;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r10, [dc_ny];
	add.s32 	%r11, %r10, -2;
	setp.lt.s32	%p2, %r1, %r11;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r12, [dc_nx];
	add.s32 	%r13, %r12, -2;
	setp.lt.s32	%p6, %r2, %r13;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB28_18;
	bra.uni 	BB28_1;

BB28_1:
	ld.const.u32 	%r14, [dc_nyPadded];
	mad.lo.s32 	%r15, %r14, %r2, %r1;
	ld.const.u64 	%rd8, [dc_a];
	cvta.to.global.u64 	%rd9, %rd8;
	cvt.s64.s32	%rd1, %r15;
	mul.wide.s32 	%rd10, %r15, 4;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.u8 	%r16, [%rd11];
	setp.ne.s32	%p8, %r16, 0;
	@%p8 bra 	BB28_18;

	cvta.to.global.u64 	%rd12, %rd4;
	cvta.to.global.u64 	%rd13, %rd3;
	cvta.to.global.u64 	%rd14, %rd2;
	shl.b64 	%rd15, %rd1, 3;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.f64 	%fd1, [%rd16];
	add.s64 	%rd17, %rd13, %rd15;
	ld.global.f64 	%fd2, [%rd17];
	add.s64 	%rd18, %rd12, %rd15;
	ld.global.f64 	%fd3, [%rd18];
	ld.const.u32 	%r17, [dc_turbulenceModel];
	mov.f64 	%fd14, 0d3FF0000000000000;
	setp.ne.s32	%p9, %r17, 1;
	mov.f64 	%fd51, %fd14;
	@%p9 bra 	BB28_4;

	cvta.to.global.u64 	%rd19, %rd5;
	add.s64 	%rd21, %rd19, %rd15;
	ld.global.f64 	%fd4, [%rd21];
	mov.f64 	%fd51, %fd4;

BB28_4:
	mov.f64 	%fd5, %fd51;
	ld.const.u32 	%r3, [dc_switches];
	and.b32  	%r18, %r3, 8192;
	setp.eq.s32	%p10, %r18, 0;
	mov.f64 	%fd50, %fd14;
	@%p10 bra 	BB28_6;

	cvta.to.global.u64 	%rd22, %rd6;
	add.s64 	%rd24, %rd22, %rd15;
	ld.global.f64 	%fd50, [%rd24];

BB28_6:
	ld.const.u64 	%rd25, [dc_nut];
	cvta.to.global.u64 	%rd26, %rd25;
	add.s64 	%rd28, %rd26, %rd15;
	ld.global.f64 	%fd8, [%rd28];
	and.b32  	%r19, %r3, 1024;
	setp.eq.s32	%p11, %r19, 0;
	mov.f64 	%fd49, %fd14;
	@%p11 bra 	BB28_8;

	ld.const.u64 	%rd29, [dc_areaFactor];
	cvta.to.global.u64 	%rd30, %rd29;
	add.s64 	%rd32, %rd30, %rd15;
	ld.global.f64 	%fd49, [%rd32];

BB28_8:
	abs.f64 	%fd17, %fd1;
	setp.gtu.f64	%p12, %fd17, 0d7FF0000000000000;
	@%p12 bra 	BB28_15;

	abs.f64 	%fd11, %fd2;
	setp.gtu.f64	%p13, %fd11, 0d7FF0000000000000;
	@%p13 bra 	BB28_15;

	abs.f64 	%fd12, %fd3;
	setp.gtu.f64	%p14, %fd12, 0d7FF0000000000000;
	@%p14 bra 	BB28_15;

	abs.f64 	%fd18, %fd5;
	setp.gtu.f64	%p15, %fd18, 0d7FF0000000000000;
	setp.lt.f64	%p16, %fd5, 0d0000000000000000;
	or.pred  	%p17, %p15, %p16;
	@%p17 bra 	BB28_15;

	abs.f64 	%fd19, %fd50;
	setp.gtu.f64	%p18, %fd19, 0d7FF0000000000000;
	setp.lt.f64	%p19, %fd50, 0d0000000000000000;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	BB28_15;

	abs.f64 	%fd20, %fd8;
	setp.gtu.f64	%p21, %fd20, 0d7FF0000000000000;
	@%p21 bra 	BB28_15;
	bra.uni 	BB28_14;

BB28_15:
	and.b32  	%r34, %r3, 1;
	setp.eq.b32	%p25, %r34, 1;
	@!%p25 bra 	BB28_17;
	bra.uni 	BB28_16;

BB28_16:
	ld.const.u64 	%rd38, [dc_nanCounter];
	cvta.to.global.u64 	%rd39, %rd38;
	shl.b64 	%rd40, %rd1, 2;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.u32 	%r35, [%rd41];
	add.s32 	%r36, %r35, 1;
	st.global.u32 	[%rd41], %r36;

BB28_17:
	mad.lo.s32 	%r40, %r9, %r4, %r6;
	and.b32  	%r41, %r40, 31;
	shl.b32 	%r42, %r41, 2;
	cvta.to.global.u64 	%rd42, %rd7;
	mul.wide.u32 	%rd43, %r42, 4;
	add.s64 	%rd44, %rd42, %rd43;
	atom.global.max.u32 	%r43, [%rd44], -1;

BB28_18:
	ret;

BB28_14:
	setp.lt.f64	%p22, %fd49, 0d3FF0000000000000;
	selp.f64	%fd21, %fd49, 0d3FF0000000000000, %p22;
	ld.const.f64 	%fd22, [dc_wetDepthThreshold];
	setp.gt.f64	%p23, %fd1, %fd22;
	ld.const.f64 	%fd23, [dc_dryDepthThreshold];
	selp.f64	%fd24, %fd1, %fd23, %p23;
	ld.const.f64 	%fd25, [dc_dy];
	ld.const.f64 	%fd26, [dc_dx];
	setp.lt.f64	%p24, %fd26, %fd25;
	selp.f64	%fd27, %fd26, %fd25, %p24;
	mul.f64 	%fd28, %fd21, %fd26;
	mul.f64 	%fd29, %fd11, %fd13;
	div.rn.f64 	%fd30, %fd29, %fd28;
	mul.f64 	%fd31, %fd30, 0d40F0000000000000;
	cvt.rzi.u32.f64	%r20, %fd31;
	mul.f64 	%fd32, %fd21, %fd25;
	mul.f64 	%fd33, %fd12, %fd13;
	div.rn.f64 	%fd34, %fd33, %fd32;
	mul.f64 	%fd35, %fd34, 0d40F0000000000000;
	cvt.rzi.u32.f64	%r21, %fd35;
	max.u32 	%r22, %r20, %r21;
	ld.const.f64 	%fd36, [dc_g];
	mul.f64 	%fd37, %fd24, %fd36;
	sqrt.rn.f64 	%fd38, %fd37;
	mul.f64 	%fd39, %fd38, %fd13;
	mul.f64 	%fd40, %fd21, %fd27;
	div.rn.f64 	%fd41, %fd39, %fd40;
	mul.f64 	%fd42, %fd41, 0d40F0000000000000;
	cvt.rzi.u32.f64	%r23, %fd42;
	mul.f64 	%fd43, %fd27, %fd27;
	mul.f64 	%fd44, %fd8, %fd13;
	div.rn.f64 	%fd45, %fd44, %fd43;
	mul.f64 	%fd46, %fd45, 0d40F0000000000000;
	cvt.rzi.u32.f64	%r24, %fd46;
	mad.lo.s32 	%r28, %r9, %r4, %r6;
	and.b32  	%r29, %r28, 31;
	shl.b32 	%r30, %r29, 2;
	cvta.to.global.u64 	%rd33, %rd7;
	mul.wide.u32 	%rd34, %r30, 4;
	add.s64 	%rd35, %rd33, %rd34;
	atom.global.max.u32 	%r31, [%rd35], %r22;
	add.s64 	%rd36, %rd35, 4;
	atom.global.max.u32 	%r32, [%rd36], %r23;
	add.s64 	%rd37, %rd35, 8;
	atom.global.max.u32 	%r33, [%rd37], %r24;
	bra.uni 	BB28_18;
}

	// .globl	gpu_postProcessStep
.visible .entry gpu_postProcessStep(
	.param .u32 gpu_postProcessStep_param_0,
	.param .f64 gpu_postProcessStep_param_1,
	.param .u64 gpu_postProcessStep_param_2,
	.param .u64 gpu_postProcessStep_param_3,
	.param .u64 gpu_postProcessStep_param_4,
	.param .u64 gpu_postProcessStep_param_5,
	.param .u64 gpu_postProcessStep_param_6,
	.param .u64 gpu_postProcessStep_param_7,
	.param .u64 gpu_postProcessStep_param_8,
	.param .u64 gpu_postProcessStep_param_9,
	.param .u64 gpu_postProcessStep_param_10
)
{
	.reg .pred 	%p<53>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<8>;
	.reg .b32 	%r<85>;
	.reg .f64 	%fd<204>;
	.reg .b64 	%rd<137>;


	ld.param.u64 	%rd14, [gpu_postProcessStep_param_2];
	ld.param.u64 	%rd15, [gpu_postProcessStep_param_3];
	ld.param.u64 	%rd16, [gpu_postProcessStep_param_4];
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd3, %rd15;
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r1, %r14, %r15, %r16;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r2, %r17, %r18, %r19;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r20, [dc_ny];
	add.s32 	%r21, %r20, -2;
	setp.lt.s32	%p2, %r1, %r21;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r22, [dc_nx];
	add.s32 	%r23, %r22, -2;
	setp.lt.s32	%p6, %r2, %r23;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB29_48;
	bra.uni 	BB29_1;

BB29_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	ld.const.u64 	%rd23, [dc_a];
	cvta.to.global.u64 	%rd4, %rd23;
	cvt.u64.u32	%rd5, %r4;
	mul.wide.u32 	%rd24, %r4, 4;
	add.s64 	%rd25, %rd4, %rd24;
	ld.global.u8 	%r5, [%rd25];
	setp.eq.s32	%p8, %r5, 255;
	@%p8 bra 	BB29_48;

	ld.const.u64 	%rd26, [dc_zc];
	cvta.to.global.u64 	%rd6, %rd26;
	shl.b64 	%rd27, %rd5, 3;
	add.s64 	%rd28, %rd6, %rd27;
	ld.global.f64 	%fd1, [%rd28];
	add.s64 	%rd29, %rd3, %rd27;
	ld.global.f64 	%fd2, [%rd29];
	add.s64 	%rd30, %rd2, %rd27;
	ld.global.f64 	%fd3, [%rd30];
	ld.const.u64 	%rd31, [dc_nut];
	cvta.to.global.u64 	%rd32, %rd31;
	add.s64 	%rd33, %rd32, %rd27;
	ld.global.f64 	%fd4, [%rd33];
	add.s32 	%r24, %r5, -1;
	setp.gt.u32	%p9, %r24, 251;
	add.s64 	%rd7, %rd1, %rd27;
	@%p9 bra 	BB29_28;
	bra.uni 	BB29_3;

BB29_28:
	ld.global.f64 	%fd197, [%rd7];
	bra.uni 	BB29_29;

BB29_3:
	ld.const.u64 	%rd34, [dc_boundaryLevelGraphTypes];
	cvta.to.global.u64 	%rd35, %rd34;
	cvt.u64.u32	%rd8, %r5;
	mul.wide.u32 	%rd36, %r5, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.u32 	%r6, [%rd37];
	setp.eq.s32	%p10, %r6, 1;
	@%p10 bra 	BB29_27;
	bra.uni 	BB29_4;

BB29_27:
	ld.const.u64 	%rd97, [dc_boundaryLevelGraphData];
	cvta.to.global.u64 	%rd98, %rd97;
	shl.b64 	%rd99, %rd8, 3;
	add.s64 	%rd100, %rd98, %rd99;
	ld.global.f64 	%fd160, [%rd100];
	sub.f64 	%fd161, %fd160, %fd1;
	ld.const.f64 	%fd162, [dc_wetDepthThreshold];
	setp.gt.f64	%p35, %fd161, %fd162;
	ld.const.f64 	%fd163, [dc_dryDepthThreshold];
	selp.f64	%fd197, %fd161, %fd163, %p35;
	st.global.f64 	[%rd7], %fd197;
	bra.uni 	BB29_29;

BB29_4:
	setp.ne.s32	%p11, %r6, 2;
	@%p11 bra 	BB29_29;

	ld.const.u32 	%r83, [dc_nyPadded];
	ld.const.u64 	%rd38, [dc_boundaryLevelGraphData];
	cvta.to.global.u64 	%rd39, %rd38;
	shl.b64 	%rd40, %rd8, 3;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.f64 	%fd5, [%rd41];
	sub.s32 	%r25, %r4, %r83;
	mul.wide.u32 	%rd42, %r25, 4;
	add.s64 	%rd43, %rd4, %rd42;
	mul.wide.u32 	%rd44, %r25, 8;
	add.s64 	%rd45, %rd6, %rd44;
	ld.global.f64 	%fd6, [%rd45];
	add.s64 	%rd46, %rd1, %rd44;
	shl.b32 	%r26, %r83, 1;
	sub.s32 	%r27, %r4, %r26;
	mul.wide.u32 	%rd47, %r27, 8;
	add.s64 	%rd48, %rd3, %rd47;
	add.s64 	%rd49, %rd3, %rd44;
	ld.global.f64 	%fd90, [%rd49];
	ld.global.f64 	%fd91, [%rd48];
	add.f64 	%fd92, %fd91, %fd90;
	mul.f64 	%fd7, %fd92, 0d3FE0000000000000;
	add.s64 	%rd50, %rd2, %rd44;
	add.s32 	%r28, %r25, -1;
	mul.wide.u32 	%rd51, %r28, 8;
	add.s64 	%rd52, %rd2, %rd51;
	ld.global.f64 	%fd93, [%rd52];
	ld.global.f64 	%fd94, [%rd50];
	add.f64 	%fd8, %fd94, %fd93;
	ld.global.u8 	%rs1, [%rd43];
	setp.eq.s16	%p12, %rs1, 0;
	ld.const.f64 	%fd9, [dc_wetDepthThreshold];
	ld.global.f64 	%fd10, [%rd46];
	setp.gt.f64	%p13, %fd10, %fd9;
	and.pred  	%p14, %p12, %p13;
	mov.f64 	%fd196, 0d0000000000000000;
	mov.f64 	%fd195, %fd196;
	mov.f64 	%fd194, %fd196;
	@!%p14 bra 	BB29_9;
	bra.uni 	BB29_6;

BB29_6:
	mul.f64 	%fd96, %fd8, 0d3FE0000000000000;
	mul.f64 	%fd97, %fd96, %fd96;
	fma.rn.f64 	%fd98, %fd7, %fd7, %fd97;
	sqrt.rn.f64 	%fd11, %fd98;
	abs.f64 	%fd12, %fd7;
	mov.f64 	%fd190, 0d0000000000000000;
	setp.leu.f64	%p15, %fd11, 0d0000000000000000;
	@%p15 bra 	BB29_8;

	ld.const.f64 	%fd99, [dc_dx];
	mul.f64 	%fd100, %fd5, %fd99;
	mul.f64 	%fd101, %fd12, %fd100;
	div.rn.f64 	%fd190, %fd101, %fd11;

BB29_8:
	add.f64 	%fd102, %fd6, %fd10;
	sub.f64 	%fd103, %fd102, %fd1;
	setp.gt.f64	%p16, %fd6, %fd1;
	selp.f64	%fd104, %fd10, %fd103, %p16;
	fma.rn.f64 	%fd195, %fd104, %fd12, 0d0000000000000000;
	sub.f64 	%fd105, %fd102, %fd190;
	fma.rn.f64 	%fd196, %fd12, %fd105, 0d0000000000000000;
	add.f64 	%fd194, %fd12, 0d0000000000000000;

BB29_9:
	ld.const.u32 	%r82, [dc_nyPadded];
	add.s32 	%r7, %r82, %r4;
	cvt.u64.u32	%rd9, %r7;
	mul.wide.u32 	%rd53, %r7, 4;
	add.s64 	%rd54, %rd4, %rd53;
	mul.wide.u32 	%rd56, %r7, 8;
	add.s64 	%rd57, %rd1, %rd56;
	ld.global.u8 	%rs2, [%rd54];
	setp.eq.s16	%p17, %rs2, 0;
	ld.global.f64 	%fd21, [%rd57];
	setp.gt.f64	%p18, %fd21, %fd9;
	and.pred  	%p19, %p17, %p18;
	@!%p19 bra 	BB29_13;
	bra.uni 	BB29_10;

BB29_10:
	shl.b64 	%rd58, %rd9, 3;
	add.s64 	%rd59, %rd6, %rd58;
	ld.global.f64 	%fd107, [%rd59];
	add.s64 	%rd61, %rd3, %rd58;
	ld.global.f64 	%fd108, [%rd61];
	add.f64 	%fd109, %fd2, %fd108;
	mul.f64 	%fd110, %fd109, 0d3FE0000000000000;
	add.s64 	%rd63, %rd2, %rd58;
	add.s32 	%r38, %r7, -1;
	mul.wide.u32 	%rd64, %r38, 8;
	add.s64 	%rd65, %rd2, %rd64;
	ld.global.f64 	%fd111, [%rd65];
	ld.global.f64 	%fd112, [%rd63];
	add.f64 	%fd113, %fd112, %fd111;
	mul.f64 	%fd114, %fd113, 0d3FE0000000000000;
	mul.f64 	%fd115, %fd114, %fd114;
	fma.rn.f64 	%fd116, %fd110, %fd110, %fd115;
	sqrt.rn.f64 	%fd22, %fd116;
	abs.f64 	%fd23, %fd110;
	add.f64 	%fd194, %fd194, %fd23;
	add.f64 	%fd25, %fd107, %fd21;
	sub.f64 	%fd117, %fd25, %fd1;
	setp.gt.f64	%p20, %fd107, %fd1;
	selp.f64	%fd118, %fd21, %fd117, %p20;
	fma.rn.f64 	%fd195, %fd118, %fd23, %fd195;
	mov.f64 	%fd191, 0d0000000000000000;
	setp.leu.f64	%p21, %fd22, 0d0000000000000000;
	@%p21 bra 	BB29_12;

	ld.const.f64 	%fd119, [dc_dx];
	mul.f64 	%fd120, %fd5, %fd119;
	mul.f64 	%fd121, %fd23, %fd120;
	div.rn.f64 	%fd191, %fd121, %fd22;

BB29_12:
	sub.f64 	%fd122, %fd25, %fd191;
	fma.rn.f64 	%fd196, %fd23, %fd122, %fd196;

BB29_13:
	ld.const.u64 	%rd136, [dc_a];
	cvta.to.global.u64 	%rd135, %rd136;
	ld.param.u64 	%rd134, [gpu_postProcessStep_param_2];
	cvta.to.global.u64 	%rd133, %rd134;
	add.s32 	%r9, %r4, -1;
	cvt.u64.u32	%rd10, %r9;
	mul.wide.u32 	%rd66, %r9, 4;
	add.s64 	%rd67, %rd135, %rd66;
	mul.wide.u32 	%rd69, %r9, 8;
	add.s64 	%rd70, %rd133, %rd69;
	ld.global.u8 	%rs3, [%rd67];
	setp.eq.s16	%p22, %rs3, 0;
	ld.global.f64 	%fd33, [%rd70];
	setp.gt.f64	%p23, %fd33, %fd9;
	and.pred  	%p24, %p22, %p23;
	@!%p24 bra 	BB29_17;
	bra.uni 	BB29_14;

BB29_14:
	ld.const.u32 	%r81, [dc_nyPadded];
	shl.b64 	%rd71, %rd10, 3;
	add.s64 	%rd72, %rd6, %rd71;
	ld.global.f64 	%fd124, [%rd72];
	sub.s32 	%r47, %r9, %r81;
	mul.wide.u32 	%rd74, %r47, 8;
	add.s64 	%rd75, %rd3, %rd74;
	add.s64 	%rd76, %rd3, %rd71;
	ld.global.f64 	%fd125, [%rd76];
	ld.global.f64 	%fd126, [%rd75];
	add.f64 	%fd127, %fd126, %fd125;
	mul.f64 	%fd128, %fd127, 0d3FE0000000000000;
	add.s32 	%r48, %r4, -2;
	mul.wide.u32 	%rd78, %r48, 8;
	add.s64 	%rd79, %rd2, %rd78;
	add.s64 	%rd80, %rd2, %rd71;
	ld.global.f64 	%fd129, [%rd80];
	ld.global.f64 	%fd130, [%rd79];
	add.f64 	%fd131, %fd130, %fd129;
	mul.f64 	%fd132, %fd131, 0d3FE0000000000000;
	mul.f64 	%fd133, %fd132, %fd132;
	fma.rn.f64 	%fd134, %fd128, %fd128, %fd133;
	sqrt.rn.f64 	%fd34, %fd134;
	abs.f64 	%fd35, %fd132;
	add.f64 	%fd194, %fd194, %fd35;
	add.f64 	%fd37, %fd124, %fd33;
	sub.f64 	%fd135, %fd37, %fd1;
	setp.gt.f64	%p25, %fd124, %fd1;
	selp.f64	%fd136, %fd33, %fd135, %p25;
	fma.rn.f64 	%fd195, %fd136, %fd35, %fd195;
	mov.f64 	%fd192, 0d0000000000000000;
	setp.leu.f64	%p26, %fd34, 0d0000000000000000;
	@%p26 bra 	BB29_16;

	ld.const.f64 	%fd137, [dc_dx];
	mul.f64 	%fd138, %fd5, %fd137;
	mul.f64 	%fd139, %fd35, %fd138;
	div.rn.f64 	%fd192, %fd139, %fd34;

BB29_16:
	sub.f64 	%fd140, %fd37, %fd192;
	fma.rn.f64 	%fd196, %fd35, %fd140, %fd196;

BB29_17:
	ld.const.u64 	%rd132, [dc_a];
	cvta.to.global.u64 	%rd131, %rd132;
	ld.param.u64 	%rd130, [gpu_postProcessStep_param_2];
	cvta.to.global.u64 	%rd129, %rd130;
	ld.const.u32 	%r77, [dc_nyPadded];
	add.s32 	%r58, %r4, 1;
	cvt.u64.u32	%rd11, %r58;
	mul.wide.u32 	%rd81, %r58, 4;
	add.s64 	%rd82, %rd131, %rd81;
	mul.wide.u32 	%rd83, %r58, 8;
	add.s64 	%rd84, %rd6, %rd83;
	ld.global.f64 	%fd45, [%rd84];
	add.s64 	%rd86, %rd129, %rd83;
	sub.s32 	%r10, %r58, %r77;
	ld.global.u8 	%rs4, [%rd82];
	setp.eq.s16	%p27, %rs4, 0;
	ld.global.f64 	%fd46, [%rd86];
	setp.gt.f64	%p28, %fd46, %fd9;
	and.pred  	%p29, %p27, %p28;
	@!%p29 bra 	BB29_21;
	bra.uni 	BB29_18;

BB29_18:
	mul.wide.u32 	%rd88, %r10, 8;
	add.s64 	%rd89, %rd3, %rd88;
	shl.b64 	%rd90, %rd11, 3;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.f64 	%fd142, [%rd91];
	ld.global.f64 	%fd143, [%rd89];
	add.f64 	%fd144, %fd143, %fd142;
	mul.f64 	%fd145, %fd144, 0d3FE0000000000000;
	add.s64 	%rd93, %rd2, %rd90;
	ld.global.f64 	%fd146, [%rd93];
	add.f64 	%fd147, %fd3, %fd146;
	mul.f64 	%fd148, %fd147, 0d3FE0000000000000;
	mul.f64 	%fd149, %fd148, %fd148;
	fma.rn.f64 	%fd150, %fd145, %fd145, %fd149;
	sqrt.rn.f64 	%fd47, %fd150;
	abs.f64 	%fd48, %fd148;
	add.f64 	%fd194, %fd194, %fd48;
	add.f64 	%fd50, %fd45, %fd46;
	sub.f64 	%fd151, %fd50, %fd1;
	setp.gt.f64	%p30, %fd45, %fd1;
	selp.f64	%fd152, %fd46, %fd151, %p30;
	fma.rn.f64 	%fd195, %fd152, %fd48, %fd195;
	mov.f64 	%fd193, 0d0000000000000000;
	setp.leu.f64	%p31, %fd47, 0d0000000000000000;
	@%p31 bra 	BB29_20;

	ld.const.f64 	%fd153, [dc_dx];
	mul.f64 	%fd154, %fd5, %fd153;
	mul.f64 	%fd155, %fd48, %fd154;
	div.rn.f64 	%fd193, %fd155, %fd47;

BB29_20:
	sub.f64 	%fd156, %fd50, %fd193;
	fma.rn.f64 	%fd196, %fd48, %fd156, %fd196;

BB29_21:
	setp.gt.f64	%p32, %fd194, 0d0000000000000000;
	@%p32 bra 	BB29_23;
	bra.uni 	BB29_22;

BB29_23:
	setp.gt.f64	%p33, %fd5, 0d0000000000000000;
	@%p33 bra 	BB29_25;
	bra.uni 	BB29_24;

BB29_25:
	div.rn.f64 	%fd157, %fd196, %fd194;
	sub.f64 	%fd158, %fd157, %fd1;
	setp.gt.f64	%p34, %fd158, %fd9;
	ld.const.f64 	%fd159, [dc_dryDepthThreshold];
	selp.f64	%fd197, %fd158, %fd159, %p34;
	bra.uni 	BB29_26;

BB29_22:
	ld.const.f64 	%fd197, [dc_dryDepthThreshold];
	bra.uni 	BB29_26;

BB29_24:
	div.rn.f64 	%fd197, %fd195, %fd194;

BB29_26:
	st.global.f64 	[%rd7], %fd197;

BB29_29:
	ld.const.u32 	%r11, [dc_switches];
	and.b32  	%r59, %r11, 1024;
	setp.eq.s32	%p36, %r59, 0;
	mov.f64 	%fd198, 0d3FF0000000000000;
	@%p36 bra 	BB29_31;

	ld.const.u64 	%rd101, [dc_areaFactor];
	cvta.to.global.u64 	%rd102, %rd101;
	add.s64 	%rd104, %rd102, %rd27;
	ld.global.f64 	%fd198, [%rd104];

BB29_31:
	ld.const.f64 	%fd67, [dc_wetDepthThreshold];
	mov.u32 	%r84, 0;
	setp.leu.f64	%p37, %fd197, %fd67;
	@%p37 bra 	BB29_44;

	add.f64 	%fd68, %fd1, %fd197;
	and.b32  	%r62, %r11, 4;
	setp.eq.s32	%p38, %r62, 0;
	mov.u32 	%r84, 0;
	@%p38 bra 	BB29_35;

	ld.param.u64 	%rd126, [gpu_postProcessStep_param_6];
	cvta.to.global.u64 	%rd105, %rd126;
	add.s64 	%rd12, %rd105, %rd27;
	ld.global.f64 	%fd165, [%rd12];
	setp.leu.f64	%p39, %fd68, %fd165;
	@%p39 bra 	BB29_35;

	ld.param.f64 	%fd189, [gpu_postProcessStep_param_1];
	ld.param.u64 	%rd127, [gpu_postProcessStep_param_7];
	st.global.f64 	[%rd12], %fd68;
	cvta.to.global.u64 	%rd107, %rd127;
	add.s64 	%rd109, %rd107, %rd27;
	st.global.f64 	[%rd109], %fd189;
	mov.u32 	%r84, 1;

BB29_35:
	and.b32  	%r65, %r11, 32768;
	setp.eq.s32	%p40, %r65, 0;
	@%p40 bra 	BB29_44;

	ld.const.f64 	%fd69, [dc_dx];
	ld.const.f64 	%fd70, [dc_dy];
	setp.lt.f64	%p41, %fd69, %fd70;
	selp.f64	%fd71, %fd69, %fd70, %p41;
	setp.lt.f64	%p42, %fd198, 0d3FF0000000000000;
	selp.f64	%fd72, %fd198, 0d3FF0000000000000, %p42;
	abs.f64 	%fd73, %fd2;
	mov.f64 	%fd166, 0d479E17B84357691B;
	setp.leu.f64	%p43, %fd73, 0d0000000000000000;
	mov.f64 	%fd203, %fd166;
	@%p43 bra 	BB29_38;

	mul.f64 	%fd167, %fd72, %fd69;
	div.rn.f64 	%fd74, %fd167, %fd73;
	mov.f64 	%fd203, %fd74;

BB29_38:
	mov.f64 	%fd75, %fd203;
	abs.f64 	%fd76, %fd3;
	setp.leu.f64	%p44, %fd76, 0d0000000000000000;
	mov.f64 	%fd202, %fd166;
	@%p44 bra 	BB29_40;

	mul.f64 	%fd169, %fd72, %fd70;
	div.rn.f64 	%fd202, %fd169, %fd76;

BB29_40:
	ld.const.f64 	%fd171, [dc_g];
	mul.f64 	%fd172, %fd197, %fd171;
	sqrt.rn.f64 	%fd173, %fd172;
	mul.f64 	%fd174, %fd72, %fd71;
	div.rn.f64 	%fd79, %fd174, %fd173;
	setp.leu.f64	%p45, %fd4, 0d0000000000000000;
	mov.f64 	%fd201, %fd166;
	@%p45 bra 	BB29_42;

	mul.f64 	%fd175, %fd71, 0d3FD3333333333333;
	mul.f64 	%fd176, %fd71, %fd175;
	div.rn.f64 	%fd201, %fd176, %fd4;

BB29_42:
	ld.param.u64 	%rd128, [gpu_postProcessStep_param_8];
	setp.lt.f64	%p46, %fd75, %fd202;
	selp.f64	%fd177, %fd75, %fd202, %p46;
	setp.lt.f64	%p47, %fd79, %fd177;
	selp.f64	%fd178, %fd79, %fd177, %p47;
	setp.lt.f64	%p48, %fd201, %fd178;
	selp.f64	%fd82, %fd201, %fd178, %p48;
	cvta.to.global.u64 	%rd110, %rd128;
	add.s64 	%rd13, %rd110, %rd27;
	ld.global.f64 	%fd179, [%rd13];
	setp.geu.f64	%p49, %fd82, %fd179;
	@%p49 bra 	BB29_44;

	st.global.f64 	[%rd13], %fd82;

BB29_44:
	setp.ne.s32	%p50, %r5, 0;
	@%p50 bra 	BB29_48;

	ld.const.f64 	%fd83, [dc_dx];
	ld.const.f64 	%fd84, [dc_dy];
	and.b32  	%r66, %r11, 8;
	setp.eq.s32	%p51, %r66, 0;
	mov.f32 	%f7, 0f00000000;
	@%p51 bra 	BB29_47;

	ld.param.u64 	%rd123, [gpu_postProcessStep_param_5];
	cvta.to.global.u64 	%rd112, %rd123;
	add.s64 	%rd114, %rd112, %rd27;
	ld.global.f64 	%fd180, [%rd114];
	mul.f64 	%fd181, %fd198, %fd180;
	mul.f64 	%fd182, %fd181, %fd83;
	mul.f64 	%fd183, %fd182, %fd84;
	cvt.rn.f32.f64	%f7, %fd183;

BB29_47:
	ld.param.u64 	%rd125, [gpu_postProcessStep_param_10];
	ld.param.u64 	%rd124, [gpu_postProcessStep_param_9];
	mov.u32 	%r80, %tid.x;
	mov.u32 	%r79, %ntid.x;
	mov.u32 	%r78, %tid.y;
	add.f64 	%fd184, %fd197, 0d3F1A36E2EB1C432D;
	sub.f64 	%fd185, %fd184, %fd67;
	mul.f64 	%fd186, %fd198, %fd185;
	mul.f64 	%fd187, %fd83, %fd186;
	mul.f64 	%fd188, %fd84, %fd187;
	cvt.rn.f32.f64	%f4, %fd188;
	mad.lo.s32 	%r70, %r78, %r79, %r80;
	and.b32  	%r71, %r70, 31;
	shl.b32 	%r72, %r71, 2;
	cvta.to.global.u64 	%rd115, %rd124;
	mul.wide.u32 	%rd116, %r72, 4;
	add.s64 	%rd117, %rd115, %rd116;
	setp.gt.f64	%p52, %fd197, %fd67;
	selp.u32	%r73, 1, 0, %p52;
	atom.global.add.u32 	%r74, [%rd117], %r73;
	add.s64 	%rd118, %rd117, 4;
	atom.global.add.u32 	%r75, [%rd118], %r84;
	shl.b32 	%r76, %r71, 3;
	cvta.to.global.u64 	%rd119, %rd125;
	mul.wide.u32 	%rd120, %r76, 4;
	add.s64 	%rd121, %rd119, %rd120;
	atom.global.add.f32 	%f5, [%rd121], %f4;
	add.s64 	%rd122, %rd121, 4;
	atom.global.add.f32 	%f6, [%rd122], %f7;

BB29_48:
	ret;
}

	// .globl	gpu_processScalarMaximum
.visible .entry gpu_processScalarMaximum(
	.param .u32 gpu_processScalarMaximum_param_0,
	.param .f64 gpu_processScalarMaximum_param_1,
	.param .u64 gpu_processScalarMaximum_param_2,
	.param .u64 gpu_processScalarMaximum_param_3,
	.param .u64 gpu_processScalarMaximum_param_4,
	.param .u64 gpu_processScalarMaximum_param_5,
	.param .u64 gpu_processScalarMaximum_param_6,
	.param .u64 gpu_processScalarMaximum_param_7,
	.param .u64 gpu_processScalarMaximum_param_8
)
{
	.reg .pred 	%p<306>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<241>;
	.reg .b64 	%rd<73>;


	ld.param.f64 	%fd88, [gpu_processScalarMaximum_param_1];
	ld.param.u64 	%rd8, [gpu_processScalarMaximum_param_2];
	ld.param.u64 	%rd9, [gpu_processScalarMaximum_param_3];
	ld.param.u64 	%rd10, [gpu_processScalarMaximum_param_4];
	ld.param.u64 	%rd11, [gpu_processScalarMaximum_param_5];
	ld.param.u64 	%rd12, [gpu_processScalarMaximum_param_6];
	ld.param.u64 	%rd13, [gpu_processScalarMaximum_param_7];
	ld.param.u64 	%rd14, [gpu_processScalarMaximum_param_8];
	cvta.to.global.u64 	%rd1, %rd10;
	mov.u32 	%r11, %ntid.x;
	mov.u32 	%r12, %ctaid.x;
	mov.u32 	%r13, %tid.x;
	mad.lo.s32 	%r1, %r11, %r12, %r13;
	mov.u32 	%r14, %ntid.y;
	mov.u32 	%r15, %ctaid.y;
	mov.u32 	%r16, %tid.y;
	mad.lo.s32 	%r2, %r14, %r15, %r16;
	setp.gt.s32	%p4, %r1, 1;
	ld.const.u32 	%r17, [dc_ny];
	add.s32 	%r18, %r17, -2;
	setp.lt.s32	%p5, %r1, %r18;
	and.pred  	%p6, %p4, %p5;
	setp.gt.s32	%p7, %r2, 1;
	and.pred  	%p8, %p6, %p7;
	ld.const.u32 	%r19, [dc_nx];
	add.s32 	%r20, %r19, -2;
	setp.lt.s32	%p9, %r2, %r20;
	and.pred  	%p10, %p8, %p9;
	@!%p10 bra 	BB30_197;
	bra.uni 	BB30_1;

BB30_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	ld.const.u64 	%rd15, [dc_a];
	cvta.to.global.u64 	%rd2, %rd15;
	cvt.u64.u32	%rd3, %r4;
	mul.wide.u32 	%rd16, %r4, 4;
	add.s64 	%rd17, %rd2, %rd16;
	ld.global.u8 	%r21, [%rd17];
	setp.eq.s32	%p11, %r21, 255;
	@%p11 bra 	BB30_197;

	shl.b64 	%rd18, %rd3, 3;
	add.s64 	%rd19, %rd1, %rd18;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.global.f64 	%fd2, [%rd19];
	setp.leu.f64	%p12, %fd2, %fd1;
	@%p12 bra 	BB30_197;

	cvta.to.global.u64 	%rd20, %rd12;
	cvta.to.global.u64 	%rd21, %rd11;
	ld.const.u64 	%rd22, [dc_zc];
	cvta.to.global.u64 	%rd23, %rd22;
	add.s64 	%rd25, %rd23, %rd18;
	ld.global.f64 	%fd3, [%rd25];
	sub.s32 	%r22, %r4, %r3;
	cvt.u64.u32	%rd4, %r22;
	mul.wide.u32 	%rd26, %r22, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.global.u8 	%r23, [%rd27];
	add.s32 	%r24, %r3, %r4;
	mul.wide.u32 	%rd28, %r24, 4;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.u8 	%r5, [%rd29];
	add.s32 	%r25, %r4, -1;
	cvt.u64.u32	%rd5, %r25;
	mul.wide.u32 	%rd30, %r25, 4;
	add.s64 	%rd31, %rd2, %rd30;
	ld.global.u32 	%r6, [%rd31];
	add.s32 	%r26, %r4, 1;
	mul.wide.u32 	%rd32, %r26, 4;
	add.s64 	%rd33, %rd2, %rd32;
	ld.global.u8 	%r7, [%rd33];
	mul.wide.u32 	%rd34, %r24, 8;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.f64 	%fd4, [%rd35];
	mul.wide.u32 	%rd36, %r25, 8;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.f64 	%fd5, [%rd37];
	mul.wide.u32 	%rd38, %r26, 8;
	add.s64 	%rd39, %rd1, %rd38;
	ld.global.f64 	%fd6, [%rd39];
	mul.wide.u32 	%rd40, %r22, 8;
	add.s64 	%rd41, %rd21, %rd40;
	ld.global.f64 	%fd239, [%rd41];
	add.s64 	%rd42, %rd21, %rd18;
	ld.global.f64 	%fd8, [%rd42];
	add.s64 	%rd43, %rd20, %rd36;
	ld.global.f64 	%fd240, [%rd43];
	add.s64 	%rd44, %rd20, %rd18;
	ld.global.f64 	%fd10, [%rd44];
	setp.eq.s32	%p14, %r23, 255;
	mov.pred 	%p305, 0;
	@%p14 bra 	BB30_5;

	shl.b64 	%rd46, %rd4, 3;
	add.s64 	%rd47, %rd1, %rd46;
	ld.global.f64 	%fd89, [%rd47];
	setp.gt.f64	%p305, %fd89, %fd1;

BB30_5:
	@%p305 bra 	BB30_8;
	bra.uni 	BB30_6;

BB30_8:
	setp.ne.s32	%p17, %r5, 255;
	setp.gt.f64	%p18, %fd4, %fd1;
	and.pred  	%p19, %p18, %p17;
	@!%p19 bra 	BB30_10;
	bra.uni 	BB30_9;

BB30_9:
	add.f64 	%fd91, %fd239, %fd8;
	mul.f64 	%fd239, %fd91, 0d3FE0000000000000;
	bra.uni 	BB30_10;

BB30_6:
	setp.eq.s32	%p15, %r5, 255;
	mov.f64 	%fd239, 0d0000000000000000;
	@%p15 bra 	BB30_10;

	setp.gt.f64	%p16, %fd4, %fd1;
	selp.f64	%fd239, %fd8, 0d0000000000000000, %p16;

BB30_10:
	mov.f64 	%fd13, %fd239;
	and.b32  	%r27, %r6, 255;
	setp.ne.s32	%p20, %r27, 255;
	setp.gt.f64	%p21, %fd5, %fd1;
	and.pred  	%p22, %p20, %p21;
	@%p22 bra 	BB30_13;
	bra.uni 	BB30_11;

BB30_13:
	setp.ne.s32	%p25, %r7, 255;
	setp.gt.f64	%p26, %fd6, %fd1;
	and.pred  	%p27, %p26, %p25;
	@!%p27 bra 	BB30_15;
	bra.uni 	BB30_14;

BB30_14:
	add.f64 	%fd93, %fd240, %fd10;
	mul.f64 	%fd240, %fd93, 0d3FE0000000000000;
	bra.uni 	BB30_15;

BB30_11:
	setp.eq.s32	%p23, %r7, 255;
	mov.f64 	%fd240, 0d0000000000000000;
	@%p23 bra 	BB30_15;

	setp.gt.f64	%p24, %fd6, %fd1;
	selp.f64	%fd240, %fd10, 0d0000000000000000, %p24;

BB30_15:
	mov.f64 	%fd16, %fd240;
	cvta.to.global.u64 	%rd48, %rd13;
	add.s64 	%rd6, %rd48, %rd18;
	ld.global.f64 	%fd17, [%rd6];
	cvta.to.global.u64 	%rd50, %rd8;
	ldu.global.u32 	%r8, [%rd50];
	setp.gt.s32	%p28, %r8, 99;
	ld.const.u32 	%r28, [dc_unitsOption];
	setp.eq.s32	%p29, %r28, 1;
	and.pred  	%p30, %p28, %p29;
	selp.f64	%fd18, 0d3FD381D7DBF487FD, 0d3FF0000000000000, %p30;
	mul.f64 	%fd94, %fd16, %fd16;
	fma.rn.f64 	%fd19, %fd13, %fd13, %fd94;
	sqrt.rn.f64 	%fd95, %fd19;
	mul.f64 	%fd20, %fd95, %fd18;
	mul.f64 	%fd21, %fd2, %fd18;
	setp.gt.s32	%p31, %r8, 108;
	@%p31 bra 	BB30_53;

	setp.gt.s32	%p51, %r8, 101;
	@%p51 bra 	BB30_31;

	setp.gt.s32	%p61, %r8, 2;
	@%p61 bra 	BB30_21;

	setp.eq.s32	%p67, %r8, 0;
	mov.f64 	%fd238, %fd21;
	@%p67 bra 	BB30_194;

	setp.eq.s32	%p68, %r8, 1;
	mov.f64 	%fd238, %fd13;
	@%p68 bra 	BB30_194;

	setp.eq.s32	%p69, %r8, 2;
	mov.f64 	%fd238, %fd16;
	@%p69 bra 	BB30_194;
	bra.uni 	BB30_90;

BB30_53:
	setp.gt.s32	%p32, %r8, 126;
	@%p32 bra 	BB30_79;

	setp.gt.s32	%p42, %r8, 120;
	@%p42 bra 	BB30_62;

	add.s32 	%r29, %r8, -110;
	setp.lt.u32	%p48, %r29, 2;
	@%p48 bra 	BB30_127;

	add.s32 	%r30, %r8, -112;
	setp.lt.u32	%p49, %r30, 2;
	@%p49 bra 	BB30_121;
	bra.uni 	BB30_57;

BB30_121:
	add.f64 	%fd135, %fd20, 0d3FE0000000000000;
	setp.lt.f64	%p168, %fd21, 0d3FD0000000000000;
	selp.f64	%fd136, 0d3FE0000000000000, 0d3FF0000000000000, %p168;
	fma.rn.f64 	%fd43, %fd21, %fd135, %fd136;
	setp.eq.s32	%p169, %r8, 112;
	@%p169 bra 	BB30_126;
	bra.uni 	BB30_122;

BB30_126:
	mul.f64 	%fd140, %fd18, %fd18;
	div.rn.f64 	%fd238, %fd43, %fd140;
	bra.uni 	BB30_194;

BB30_31:
	setp.gt.s32	%p52, %r8, 104;
	@%p52 bra 	BB30_38;

	setp.eq.s32	%p58, %r8, 102;
	@%p58 bra 	BB30_174;

	setp.eq.s32	%p59, %r8, 103;
	@%p59 bra 	BB30_167;
	bra.uni 	BB30_34;

BB30_167:
	mov.f64 	%fd183, 0d0000000000000000;
	setp.le.f64	%p266, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd183;
	@%p266 bra 	BB30_194;

	setp.gt.f64	%p267, %fd20, 0d4003333333333333;
	mov.f64 	%fd184, 0d401C000000000000;
	mov.f64 	%fd238, %fd184;
	@%p267 bra 	BB30_194;

	mul.f64 	%fd66, %fd21, %fd20;
	setp.gt.f64	%p268, %fd66, 0d4000000000000000;
	mov.f64 	%fd185, 0d4018000000000000;
	mov.f64 	%fd238, %fd185;
	@%p268 bra 	BB30_194;

	setp.gt.f64	%p269, %fd20, 0d4000000000000000;
	setp.gt.f64	%p270, %fd66, 0d3FF0000000000000;
	or.pred  	%p271, %p269, %p270;
	mov.f64 	%fd186, 0d4014000000000000;
	mov.f64 	%fd238, %fd186;
	@%p271 bra 	BB30_194;

	setp.gt.f64	%p272, %fd21, 0d4000000000000000;
	mov.f64 	%fd187, 0d4010000000000000;
	mov.f64 	%fd238, %fd187;
	@%p272 bra 	BB30_194;

	setp.gt.f64	%p273, %fd21, 0d3FF0000000000000;
	mov.f64 	%fd188, 0d4008000000000000;
	mov.f64 	%fd238, %fd188;
	@%p273 bra 	BB30_194;

	fma.rn.f64 	%fd189, %fd21, 0d400A666666666666, %fd20;
	setp.gt.f64	%p274, %fd189, 0d40051EB851EB851F;
	selp.f64	%fd238, 0d4000000000000000, 0d3FF0000000000000, %p274;
	bra.uni 	BB30_194;

BB30_79:
	setp.gt.s32	%p33, %r8, 130;
	@%p33 bra 	BB30_87;

	setp.eq.s32	%p39, %r8, 127;
	@%p39 bra 	BB30_110;

	setp.eq.s32	%p40, %r8, 128;
	@%p40 bra 	BB30_105;
	bra.uni 	BB30_82;

BB30_105:
	mov.f64 	%fd109, 0d0000000000000000;
	setp.le.f64	%p108, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd109;
	@%p108 bra 	BB30_194;

	setp.gt.f64	%p109, %fd20, 0d4004000000000000;
	setp.gt.f64	%p110, %fd21, 0d4004000000000000;
	or.pred  	%p111, %p109, %p110;
	mul.f64 	%fd32, %fd21, %fd20;
	setp.gt.f64	%p112, %fd32, 0d4004000000000000;
	or.pred  	%p113, %p111, %p112;
	mov.f64 	%fd110, 0d4014000000000000;
	mov.f64 	%fd238, %fd110;
	@%p113 bra 	BB30_194;

	setp.gt.f64	%p114, %fd20, 0d4000000000000000;
	setp.gt.f64	%p115, %fd21, 0d4000000000000000;
	or.pred  	%p116, %p114, %p115;
	setp.gt.f64	%p117, %fd32, 0d3FF0000000000000;
	or.pred  	%p118, %p116, %p117;
	mov.f64 	%fd111, 0d4010000000000000;
	mov.f64 	%fd238, %fd111;
	@%p118 bra 	BB30_194;

	fma.rn.f64 	%fd113, %fd21, 0d4010000000000000, %fd20;
	setp.gt.f64	%p119, %fd113, 0d400999999999999A;
	mov.f64 	%fd112, 0d4008000000000000;
	mov.f64 	%fd238, %fd112;
	@%p119 bra 	BB30_194;

	setp.gt.f64	%p120, %fd20, 0d3FE0000000000000;
	setp.gt.f64	%p121, %fd21, 0d3FD3333333333333;
	or.pred  	%p122, %p120, %p121;
	selp.f64	%fd238, 0d4000000000000000, 0d3FF0000000000000, %p122;
	bra.uni 	BB30_194;

BB30_21:
	setp.gt.s32	%p62, %r8, 22;
	@%p62 bra 	BB30_25;

	setp.eq.s32	%p65, %r8, 3;
	@%p65 bra 	BB30_193;
	bra.uni 	BB30_23;

BB30_193:
	mul.f64 	%fd238, %fd21, %fd20;
	bra.uni 	BB30_194;

BB30_62:
	setp.gt.s32	%p43, %r8, 122;
	@%p43 bra 	BB30_70;

	setp.eq.s32	%p46, %r8, 121;
	@%p46 bra 	BB30_116;
	bra.uni 	BB30_64;

BB30_116:
	mov.f64 	%fd131, 0d0000000000000000;
	setp.le.f64	%p163, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd131;
	@%p163 bra 	BB30_194;

	mul.f64 	%fd41, %fd21, %fd20;
	setp.lt.f64	%p164, %fd41, 0d3FC999999999999A;
	mov.f64 	%fd238, 0d3FF0000000000000;
	@%p164 bra 	BB30_194;

	setp.lt.f64	%p165, %fd41, 0d3FD999999999999A;
	mov.f64 	%fd238, 0d4000000000000000;
	@%p165 bra 	BB30_194;

	setp.lt.f64	%p166, %fd41, 0d3FE3333333333333;
	mov.f64 	%fd238, 0d4008000000000000;
	@%p166 bra 	BB30_194;

	setp.lt.f64	%p167, %fd41, 0d3FEAE147AE147AE1;
	selp.f64	%fd238, 0d4010000000000000, 0d4014000000000000, %p167;
	bra.uni 	BB30_194;

BB30_38:
	setp.gt.s32	%p53, %r8, 106;
	@%p53 bra 	BB30_45;

	setp.eq.s32	%p56, %r8, 105;
	@%p56 bra 	BB30_161;
	bra.uni 	BB30_40;

BB30_161:
	mov.f64 	%fd174, 0d0000000000000000;
	setp.le.f64	%p249, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd174;
	@%p249 bra 	BB30_194;

	setp.le.f64	%p250, %fd20, 0d3FF8000000000000;
	setp.le.f64	%p251, %fd21, 0d3FD6666666666666;
	and.pred  	%p252, %p251, %p250;
	mov.f64 	%fd175, 0d4000000000000000;
	mov.f64 	%fd238, %fd175;
	@!%p252 bra 	BB30_194;
	bra.uni 	BB30_163;

BB30_163:
	mul.f64 	%fd176, %fd21, %fd20;
	setp.le.f64	%p253, %fd176, 0d3FD6666666666666;
	selp.f64	%fd238, 0d3FF0000000000000, 0d4000000000000000, %p253;
	bra.uni 	BB30_194;

BB30_87:
	setp.gt.s32	%p34, %r8, 132;
	@%p34 bra 	BB30_91;

	setp.eq.s32	%p37, %r8, 131;
	@%p37 bra 	BB30_101;
	bra.uni 	BB30_89;

BB30_101:
	cvta.to.global.u64 	%rd53, %rd9;
	ldu.global.f64 	%fd104, [%rd53];
	mov.f64 	%fd103, 0d0000000000000000;
	setp.le.f64	%p84, %fd21, %fd104;
	mov.f64 	%fd238, %fd103;
	@%p84 bra 	BB30_194;

	mul.f64 	%fd27, %fd21, %fd20;
	setp.gt.f64	%p85, %fd27, 0d3FF3333333333333;
	setp.gt.f64	%p86, %fd21, 0d3FF3333333333333;
	or.pred  	%p87, %p85, %p86;
	setp.gt.f64	%p88, %fd20, 0d4008000000000000;
	or.pred  	%p89, %p87, %p88;
	mov.f64 	%fd238, 0d4010000000000000;
	@%p89 bra 	BB30_194;

	setp.gt.f64	%p90, %fd27, 0d3FE999999999999A;
	mov.f64 	%fd238, 0d4008000000000000;
	@%p90 bra 	BB30_194;

	setp.gt.f64	%p91, %fd27, 0d3FE3333333333333;
	selp.f64	%fd238, 0d4000000000000000, 0d3FF0000000000000, %p91;
	bra.uni 	BB30_194;

BB30_25:
	add.s32 	%r31, %r8, -23;
	setp.lt.u32	%p63, %r31, 2;
	@%p63 bra 	BB30_179;
	bra.uni 	BB30_26;

BB30_179:
	ld.const.f64 	%fd199, [dc_nUnitsFactor];
	ld.const.u64 	%rd58, [dc_mnu];
	cvta.to.global.u64 	%rd59, %rd58;
	shl.b64 	%rd60, %rd4, 3;
	add.s64 	%rd61, %rd59, %rd60;
	add.s64 	%rd63, %rd59, %rd18;
	ld.global.f64 	%fd200, [%rd63];
	ld.global.f64 	%fd201, [%rd61];
	add.f64 	%fd202, %fd201, %fd200;
	ld.const.u64 	%rd64, [dc_mnv];
	cvta.to.global.u64 	%rd65, %rd64;
	shl.b64 	%rd66, %rd5, 3;
	add.s64 	%rd67, %rd65, %rd66;
	ld.global.f64 	%fd203, [%rd67];
	add.f64 	%fd204, %fd202, %fd203;
	add.s64 	%rd68, %rd65, %rd18;
	ld.global.f64 	%fd205, [%rd68];
	add.f64 	%fd206, %fd204, %fd205;
	mul.f64 	%fd207, %fd199, %fd206;
	mul.f64 	%fd208, %fd207, 0d3FD0000000000000;
	ld.const.f64 	%fd209, [dc_g];
	ld.const.f64 	%fd210, [dc_rho];
	mul.f64 	%fd211, %fd210, %fd209;
	mul.f64 	%fd212, %fd211, %fd208;
	mul.f64 	%fd213, %fd208, %fd212;
	mul.f64 	%fd71, %fd19, %fd213;
	mov.f64 	%fd214, 0d3FD5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd214;
	}
	bfe.u32 	%r35, %r9, 20, 11;
	add.s32 	%r36, %r35, -1012;
	mov.u64 	%rd69, 4599676419421066581;
	shl.b64 	%rd7, %rd69, %r36;
	setp.eq.s64	%p286, %rd7, -9223372036854775808;
	abs.f64 	%fd72, %fd21;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd72;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd214;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd234, [retval0+0];
	
	//{
	}// Callseq End 7
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd21;
	}
	setp.lt.s32	%p287, %r10, 0;
	and.pred  	%p3, %p287, %p286;
	@!%p3 bra 	BB30_181;
	bra.uni 	BB30_180;

BB30_180:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd234;
	}
	xor.b32  	%r38, %r37, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd234;
	}
	mov.b64 	%fd234, {%r39, %r38};

BB30_181:
	mov.f64 	%fd233, %fd234;
	setp.eq.f64	%p288, %fd21, 0d0000000000000000;
	@%p288 bra 	BB30_184;
	bra.uni 	BB30_182;

BB30_184:
	selp.b32	%r40, %r10, 0, %p286;
	or.b32  	%r41, %r40, 2146435072;
	setp.lt.s32	%p292, %r9, 0;
	selp.b32	%r42, %r41, %r40, %p292;
	mov.u32 	%r43, 0;
	mov.b64 	%fd233, {%r43, %r42};
	bra.uni 	BB30_185;

BB30_70:
	setp.eq.s32	%p44, %r8, 123;
	@%p44 bra 	BB30_113;
	bra.uni 	BB30_71;

BB30_113:
	mov.f64 	%fd125, 0d0000000000000000;
	setp.le.f64	%p143, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd125;
	@%p143 bra 	BB30_194;

	mul.f64 	%fd37, %fd21, %fd20;
	setp.lt.f64	%p144, %fd37, 0d3FD999999999999A;
	setp.lt.f64	%p145, %fd21, 0d3FD999999999999A;
	and.pred  	%p146, %p144, %p145;
	mov.f64 	%fd126, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd126;
	@%p146 bra 	BB30_194;

	setp.lt.f64	%p147, %fd37, 0d3FE999999999999A;
	setp.lt.f64	%p148, %fd21, 0d3FE999999999999A;
	and.pred  	%p149, %p147, %p148;
	selp.f64	%fd238, 0d4000000000000000, 0d4008000000000000, %p149;
	bra.uni 	BB30_194;

BB30_45:
	setp.eq.s32	%p54, %r8, 107;
	@%p54 bra 	BB30_154;
	bra.uni 	BB30_46;

BB30_154:
	mov.f64 	%fd164, 0d0000000000000000;
	setp.le.f64	%p234, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd164;
	@%p234 bra 	BB30_194;

	setp.gtu.f64	%p235, %fd20, 0d4000000000000000;
	@%p235 bra 	BB30_157;

	fma.rn.f64 	%fd166, %fd21, 0d401AAAAB8A5CE5B4, %fd20;
	mov.f64 	%fd165, 0d3FF0000000000000;
	setp.le.f64	%p236, %fd166, 0d4008000000000000;
	mov.f64 	%fd238, %fd165;
	@%p236 bra 	BB30_194;

BB30_157:
	@%p235 bra 	BB30_159;

	fma.rn.f64 	%fd168, %fd21, 0d400AAAA8EB463498, %fd20;
	mov.f64 	%fd167, 0d4000000000000000;
	setp.le.f64	%p238, %fd168, 0d4005555714B9CB68;
	mov.f64 	%fd238, %fd167;
	@%p238 bra 	BB30_194;

BB30_159:
	setp.le.f64	%p239, %fd21, 0d4000000000000000;
	setp.le.f64	%p240, %fd20, 0d4000000000000000;
	and.pred  	%p241, %p240, %p239;
	mov.f64 	%fd169, 0d4010000000000000;
	mov.f64 	%fd238, %fd169;
	@!%p241 bra 	BB30_194;
	bra.uni 	BB30_160;

BB30_160:
	mul.f64 	%fd170, %fd21, %fd20;
	setp.le.f64	%p242, %fd170, 0d3FF0000000000000;
	selp.f64	%fd238, 0d4008000000000000, 0d4010000000000000, %p242;
	bra.uni 	BB30_194;

BB30_91:
	setp.eq.s32	%p35, %r8, 133;
	@%p35 bra 	BB30_97;
	bra.uni 	BB30_92;

BB30_97:
	cvta.to.global.u64 	%rd51, %rd9;
	ldu.global.f64 	%fd99, [%rd51];
	setp.gtu.f64	%p76, %fd21, %fd99;
	selp.f64	%fd238, 0d4010000000000000, 0d0000000000000000, %p76;
	bra.uni 	BB30_194;

BB30_127:
	ldu.global.u32 	%r33, [%rd50+4];
	mov.f64 	%fd227, 0d0000000000000000;
	setp.eq.s32	%p174, %r33, 1;
	@%p174 bra 	BB30_145;
	bra.uni 	BB30_128;

BB30_145:
	add.f64 	%fd149, %fd20, 0d3FF8000000000000;
	mul.f64 	%fd227, %fd21, %fd149;
	bra.uni 	BB30_146;

BB30_174:
	mov.f64 	%fd190, 0d0000000000000000;
	setp.le.f64	%p275, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd190;
	@%p275 bra 	BB30_194;

	setp.gt.f64	%p276, %fd20, 0d4000000000000000;
	mov.f64 	%fd191, 0d4014000000000000;
	mov.f64 	%fd238, %fd191;
	@%p276 bra 	BB30_194;

	mul.f64 	%fd193, %fd21, %fd20;
	setp.gt.f64	%p277, %fd193, 0d3FF0000000000000;
	mov.f64 	%fd192, 0d4010000000000000;
	mov.f64 	%fd238, %fd192;
	@%p277 bra 	BB30_194;

	setp.gt.f64	%p278, %fd21, 0d3FF0000000000000;
	mov.f64 	%fd194, 0d4008000000000000;
	mov.f64 	%fd238, %fd194;
	@%p278 bra 	BB30_194;

	fma.rn.f64 	%fd195, %fd21, 0d400A666666666666, %fd20;
	setp.gt.f64	%p279, %fd195, 0d40051EB851EB851F;
	selp.f64	%fd238, 0d4000000000000000, 0d3FF0000000000000, %p279;
	bra.uni 	BB30_194;

BB30_34:
	setp.eq.s32	%p60, %r8, 104;
	@%p60 bra 	BB30_35;
	bra.uni 	BB30_90;

BB30_35:
	mov.f64 	%fd177, 0d0000000000000000;
	setp.le.f64	%p254, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd177;
	@%p254 bra 	BB30_194;

	setp.le.f64	%p255, %fd20, 0d3FD851EB851EB852;
	setp.le.f64	%p256, %fd21, 0d3FD3333333333333;
	and.pred  	%p257, %p256, %p255;
	mov.f64 	%fd178, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd178;
	@%p257 bra 	BB30_194;

	setp.le.f64	%p258, %fd20, 0d3FE999999999999A;
	setp.le.f64	%p259, %fd21, 0d3FE3333333333333;
	and.pred  	%p260, %p259, %p258;
	@!%p260 bra 	BB30_165;
	bra.uni 	BB30_164;

BB30_164:
	fma.rn.f64 	%fd180, %fd20, 0d3FE47AE147AE147B, %fd21;
	mov.f64 	%fd179, 0d4000000000000000;
	setp.le.f64	%p261, %fd180, 0d3FEA3D70A3D70A3D;
	mov.f64 	%fd238, %fd179;
	@%p261 bra 	BB30_194;

BB30_165:
	setp.le.f64	%p262, %fd20, 0d3FF8000000000000;
	setp.le.f64	%p263, %fd21, 0d3FF3333333333333;
	and.pred  	%p264, %p263, %p262;
	mov.f64 	%fd181, 0d4010000000000000;
	mov.f64 	%fd238, %fd181;
	@!%p264 bra 	BB30_194;
	bra.uni 	BB30_166;

BB30_166:
	fma.rn.f64 	%fd182, %fd20, 0d3FE6147AE147AE14, %fd21;
	setp.le.f64	%p265, %fd182, 0d3FF6147AE147AE14;
	selp.f64	%fd238, 0d4008000000000000, 0d4010000000000000, %p265;
	bra.uni 	BB30_194;

BB30_110:
	ldu.global.u32 	%r32, [%rd50+4];
	mov.f64 	%fd114, 0d0000000000000000;
	setp.ne.s32	%p123, %r32, 100;
	mov.f64 	%fd238, %fd114;
	@%p123 bra 	BB30_194;

	mov.f64 	%fd115, 0d3FF0000000000000;
	setp.le.f64	%p124, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd115;
	@%p124 bra 	BB30_194;

	mul.f64 	%fd116, %fd20, %fd20;
	div.rn.f64 	%fd117, %fd116, 0d40339EB851EB851F;
	add.f64 	%fd118, %fd21, %fd117;
	setp.lt.f64	%p125, %fd118, 0d3FD3333333333333;
	selp.f64	%fd238, 0d4000000000000000, 0d4008000000000000, %p125;
	bra.uni 	BB30_194;

BB30_82:
	setp.eq.s32	%p41, %r8, 129;
	@%p41 bra 	BB30_83;
	bra.uni 	BB30_90;

BB30_83:
	mov.f64 	%fd107, 0d0000000000000000;
	setp.le.f64	%p92, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd107;
	@%p92 bra 	BB30_194;

	setp.lt.f64	%p93, %fd21, 0d3FE0000000000000;
	setp.lt.f64	%p94, %fd20, 0d3FF8000000000000;
	and.pred  	%p95, %p93, %p94;
	mul.f64 	%fd29, %fd21, %fd20;
	setp.lt.f64	%p96, %fd29, 0d3FE3333333333333;
	and.pred  	%p97, %p95, %p96;
	mov.f64 	%fd108, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd108;
	@%p97 bra 	BB30_194;

	setp.lt.f64	%p98, %fd21, 0d4000000000000000;
	setp.lt.f64	%p99, %fd20, 0d4000000000000000;
	and.pred  	%p100, %p98, %p99;
	setp.lt.f64	%p101, %fd29, 0d3FE999999999999A;
	and.pred  	%p102, %p100, %p101;
	setp.geu.f64	%p103, %fd21, 0d4000000000000000;
	setp.geu.f64	%p104, %fd20, 0d4000000000000000;
	or.pred  	%p105, %p103, %p104;
	or.pred  	%p106, %p102, %p105;
	selp.f64	%fd238, 0d4000000000000000, 0d4010000000000000, %p102;
	@%p106 bra 	BB30_194;

	setp.lt.f64	%p107, %fd29, 0d3FF3333333333333;
	selp.f64	%fd238, 0d4008000000000000, 0d4010000000000000, %p107;
	bra.uni 	BB30_194;

BB30_23:
	setp.eq.s32	%p66, %r8, 9;
	@%p66 bra 	BB30_24;
	bra.uni 	BB30_90;

BB30_24:
	add.f64 	%fd221, %fd3, %fd21;
	ld.const.f64 	%fd222, [dc_g];
	add.f64 	%fd223, %fd222, %fd222;
	div.rn.f64 	%fd224, %fd19, %fd223;
	add.f64 	%fd238, %fd221, %fd224;
	bra.uni 	BB30_194;

BB30_64:
	setp.eq.s32	%p47, %r8, 122;
	@%p47 bra 	BB30_65;
	bra.uni 	BB30_90;

BB30_65:
	mov.f64 	%fd127, 0d0000000000000000;
	setp.le.f64	%p150, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd127;
	@%p150 bra 	BB30_194;

	mul.f64 	%fd39, %fd21, %fd20;
	setp.lt.f64	%p151, %fd39, 0d3FC999999999999A;
	setp.lt.f64	%p152, %fd21, 0d3FC999999999999A;
	and.pred  	%p153, %p151, %p152;
	mov.f64 	%fd128, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd128;
	@%p153 bra 	BB30_194;

	setp.lt.f64	%p154, %fd39, 0d3FD999999999999A;
	setp.lt.f64	%p155, %fd21, 0d3FD999999999999A;
	and.pred  	%p156, %p154, %p155;
	mov.f64 	%fd129, 0d4000000000000000;
	mov.f64 	%fd238, %fd129;
	@%p156 bra 	BB30_194;

	setp.lt.f64	%p157, %fd39, 0d3FE3333333333333;
	setp.lt.f64	%p158, %fd21, 0d3FE3333333333333;
	and.pred  	%p159, %p157, %p158;
	mov.f64 	%fd130, 0d4008000000000000;
	mov.f64 	%fd238, %fd130;
	@%p159 bra 	BB30_194;

	setp.lt.f64	%p160, %fd39, 0d3FEAE147AE147AE1;
	setp.lt.f64	%p161, %fd21, 0d3FEAE147AE147AE1;
	and.pred  	%p162, %p160, %p161;
	selp.f64	%fd238, 0d4010000000000000, 0d4014000000000000, %p162;
	bra.uni 	BB30_194;

BB30_40:
	setp.eq.s32	%p57, %r8, 106;
	@%p57 bra 	BB30_41;
	bra.uni 	BB30_90;

BB30_41:
	mov.f64 	%fd171, 0d0000000000000000;
	setp.le.f64	%p243, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd171;
	@%p243 bra 	BB30_194;

	setp.le.f64	%p244, %fd21, 0d3FD999999999999A;
	mul.f64 	%fd62, %fd21, %fd20;
	setp.le.f64	%p245, %fd62, 0d3FD999999999999A;
	and.pred  	%p246, %p244, %p245;
	mov.f64 	%fd172, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd172;
	@%p246 bra 	BB30_194;

	setp.gtu.f64	%p247, %fd21, 0d3FE999999999999A;
	mov.f64 	%fd238, 0d4008000000000000;
	@%p247 bra 	BB30_194;

	setp.le.f64	%p248, %fd62, 0d3FE999999999999A;
	selp.f64	%fd238, 0d4000000000000000, 0d4008000000000000, %p248;
	bra.uni 	BB30_194;

BB30_89:
	setp.eq.s32	%p38, %r8, 132;
	@%p38 bra 	BB30_98;
	bra.uni 	BB30_90;

BB30_98:
	cvta.to.global.u64 	%rd52, %rd9;
	ldu.global.f64 	%fd101, [%rd52];
	mov.f64 	%fd100, 0d0000000000000000;
	setp.le.f64	%p77, %fd21, %fd101;
	mov.f64 	%fd238, %fd100;
	@%p77 bra 	BB30_194;

	mul.f64 	%fd25, %fd21, %fd20;
	setp.gt.f64	%p78, %fd25, 0d3FE3333333333333;
	setp.gt.f64	%p79, %fd21, 0d3FE0000000000000;
	or.pred  	%p80, %p78, %p79;
	setp.gt.f64	%p81, %fd20, 0d4008000000000000;
	or.pred  	%p82, %p80, %p81;
	mov.f64 	%fd238, 0d4010000000000000;
	@%p82 bra 	BB30_194;

	setp.gt.f64	%p83, %fd25, 0d3FD999999999999A;
	selp.f64	%fd238, 0d4008000000000000, 0d3FF0000000000000, %p83;
	bra.uni 	BB30_194;

BB30_71:
	setp.eq.s32	%p45, %r8, 124;
	@%p45 bra 	BB30_72;
	bra.uni 	BB30_90;

BB30_72:
	mov.f64 	%fd119, 0d0000000000000000;
	setp.le.f64	%p126, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd119;
	@%p126 bra 	BB30_194;

	setp.ge.f64	%p127, %fd20, 0d4010000000000000;
	setp.ge.f64	%p128, %fd21, 0d4010000000000000;
	or.pred  	%p129, %p128, %p127;
	mul.f64 	%fd35, %fd21, %fd20;
	setp.ge.f64	%p130, %fd35, 0d4010000000000000;
	or.pred  	%p131, %p129, %p130;
	mov.f64 	%fd120, 0d4018000000000000;
	mov.f64 	%fd238, %fd120;
	@%p131 bra 	BB30_194;

	setp.ge.f64	%p132, %fd20, 0d4000000000000000;
	setp.ge.f64	%p133, %fd21, 0d4000000000000000;
	or.pred  	%p134, %p133, %p132;
	setp.ge.f64	%p135, %fd35, 0d3FF0000000000000;
	or.pred  	%p136, %p134, %p135;
	mov.f64 	%fd121, 0d4014000000000000;
	mov.f64 	%fd238, %fd121;
	@%p136 bra 	BB30_194;

	setp.ge.f64	%p137, %fd21, 0d3FF3333333333333;
	setp.ge.f64	%p138, %fd35, 0d3FE3333333333333;
	or.pred  	%p139, %p137, %p138;
	mov.f64 	%fd122, 0d4010000000000000;
	mov.f64 	%fd238, %fd122;
	@%p139 bra 	BB30_194;

	mov.f64 	%fd123, 0d4008000000000000;
	setp.ge.f64	%p140, %fd21, 0d3FE0000000000000;
	mov.f64 	%fd238, %fd123;
	@%p140 bra 	BB30_194;

	mov.f64 	%fd124, 0d4000000000000000;
	setp.ge.f64	%p141, %fd21, 0d3FD3333333333333;
	mov.f64 	%fd238, %fd124;
	@%p141 bra 	BB30_194;

	setp.ge.f64	%p142, %fd35, 0d3FD3333333333333;
	selp.f64	%fd238, 0d4000000000000000, 0d3FF0000000000000, %p142;
	bra.uni 	BB30_194;

BB30_46:
	setp.eq.s32	%p55, %r8, 108;
	@%p55 bra 	BB30_47;
	bra.uni 	BB30_90;

BB30_47:
	mov.f64 	%fd158, 0d0000000000000000;
	setp.le.f64	%p219, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd158;
	@%p219 bra 	BB30_194;

	setp.le.f64	%p220, %fd21, 0d3FD3333333333333;
	setp.le.f64	%p221, %fd20, 0d3FE0000000000000;
	and.pred  	%p222, %p221, %p220;
	mov.f64 	%fd159, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd159;
	@%p222 bra 	BB30_194;

	setp.gtu.f64	%p223, %fd20, 0d4000000000000000;
	@%p223 bra 	BB30_51;

	fma.rn.f64 	%fd161, %fd21, 0d4010000000000000, %fd20;
	mov.f64 	%fd160, 0d4000000000000000;
	setp.le.f64	%p224, %fd161, 0d400999999999999A;
	mov.f64 	%fd238, %fd160;
	@%p224 bra 	BB30_194;

BB30_51:
	setp.le.f64	%p225, %fd21, 0d4000000000000000;
	setp.le.f64	%p226, %fd20, 0d4000000000000000;
	and.pred  	%p227, %p226, %p225;
	mul.f64 	%fd59, %fd21, %fd20;
	setp.le.f64	%p228, %fd59, 0d3FF0000000000000;
	and.pred  	%p229, %p227, %p228;
	mov.f64 	%fd162, 0d4008000000000000;
	mov.f64 	%fd238, %fd162;
	@%p229 bra 	BB30_194;

	setp.le.f64	%p230, %fd21, 0d4004000000000000;
	setp.le.f64	%p231, %fd20, 0d4004000000000000;
	and.pred  	%p232, %p231, %p230;
	mov.f64 	%fd238, 0d4014000000000000;
	@!%p232 bra 	BB30_194;
	bra.uni 	BB30_153;

BB30_153:
	setp.le.f64	%p233, %fd59, 0d4004000000000000;
	selp.f64	%fd238, 0d4010000000000000, 0d4014000000000000, %p233;
	bra.uni 	BB30_194;

BB30_92:
	setp.ne.s32	%p36, %r8, 141;
	@%p36 bra 	BB30_90;

	mov.f64 	%fd96, 0d0000000000000000;
	setp.le.f64	%p70, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd96;
	@%p70 bra 	BB30_194;

	setp.lt.f64	%p71, %fd21, 0d3FE0000000000000;
	mul.f64 	%fd22, %fd21, %fd20;
	setp.lt.f64	%p72, %fd22, 0d3FE0000000000000;
	and.pred  	%p73, %p71, %p72;
	mov.f64 	%fd97, 0d3FF0000000000000;
	mov.f64 	%fd238, %fd97;
	@%p73 bra 	BB30_194;

	mov.f64 	%fd98, 0d4008000000000000;
	setp.geu.f64	%p74, %fd21, 0d3FF8000000000000;
	mov.f64 	%fd238, %fd98;
	@%p74 bra 	BB30_194;

	setp.lt.f64	%p75, %fd22, 0d3FF8000000000000;
	selp.f64	%fd238, 0d4000000000000000, 0d4008000000000000, %p75;
	bra.uni 	BB30_194;

BB30_57:
	setp.eq.s32	%p50, %r8, 109;
	@%p50 bra 	BB30_58;
	bra.uni 	BB30_90;

BB30_58:
	mov.f64 	%fd154, 0d4000000000000000;
	setp.le.f64	%p204, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd154;
	@%p204 bra 	BB30_194;

	setp.le.f64	%p205, %fd21, 0d3FF0000000000000;
	setp.le.f64	%p206, %fd20, 0d3FF0000000000000;
	and.pred  	%p207, %p206, %p205;
	mul.f64 	%fd57, %fd21, %fd20;
	setp.le.f64	%p208, %fd57, 0d3FD3333333333333;
	and.pred  	%p209, %p207, %p208;
	mov.f64 	%fd237, %fd154;
	mov.f64 	%fd238, %fd237;
	@%p209 bra 	BB30_194;

	setp.le.f64	%p210, %fd21, 0d3FF8000000000000;
	setp.le.f64	%p211, %fd20, 0d3FF8000000000000;
	and.pred  	%p212, %p211, %p210;
	setp.le.f64	%p213, %fd57, 0d3FF8000000000000;
	and.pred  	%p214, %p212, %p213;
	mov.f64 	%fd156, 0d4008000000000000;
	mov.f64 	%fd238, %fd156;
	@%p214 bra 	BB30_194;

	setp.le.f64	%p215, %fd21, 0d4008000000000000;
	setp.le.f64	%p216, %fd20, 0d4008000000000000;
	and.pred  	%p217, %p216, %p215;
	mov.f64 	%fd238, 0d4014000000000000;
	@!%p217 bra 	BB30_194;
	bra.uni 	BB30_152;

BB30_152:
	setp.le.f64	%p218, %fd57, 0d4008000000000000;
	selp.f64	%fd238, 0d4010000000000000, 0d4014000000000000, %p218;
	bra.uni 	BB30_194;

BB30_122:
	mov.f64 	%fd238, 0d0000000000000000;
	setp.le.f64	%p170, %fd43, 0d0000000000000000;
	@%p170 bra 	BB30_194;

	mov.f64 	%fd238, 0d3FF0000000000000;
	setp.le.f64	%p171, %fd43, 0d3FE8000000000000;
	@%p171 bra 	BB30_194;

	mov.f64 	%fd238, 0d4000000000000000;
	setp.le.f64	%p172, %fd43, 0d3FF4000000000000;
	@%p172 bra 	BB30_194;

	setp.gtu.f64	%p173, %fd43, 0d4000000000000000;
	selp.f64	%fd238, 0d4010000000000000, 0d4008000000000000, %p173;
	bra.uni 	BB30_194;

BB30_128:
	setp.ne.s32	%p175, %r33, 2;
	@%p175 bra 	BB30_146;

	cvta.to.global.u64 	%rd56, %rd9;
	ldu.global.f64 	%fd226, [%rd56];
	ldu.global.u32 	%r34, [%rd50+8];
	setp.gt.s32	%p176, %r34, 2;
	@%p176 bra 	BB30_135;

	setp.eq.s32	%p179, %r34, 1;
	@%p179 bra 	BB30_141;
	bra.uni 	BB30_131;

BB30_141:
	setp.gt.f64	%p194, %fd21, 0d3FB999999999999A;
	setp.gt.f64	%p195, %fd20, 0d4000000000000000;
	and.pred  	%p196, %p194, %p195;
	mov.f64 	%fd226, 0d3FE0000000000000;
	@%p196 bra 	BB30_144;

	mov.f64 	%fd226, 0d0000000000000000;
	setp.le.f64	%p197, %fd21, 0d3FD0000000000000;
	@%p197 bra 	BB30_144;

	setp.gtu.f64	%p198, %fd21, 0d3FE8000000000000;
	selp.f64	%fd226, 0d3FE0000000000000, 0d0000000000000000, %p198;
	bra.uni 	BB30_144;

BB30_26:
	setp.eq.s32	%p64, %r8, 101;
	@%p64 bra 	BB30_27;
	bra.uni 	BB30_90;

BB30_27:
	mov.f64 	%fd196, 0d0000000000000000;
	setp.le.f64	%p280, %fd21, 0d0000000000000000;
	mov.f64 	%fd238, %fd196;
	@%p280 bra 	BB30_194;

	setp.gt.f64	%p281, %fd20, 0d4000000000000000;
	setp.gt.f64	%p282, %fd21, 0d3FF0000000000000;
	or.pred  	%p283, %p281, %p282;
	mov.f64 	%fd197, 0d4008000000000000;
	mov.f64 	%fd238, %fd197;
	@%p283 bra 	BB30_194;

	fma.rn.f64 	%fd69, %fd21, 0d400AAAA8EB463498, %fd20;
	setp.lt.f64	%p284, %fd69, 0d4005555714B9CB68;
	mov.f64 	%fd238, 0d3FF0000000000000;
	@%p284 bra 	BB30_194;

	setp.gt.f64	%p285, %fd69, 0d400AAAA8EB463498;
	selp.f64	%fd238, 0d4008000000000000, 0d4000000000000000, %p285;
	bra.uni 	BB30_194;

BB30_90:
	mov.f64 	%fd238, 0dC79E17B84357691B;
	bra.uni 	BB30_194;

BB30_182:
	setp.gt.s32	%p289, %r10, -1;
	@%p289 bra 	BB30_185;

	cvt.rzi.f64.f64	%fd216, %fd214;
	setp.neu.f64	%p290, %fd216, 0d3FD5555555555555;
	selp.f64	%fd233, 0dFFF8000000000000, %fd233, %p290;

BB30_185:
	mov.f64 	%fd78, %fd233;
	add.f64 	%fd79, %fd21, 0d3FD5555555555555;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd79;
	}
	and.b32  	%r45, %r44, 2146435072;
	setp.ne.s32	%p293, %r45, 2146435072;
	mov.f64 	%fd232, %fd78;
	@%p293 bra 	BB30_192;

	setp.gtu.f64	%p294, %fd72, 0d7FF0000000000000;
	mov.f64 	%fd232, %fd79;
	@%p294 bra 	BB30_192;

	abs.f64 	%fd80, %fd214;
	setp.gtu.f64	%p295, %fd80, 0d7FF0000000000000;
	mov.f64 	%fd231, %fd79;
	mov.f64 	%fd232, %fd231;
	@%p295 bra 	BB30_192;

	setp.eq.f64	%p296, %fd80, 0d7FF0000000000000;
	@%p296 bra 	BB30_191;
	bra.uni 	BB30_189;

BB30_191:
	setp.gt.f64	%p298, %fd72, 0d3FF0000000000000;
	selp.b32	%r52, 2146435072, 0, %p298;
	xor.b32  	%r53, %r52, 2146435072;
	setp.lt.s32	%p299, %r9, 0;
	selp.b32	%r54, %r53, %r52, %p299;
	setp.eq.f64	%p300, %fd21, 0dBFF0000000000000;
	selp.b32	%r55, 1072693248, %r54, %p300;
	mov.u32 	%r56, 0;
	mov.b64 	%fd232, {%r56, %r55};
	bra.uni 	BB30_192;

BB30_135:
	setp.eq.s32	%p177, %r34, 3;
	@%p177 bra 	BB30_139;
	bra.uni 	BB30_136;

BB30_139:
	setp.gt.f64	%p185, %fd21, 0d3FB999999999999A;
	setp.gt.f64	%p186, %fd20, 0d4000000000000000;
	and.pred  	%p187, %p185, %p186;
	mov.f64 	%fd226, 0d3FF0000000000000;
	@%p187 bra 	BB30_144;

	setp.gtu.f64	%p188, %fd21, 0d3FD0000000000000;
	selp.f64	%fd226, 0d3FF0000000000000, 0d0000000000000000, %p188;
	bra.uni 	BB30_144;

BB30_131:
	setp.eq.s32	%p180, %r34, 2;
	@%p180 bra 	BB30_132;
	bra.uni 	BB30_144;

BB30_132:
	setp.gt.f64	%p189, %fd21, 0d3FB999999999999A;
	setp.gt.f64	%p190, %fd20, 0d4000000000000000;
	and.pred  	%p191, %p189, %p190;
	mov.f64 	%fd226, 0d3FF0000000000000;
	@%p191 bra 	BB30_144;

	mov.f64 	%fd226, 0d0000000000000000;
	setp.le.f64	%p192, %fd21, 0d3FD0000000000000;
	@%p192 bra 	BB30_144;

	setp.gtu.f64	%p193, %fd21, 0d3FE8000000000000;
	selp.f64	%fd226, 0d3FF0000000000000, 0d3FE0000000000000, %p193;
	bra.uni 	BB30_144;

BB30_136:
	setp.ne.s32	%p178, %r34, 4;
	@%p178 bra 	BB30_144;

	setp.gt.f64	%p181, %fd21, 0d3FB999999999999A;
	setp.gt.f64	%p182, %fd20, 0d4000000000000000;
	and.pred  	%p183, %p181, %p182;
	mov.f64 	%fd226, 0d3FF0000000000000;
	@%p183 bra 	BB30_144;

	setp.gtu.f64	%p184, %fd21, 0d3FD0000000000000;
	selp.f64	%fd226, 0d3FF0000000000000, 0d3FE0000000000000, %p184;

BB30_144:
	add.f64 	%fd148, %fd20, 0d3FE0000000000000;
	fma.rn.f64 	%fd227, %fd21, %fd148, %fd226;

BB30_146:
	setp.eq.s32	%p199, %r8, 110;
	@%p199 bra 	BB30_151;
	bra.uni 	BB30_147;

BB30_151:
	mul.f64 	%fd153, %fd18, %fd18;
	div.rn.f64 	%fd238, %fd227, %fd153;
	bra.uni 	BB30_194;

BB30_147:
	mov.f64 	%fd238, 0d0000000000000000;
	setp.le.f64	%p200, %fd227, 0d0000000000000000;
	@%p200 bra 	BB30_194;

	mov.f64 	%fd238, 0d3FF0000000000000;
	setp.le.f64	%p201, %fd227, 0d3FE8000000000000;
	@%p201 bra 	BB30_194;

	mov.f64 	%fd238, 0d4000000000000000;
	setp.le.f64	%p202, %fd227, 0d3FF4000000000000;
	@%p202 bra 	BB30_194;

	setp.gtu.f64	%p203, %fd227, 0d4004000000000000;
	selp.f64	%fd238, 0d4010000000000000, 0d4008000000000000, %p203;
	bra.uni 	BB30_194;

BB30_189:
	setp.neu.f64	%p297, %fd72, 0d7FF0000000000000;
	mov.f64 	%fd232, %fd78;
	@%p297 bra 	BB30_192;

	shr.s32 	%r46, %r9, 31;
	and.b32  	%r47, %r46, -2146435072;
	add.s32 	%r48, %r47, 2146435072;
	or.b32  	%r49, %r48, -2147483648;
	selp.b32	%r50, %r49, %r48, %p3;
	mov.u32 	%r51, 0;
	mov.b64 	%fd232, {%r51, %r50};

BB30_192:
	setp.eq.f64	%p301, %fd21, 0d3FF0000000000000;
	selp.f64	%fd218, 0d3FF0000000000000, %fd232, %p301;
	div.rn.f64 	%fd219, %fd71, %fd218;
	mul.f64 	%fd220, %fd20, %fd219;
	setp.eq.s32	%p302, %r8, 24;
	selp.f64	%fd238, %fd220, %fd219, %p302;

BB30_194:
	setp.leu.f64	%p303, %fd238, %fd17;
	@%p303 bra 	BB30_197;

	st.global.f64 	[%rd6], %fd238;
	ld.const.u8 	%rs1, [dc_switches+1];
	and.b16  	%rs2, %rs1, 64;
	setp.eq.s16	%p304, %rs2, 0;
	@%p304 bra 	BB30_197;

	cvta.to.global.u64 	%rd70, %rd14;
	add.s64 	%rd72, %rd70, %rd18;
	st.global.f64 	[%rd72], %fd88;

BB30_197:
	ret;
}

	// .globl	gpu_processVectorMaximum
.visible .entry gpu_processVectorMaximum(
	.param .u32 gpu_processVectorMaximum_param_0,
	.param .f64 gpu_processVectorMaximum_param_1,
	.param .u64 gpu_processVectorMaximum_param_2,
	.param .u64 gpu_processVectorMaximum_param_3,
	.param .u64 gpu_processVectorMaximum_param_4,
	.param .u64 gpu_processVectorMaximum_param_5,
	.param .u64 gpu_processVectorMaximum_param_6,
	.param .u64 gpu_processVectorMaximum_param_7,
	.param .u64 gpu_processVectorMaximum_param_8,
	.param .u64 gpu_processVectorMaximum_param_9
)
{
	.reg .pred 	%p<31>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<25>;
	.reg .f64 	%fd<32>;
	.reg .b64 	%rd<48>;


	ld.param.f64 	%fd17, [gpu_processVectorMaximum_param_1];
	ld.param.u64 	%rd7, [gpu_processVectorMaximum_param_2];
	ld.param.u64 	%rd13, [gpu_processVectorMaximum_param_4];
	ld.param.u64 	%rd8, [gpu_processVectorMaximum_param_5];
	ld.param.u64 	%rd9, [gpu_processVectorMaximum_param_6];
	ld.param.u64 	%rd10, [gpu_processVectorMaximum_param_7];
	ld.param.u64 	%rd11, [gpu_processVectorMaximum_param_8];
	ld.param.u64 	%rd12, [gpu_processVectorMaximum_param_9];
	cvta.to.global.u64 	%rd1, %rd13;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r1, %r8, %r9, %r10;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r11, %r12, %r13;
	setp.gt.s32	%p3, %r1, 1;
	ld.const.u32 	%r14, [dc_ny];
	add.s32 	%r15, %r14, -2;
	setp.lt.s32	%p4, %r1, %r15;
	and.pred  	%p5, %p3, %p4;
	setp.gt.s32	%p6, %r2, 1;
	and.pred  	%p7, %p5, %p6;
	ld.const.u32 	%r16, [dc_nx];
	add.s32 	%r17, %r16, -2;
	setp.lt.s32	%p8, %r2, %r17;
	and.pred  	%p9, %p7, %p8;
	@!%p9 bra 	BB31_18;
	bra.uni 	BB31_1;

BB31_1:
	ld.const.u32 	%r3, [dc_nyPadded];
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	ld.const.u64 	%rd14, [dc_a];
	cvta.to.global.u64 	%rd2, %rd14;
	cvt.u64.u32	%rd3, %r4;
	mul.wide.u32 	%rd15, %r4, 4;
	add.s64 	%rd16, %rd2, %rd15;
	ld.global.u8 	%r18, [%rd16];
	setp.eq.s32	%p10, %r18, 255;
	@%p10 bra 	BB31_18;

	shl.b64 	%rd17, %rd3, 3;
	add.s64 	%rd18, %rd1, %rd17;
	ld.const.f64 	%fd1, [dc_wetDepthThreshold];
	ld.global.f64 	%fd18, [%rd18];
	setp.leu.f64	%p11, %fd18, %fd1;
	@%p11 bra 	BB31_18;

	cvta.to.global.u64 	%rd19, %rd9;
	cvta.to.global.u64 	%rd20, %rd8;
	sub.s32 	%r19, %r4, %r3;
	mul.wide.u32 	%rd21, %r19, 4;
	add.s64 	%rd22, %rd2, %rd21;
	ld.global.u8 	%r20, [%rd22];
	add.s32 	%r21, %r3, %r4;
	mul.wide.u32 	%rd23, %r21, 4;
	add.s64 	%rd24, %rd2, %rd23;
	ld.global.u8 	%r5, [%rd24];
	add.s32 	%r22, %r4, -1;
	mul.wide.u32 	%rd25, %r22, 4;
	add.s64 	%rd26, %rd2, %rd25;
	ld.global.u8 	%r6, [%rd26];
	add.s32 	%r23, %r4, 1;
	mul.wide.u32 	%rd27, %r23, 4;
	add.s64 	%rd28, %rd2, %rd27;
	ld.global.u8 	%r7, [%rd28];
	mul.wide.u32 	%rd29, %r19, 8;
	add.s64 	%rd4, %rd1, %rd29;
	mul.wide.u32 	%rd30, %r21, 8;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.f64 	%fd2, [%rd31];
	mul.wide.u32 	%rd32, %r22, 8;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f64 	%fd3, [%rd33];
	mul.wide.u32 	%rd34, %r23, 8;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.f64 	%fd4, [%rd35];
	add.s64 	%rd36, %rd20, %rd29;
	ld.global.f64 	%fd30, [%rd36];
	add.s64 	%rd38, %rd20, %rd17;
	ld.global.f64 	%fd6, [%rd38];
	add.s64 	%rd39, %rd19, %rd32;
	ld.global.f64 	%fd31, [%rd39];
	add.s64 	%rd40, %rd19, %rd17;
	ld.global.f64 	%fd8, [%rd40];
	setp.eq.s32	%p13, %r20, 255;
	mov.pred 	%p30, 0;
	@%p13 bra 	BB31_5;

	ld.global.f64 	%fd19, [%rd4];
	setp.gt.f64	%p30, %fd19, %fd1;

BB31_5:
	@%p30 bra 	BB31_8;
	bra.uni 	BB31_6;

BB31_8:
	setp.ne.s32	%p16, %r5, 255;
	setp.gt.f64	%p17, %fd2, %fd1;
	and.pred  	%p18, %p17, %p16;
	@!%p18 bra 	BB31_10;
	bra.uni 	BB31_9;

BB31_9:
	add.f64 	%fd21, %fd30, %fd6;
	mul.f64 	%fd30, %fd21, 0d3FE0000000000000;
	bra.uni 	BB31_10;

BB31_6:
	setp.eq.s32	%p14, %r5, 255;
	mov.f64 	%fd30, 0d0000000000000000;
	@%p14 bra 	BB31_10;

	setp.gt.f64	%p15, %fd2, %fd1;
	selp.f64	%fd30, %fd6, 0d0000000000000000, %p15;

BB31_10:
	setp.ne.s32	%p19, %r6, 255;
	setp.gt.f64	%p20, %fd3, %fd1;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	BB31_13;
	bra.uni 	BB31_11;

BB31_13:
	setp.ne.s32	%p24, %r7, 255;
	setp.gt.f64	%p25, %fd4, %fd1;
	and.pred  	%p26, %p25, %p24;
	@!%p26 bra 	BB31_15;
	bra.uni 	BB31_14;

BB31_14:
	add.f64 	%fd23, %fd31, %fd8;
	mul.f64 	%fd31, %fd23, 0d3FE0000000000000;
	bra.uni 	BB31_15;

BB31_11:
	setp.eq.s32	%p22, %r7, 255;
	mov.f64 	%fd31, 0d0000000000000000;
	@%p22 bra 	BB31_15;

	setp.gt.f64	%p23, %fd4, %fd1;
	selp.f64	%fd31, %fd8, 0d0000000000000000, %p23;

BB31_15:
	cvta.to.global.u64 	%rd41, %rd10;
	add.s64 	%rd5, %rd41, %rd17;
	cvta.to.global.u64 	%rd43, %rd11;
	add.s64 	%rd6, %rd43, %rd17;
	cvta.to.global.u64 	%rd44, %rd7;
	ldu.global.u32 	%r24, [%rd44];
	setp.eq.s32	%p27, %r24, 0;
	selp.f64	%fd15, %fd30, 0d0000000000000000, %p27;
	selp.f64	%fd16, %fd31, 0d0000000000000000, %p27;
	mul.f64 	%fd24, %fd16, %fd16;
	fma.rn.f64 	%fd25, %fd15, %fd15, %fd24;
	ld.global.f64 	%fd26, [%rd5];
	ld.global.f64 	%fd27, [%rd6];
	mul.f64 	%fd28, %fd27, %fd27;
	fma.rn.f64 	%fd29, %fd26, %fd26, %fd28;
	setp.leu.f64	%p28, %fd25, %fd29;
	@%p28 bra 	BB31_18;

	st.global.f64 	[%rd5], %fd15;
	st.global.f64 	[%rd6], %fd16;
	ld.const.u8 	%rs1, [dc_switches+1];
	and.b16  	%rs2, %rs1, 64;
	setp.eq.s16	%p29, %rs2, 0;
	@%p29 bra 	BB31_18;

	cvta.to.global.u64 	%rd45, %rd12;
	add.s64 	%rd47, %rd45, %rd17;
	st.global.f64 	[%rd47], %fd17;

BB31_18:
	ret;
}

	// .globl	gpu_postProcessDepthExceedance
.visible .entry gpu_postProcessDepthExceedance(
	.param .u32 gpu_postProcessDepthExceedance_param_0,
	.param .f64 gpu_postProcessDepthExceedance_param_1,
	.param .f64 gpu_postProcessDepthExceedance_param_2,
	.param .f64 gpu_postProcessDepthExceedance_param_3,
	.param .u64 gpu_postProcessDepthExceedance_param_4,
	.param .u64 gpu_postProcessDepthExceedance_param_5,
	.param .u64 gpu_postProcessDepthExceedance_param_6
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<17>;


	ld.param.f64 	%fd1, [gpu_postProcessDepthExceedance_param_1];
	ld.param.f64 	%fd2, [gpu_postProcessDepthExceedance_param_2];
	ld.param.f64 	%fd3, [gpu_postProcessDepthExceedance_param_3];
	ld.param.u64 	%rd2, [gpu_postProcessDepthExceedance_param_4];
	ld.param.u64 	%rd3, [gpu_postProcessDepthExceedance_param_5];
	ld.param.u64 	%rd4, [gpu_postProcessDepthExceedance_param_6];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r6;
	mov.u32 	%r7, %ntid.y;
	mov.u32 	%r8, %ctaid.y;
	mov.u32 	%r9, %tid.y;
	mad.lo.s32 	%r2, %r7, %r8, %r9;
	setp.gt.s32	%p1, %r1, 1;
	ld.const.u32 	%r10, [dc_ny];
	add.s32 	%r11, %r10, -2;
	setp.lt.s32	%p2, %r1, %r11;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r2, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r12, [dc_nx];
	add.s32 	%r13, %r12, -2;
	setp.lt.s32	%p6, %r2, %r13;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB32_6;
	bra.uni 	BB32_1;

BB32_1:
	ld.const.u32 	%r14, [dc_nyPadded];
	mad.lo.s32 	%r3, %r14, %r2, %r1;
	ld.const.u64 	%rd5, [dc_a];
	cvta.to.global.u64 	%rd6, %rd5;
	mul.wide.s32 	%rd7, %r3, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.u8 	%r15, [%rd8];
	setp.eq.s32	%p8, %r15, 255;
	@%p8 bra 	BB32_6;

	cvta.to.global.u64 	%rd9, %rd2;
	mul.wide.s32 	%rd10, %r3, 8;
	add.s64 	%rd11, %rd9, %rd10;
	ld.const.f64 	%fd4, [dc_wetDepthThreshold];
	ld.global.f64 	%fd5, [%rd11];
	setp.gt.f64	%p9, %fd5, %fd4;
	setp.gt.f64	%p10, %fd5, %fd3;
	and.pred  	%p11, %p9, %p10;
	@!%p11 bra 	BB32_6;
	bra.uni 	BB32_3;

BB32_3:
	cvta.to.global.u64 	%rd12, %rd3;
	add.s64 	%rd1, %rd12, %rd10;
	ld.global.f64 	%fd6, [%rd1];
	setp.geu.f64	%p12, %fd6, 0dC76812F9CF7920E3;
	@%p12 bra 	BB32_5;

	st.global.f64 	[%rd1], %fd1;

BB32_5:
	cvta.to.global.u64 	%rd14, %rd4;
	add.s64 	%rd16, %rd14, %rd10;
	ld.global.f64 	%fd7, [%rd16];
	add.f64 	%fd8, %fd7, %fd2;
	st.global.f64 	[%rd16], %fd8;

BB32_6:
	ret;
}

	// .globl	gpu_countFloodCells
.visible .entry gpu_countFloodCells(
	.param .u32 gpu_countFloodCells_param_0,
	.param .f64 gpu_countFloodCells_param_1,
	.param .u64 gpu_countFloodCells_param_2,
	.param .u64 gpu_countFloodCells_param_3,
	.param .u64 gpu_countFloodCells_param_4
)
{
	.reg .pred 	%p<21>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<61>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<59>;


	ld.param.f64 	%fd2, [gpu_countFloodCells_param_1];
	ld.param.u64 	%rd6, [gpu_countFloodCells_param_2];
	ld.param.u64 	%rd7, [gpu_countFloodCells_param_3];
	ld.param.u64 	%rd8, [gpu_countFloodCells_param_4];
	cvta.to.global.u64 	%rd1, %rd8;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r3, %r1, %r16, %r2;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mov.u32 	%r4, %tid.y;
	mad.lo.s32 	%r5, %r17, %r18, %r4;
	setp.gt.s32	%p1, %r3, 1;
	ld.const.u32 	%r19, [dc_ny];
	add.s32 	%r20, %r19, -2;
	setp.lt.s32	%p2, %r3, %r20;
	and.pred  	%p3, %p1, %p2;
	setp.gt.s32	%p4, %r5, 1;
	and.pred  	%p5, %p3, %p4;
	ld.const.u32 	%r21, [dc_nx];
	add.s32 	%r22, %r21, -2;
	setp.lt.s32	%p6, %r5, %r22;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB33_17;
	bra.uni 	BB33_1;

BB33_1:
	ld.const.u32 	%r23, [dc_nyPadded];
	mad.lo.s32 	%r24, %r23, %r5, %r3;
	ld.const.u64 	%rd9, [dc_a];
	cvta.to.global.u64 	%rd10, %rd9;
	cvt.s64.s32	%rd2, %r24;
	mul.wide.s32 	%rd11, %r24, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.u8 	%r25, [%rd12];
	setp.ne.s32	%p8, %r25, 0;
	@%p8 bra 	BB33_17;

	cvta.to.global.u64 	%rd13, %rd6;
	cvta.to.global.u64 	%rd14, %rd7;
	shl.b64 	%rd15, %rd2, 2;
	add.s64 	%rd3, %rd14, %rd15;
	ld.global.u16 	%r6, [%rd3];
	shl.b64 	%rd16, %rd2, 3;
	add.s64 	%rd17, %rd13, %rd16;
	ld.global.f64 	%fd1, [%rd17];
	mov.u32 	%r60, 0;
	setp.eq.s32	%p9, %r6, 0;
	@%p9 bra 	BB33_4;

	setp.ne.s32	%p10, %r6, 65535;
	@%p10 bra 	BB33_16;

BB33_4:
	mov.u32 	%r59, 0;
	setp.leu.f64	%p11, %fd1, %fd2;
	@%p11 bra 	BB33_6;

	div.rn.f64 	%fd3, %fd1, 0d3F50624DD2F1A9FC;
	cvt.rmi.f64.f64	%fd4, %fd3;
	cvt.rzi.u32.f64	%r28, %fd4;
	mov.u32 	%r29, 65535;
	min.u32 	%r59, %r28, %r29;

BB33_6:
	setp.lt.u32	%p12, %r59, 2;
	setp.eq.s32	%p13, %r6, 65535;
	and.pred  	%p14, %p13, %p12;
	selp.b32	%r60, 1, %r59, %p14;
	ld.const.u8 	%rs1, [dc_switches];
	and.b16  	%rs2, %rs1, 128;
	setp.eq.s16	%p15, %rs2, 0;
	mad.lo.s32 	%r30, %r4, %r1, %r2;
	and.b32  	%r31, %r30, 31;
	cvt.u64.u32	%rd4, %r31;
	setp.ne.s32	%p16, %r60, 0;
	selp.u32	%r10, 1, 0, %p16;
	@%p15 bra 	BB33_15;

	ld.const.u64 	%rd18, [dc_hyetographIndexLayer];
	cvta.to.global.u64 	%rd19, %rd18;
	add.s64 	%rd21, %rd19, %rd16;
	ld.global.u64 	%rd5, [%rd21];
	cvt.u32.u64	%r32, %rd5;
	and.b32  	%r11, %r32, 65535;
	setp.eq.s32	%p17, %r11, 0;
	@%p17 bra 	BB33_9;

	add.s32 	%r33, %r11, -1;
	shl.b32 	%r34, %r33, 6;
	cvt.u64.u32	%rd22, %r34;
	add.s64 	%rd23, %rd22, %rd4;
	shl.b64 	%rd24, %rd23, 2;
	add.s64 	%rd25, %rd1, %rd24;
	atom.global.add.u32 	%r35, [%rd25], %r10;
	add.s32 	%r36, %r34, 32;
	cvt.u64.u32	%rd26, %r36;
	add.s64 	%rd27, %rd26, %rd4;
	shl.b64 	%rd28, %rd27, 2;
	add.s64 	%rd29, %rd1, %rd28;
	atom.global.add.u32 	%r37, [%rd29], %r60;

BB33_9:
	shr.u32 	%r12, %r32, 16;
	setp.eq.s32	%p18, %r12, 0;
	@%p18 bra 	BB33_11;

	add.s32 	%r39, %r12, -1;
	shl.b32 	%r40, %r39, 6;
	cvt.u64.u32	%rd30, %r40;
	add.s64 	%rd31, %rd30, %rd4;
	shl.b64 	%rd32, %rd31, 2;
	add.s64 	%rd33, %rd1, %rd32;
	atom.global.add.u32 	%r41, [%rd33], %r10;
	add.s32 	%r42, %r40, 32;
	cvt.u64.u32	%rd34, %r42;
	add.s64 	%rd35, %rd34, %rd4;
	shl.b64 	%rd36, %rd35, 2;
	add.s64 	%rd37, %rd1, %rd36;
	atom.global.add.u32 	%r43, [%rd37], %r60;

BB33_11:
	shr.u64 	%rd38, %rd5, 32;
	cvt.u32.u64	%r44, %rd38;
	and.b32  	%r13, %r44, 65535;
	setp.eq.s32	%p19, %r13, 0;
	@%p19 bra 	BB33_13;

	add.s32 	%r45, %r13, -1;
	shl.b32 	%r46, %r45, 6;
	cvt.u64.u32	%rd39, %r46;
	add.s64 	%rd40, %rd39, %rd4;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd42, %rd1, %rd41;
	atom.global.add.u32 	%r47, [%rd42], %r10;
	add.s32 	%r48, %r46, 32;
	cvt.u64.u32	%rd43, %r48;
	add.s64 	%rd44, %rd43, %rd4;
	shl.b64 	%rd45, %rd44, 2;
	add.s64 	%rd46, %rd1, %rd45;
	atom.global.add.u32 	%r49, [%rd46], %r60;

BB33_13:
	shr.u64 	%rd47, %rd5, 48;
	cvt.u32.u64	%r14, %rd47;
	setp.eq.s32	%p20, %r14, 0;
	@%p20 bra 	BB33_16;

	add.s32 	%r50, %r14, -1;
	shl.b32 	%r51, %r50, 6;
	cvt.u64.u32	%rd48, %r51;
	add.s64 	%rd49, %rd48, %rd4;
	shl.b64 	%rd50, %rd49, 2;
	add.s64 	%rd51, %rd1, %rd50;
	atom.global.add.u32 	%r52, [%rd51], %r10;
	add.s32 	%r53, %r51, 32;
	cvt.u64.u32	%rd52, %r53;
	add.s64 	%rd53, %rd52, %rd4;
	shl.b64 	%rd54, %rd53, 2;
	add.s64 	%rd55, %rd1, %rd54;
	atom.global.add.u32 	%r54, [%rd55], %r60;
	bra.uni 	BB33_16;

BB33_15:
	shl.b64 	%rd56, %rd4, 2;
	add.s64 	%rd57, %rd1, %rd56;
	atom.global.add.u32 	%r55, [%rd57], %r10;
	add.s64 	%rd58, %rd57, 128;
	atom.global.add.u32 	%r56, [%rd58], %r60;

BB33_16:
	shl.b32 	%r57, %r60, 16;
	or.b32  	%r58, %r57, %r6;
	st.global.u32 	[%rd3], %r58;

BB33_17:
	ret;
}

.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<49>;
	.reg .f64 	%fd<136>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	ld.param.f64 	%fd13, [__internal_accurate_pow_param_1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd12;
	}
	shr.u32 	%r47, %r46, 20;
	setp.ne.s32	%p1, %r47, 0;
	@%p1 bra 	BB34_2;

	mul.f64 	%fd14, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd14;
	}
	shr.u32 	%r16, %r46, 20;
	add.s32 	%r47, %r16, -54;

BB34_2:
	add.s32 	%r48, %r47, -1023;
	and.b32  	%r17, %r46, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd134, {%r45, %r18};
	setp.lt.u32	%p2, %r18, 1073127583;
	@%p2 bra 	BB34_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd134;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd134;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd134, {%r19, %r21};
	add.s32 	%r48, %r47, -1022;

BB34_4:
	add.f64 	%fd16, %fd134, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd15,%fd16;
	// inline asm
	neg.f64 	%fd17, %fd16;
	mov.f64 	%fd18, 0d3FF0000000000000;
	fma.rn.f64 	%fd19, %fd17, %fd15, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd19, %fd19;
	fma.rn.f64 	%fd21, %fd20, %fd15, %fd15;
	add.f64 	%fd22, %fd134, 0dBFF0000000000000;
	mul.f64 	%fd23, %fd22, %fd21;
	fma.rn.f64 	%fd24, %fd22, %fd21, %fd23;
	mul.f64 	%fd25, %fd24, %fd24;
	mov.f64 	%fd26, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd27, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd28, %fd27, %fd25, %fd26;
	mov.f64 	%fd29, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd30, %fd28, %fd25, %fd29;
	mov.f64 	%fd31, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd32, %fd30, %fd25, %fd31;
	mov.f64 	%fd33, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd34, %fd32, %fd25, %fd33;
	mov.f64 	%fd35, 0d3F6249249242B910;
	fma.rn.f64 	%fd36, %fd34, %fd25, %fd35;
	mov.f64 	%fd37, 0d3F89999999999DFB;
	fma.rn.f64 	%fd38, %fd36, %fd25, %fd37;
	sub.f64 	%fd39, %fd22, %fd24;
	add.f64 	%fd40, %fd39, %fd39;
	neg.f64 	%fd41, %fd24;
	fma.rn.f64 	%fd42, %fd41, %fd22, %fd40;
	mul.f64 	%fd43, %fd21, %fd42;
	fma.rn.f64 	%fd44, %fd25, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd45, 0d3FB5555555555555;
	sub.f64 	%fd46, %fd45, %fd44;
	fma.rn.f64 	%fd47, %fd25, %fd38, %fd46;
	add.f64 	%fd48, %fd47, 0d0000000000000000;
	add.f64 	%fd49, %fd48, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd50, %fd44, %fd49;
	sub.f64 	%fd51, %fd44, %fd50;
	add.f64 	%fd52, %fd49, %fd51;
	mul.rn.f64 	%fd53, %fd24, %fd24;
	neg.f64 	%fd54, %fd53;
	fma.rn.f64 	%fd55, %fd24, %fd24, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd43;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd56, {%r22, %r24};
	fma.rn.f64 	%fd57, %fd24, %fd56, %fd55;
	mul.rn.f64 	%fd58, %fd53, %fd24;
	neg.f64 	%fd59, %fd58;
	fma.rn.f64 	%fd60, %fd53, %fd24, %fd59;
	fma.rn.f64 	%fd61, %fd53, %fd43, %fd60;
	fma.rn.f64 	%fd62, %fd57, %fd24, %fd61;
	mul.rn.f64 	%fd63, %fd50, %fd58;
	neg.f64 	%fd64, %fd63;
	fma.rn.f64 	%fd65, %fd50, %fd58, %fd64;
	fma.rn.f64 	%fd66, %fd50, %fd62, %fd65;
	fma.rn.f64 	%fd67, %fd52, %fd58, %fd66;
	add.f64 	%fd68, %fd63, %fd67;
	sub.f64 	%fd69, %fd63, %fd68;
	add.f64 	%fd70, %fd67, %fd69;
	add.f64 	%fd71, %fd24, %fd68;
	sub.f64 	%fd72, %fd24, %fd71;
	add.f64 	%fd73, %fd68, %fd72;
	add.f64 	%fd74, %fd70, %fd73;
	add.f64 	%fd75, %fd43, %fd74;
	add.f64 	%fd76, %fd71, %fd75;
	sub.f64 	%fd77, %fd71, %fd76;
	add.f64 	%fd78, %fd75, %fd77;
	xor.b32  	%r25, %r48, -2147483648;
	mov.u32 	%r26, 1127219200;
	mov.b64 	%fd79, {%r25, %r26};
	mov.u32 	%r27, -2147483648;
	mov.b64 	%fd80, {%r27, %r26};
	sub.f64 	%fd81, %fd79, %fd80;
	mov.f64 	%fd82, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd83, %fd81, %fd82, %fd76;
	neg.f64 	%fd84, %fd81;
	fma.rn.f64 	%fd85, %fd84, %fd82, %fd83;
	sub.f64 	%fd86, %fd85, %fd76;
	sub.f64 	%fd87, %fd78, %fd86;
	mov.f64 	%fd88, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd89, %fd81, %fd88, %fd87;
	add.f64 	%fd90, %fd83, %fd89;
	sub.f64 	%fd91, %fd83, %fd90;
	add.f64 	%fd92, %fd89, %fd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd13;
	}
	add.s32 	%r29, %r28, %r28;
	setp.gt.u32	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd13;
	}
	mov.b64 	%fd93, {%r32, %r31};
	mul.rn.f64 	%fd94, %fd90, %fd93;
	neg.f64 	%fd95, %fd94;
	fma.rn.f64 	%fd96, %fd90, %fd93, %fd95;
	fma.rn.f64 	%fd97, %fd92, %fd93, %fd96;
	add.f64 	%fd4, %fd94, %fd97;
	sub.f64 	%fd98, %fd94, %fd4;
	add.f64 	%fd5, %fd97, %fd98;
	mov.f64 	%fd99, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd100, %fd4, %fd99;
	mov.f64 	%fd101, 0d4338000000000000;
	add.rn.f64 	%fd102, %fd100, %fd101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd102;
	}
	mov.f64 	%fd103, 0dC338000000000000;
	add.rn.f64 	%fd104, %fd102, %fd103;
	mov.f64 	%fd105, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd106, %fd104, %fd105, %fd4;
	mov.f64 	%fd107, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd108, %fd104, %fd107, %fd106;
	mov.f64 	%fd109, 0d3E928AF3FCA213EA;
	mov.f64 	%fd110, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd111, %fd110, %fd108, %fd109;
	mov.f64 	%fd112, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd113, %fd111, %fd108, %fd112;
	mov.f64 	%fd114, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd115, %fd113, %fd108, %fd114;
	mov.f64 	%fd116, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd117, %fd115, %fd108, %fd116;
	mov.f64 	%fd118, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd119, %fd117, %fd108, %fd118;
	mov.f64 	%fd120, 0d3F81111111122322;
	fma.rn.f64 	%fd121, %fd119, %fd108, %fd120;
	mov.f64 	%fd122, 0d3FA55555555502A1;
	fma.rn.f64 	%fd123, %fd121, %fd108, %fd122;
	mov.f64 	%fd124, 0d3FC5555555555511;
	fma.rn.f64 	%fd125, %fd123, %fd108, %fd124;
	mov.f64 	%fd126, 0d3FE000000000000B;
	fma.rn.f64 	%fd127, %fd125, %fd108, %fd126;
	fma.rn.f64 	%fd128, %fd127, %fd108, %fd18;
	fma.rn.f64 	%fd129, %fd128, %fd108, %fd18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd129;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd129;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd135, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	 %f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB34_7;

	setp.lt.f64	%p5, %fd4, 0d0000000000000000;
	add.f64 	%fd130, %fd4, 0d7FF0000000000000;
	selp.f64	%fd135, 0d0000000000000000, %fd130, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB34_7;

	shr.u32 	%r36, %r13, 31;
	add.s32 	%r37, %r13, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, %r15;
	mov.b64 	%fd131, {%r14, %r40};
	sub.s32 	%r41, %r13, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd132, {%r44, %r43};
	mul.f64 	%fd135, %fd131, %fd132;

BB34_7:
	abs.f64 	%fd133, %fd135;
	setp.eq.f64	%p7, %fd133, 0d7FF0000000000000;
	@%p7 bra 	BB34_9;

	fma.rn.f64 	%fd135, %fd135, %fd5, %fd135;

BB34_9:
	st.param.f64	[func_retval0+0], %fd135;
	ret;
}


